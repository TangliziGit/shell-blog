# Notes on MIT 6.824

> - MIT6.824 Schedule: https://pdos.csail.mit.edu/6.824/schedule.html
> - MIT6.824分布式系统课程: https://www.zhihu.com/column/c_1273718607160393728

明确一下目标，学习这个课程是为了深入了解分布式应用的概念和指标（为什么使用分布式、困难是什么、一致性是什么等问题），以及现有分布式应用（MapReduce、GFS等）和主流问题解决方案（主备容灾细节、分布式共识算法等）。

- 关于分布式的概念，会在每个Lecture里记录下来。如果缺失了某个lecture，那么说明这节里没有什么需要注意的地方。
- 对于paper里的关键点，则会专门开一个标题去记录重点。
- 对于每个lecture，最好有一句话能够总结整个章节



## Lecture 1 - MapReduce(2004)：分布式计算 - 计算的抽象、分发和容错

### 分布式系统的目的 & 困难

1. **提升性能**
2. **错误容忍**（冗余计算、冗余存储）
4. 安全与隔离（例：区块链）
4. 物理容灾

分布式系统困难的原因：

1. 性能：并行问题
2. 容错：局部故障问题
3. 扩展性：并非机器加更多机器就有更好性能

### 分布式系统的三个抽象

- 存储
- 计算
- 通信

### 分布式系统的话题

- 实现：RPC方法、多线程技术、并发控制
- 可扩展性：系统应当可以通过增加机器来提高系统性能。我们希望通过增加机器的方式来实现扩展，但是现实中这很难实现，**需要架构设计来将可扩展性持续推进下去**。
  - 例：当用户量上涨，如何提高web系统性能？
    1. 部署多个web服务器，直到瓶颈从吞吐量转变为数据存储
    2. 数据库分库分表，需要大量工作

- 容错性：在成百上千台服务器上运行系统，故障将变为常态。常见的容错评判机制是可用性和自愈性
  - 一些提高容错性的手段：使用非易失性存储，建立副本机制在故障时切换（数据冗余）

- 一致性：强调强一致性的CAP、强调弱一致性的BASE
  - BASE是对CAP的：基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）


## Paper：MapReduce

> https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf

1. Core design
   - Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reducefunction that merges all intermediate values associated with the same intermediate key.
2. Target
   - hides the messy details of parallelization, fault-tolerance, data distribution and load balancing in a library
3. Why use map reduce primitives?
   - parallelize large computations easily
   - to use re-execution as the primary mechanism for fault tolerance

### Model

- map(k1, v1) -> list(k2, v2)：接受kv二元组，产出中间kv对
  - 可以理解成按照k2聚合列表v2
- reduce(k2, list(v2)) -> list(v2)：合并中间kv对
  - 内部使用Emit处理结果

在业务上，MapReduce简化了在k2上聚合逻辑。

**Examples**

- 分布式Grep
- 倒排索引：map接受文件名和内容，产出词和文件名，reduce处理词和文件名列表
- 分布式排序：TODO：拆分数组，map接受子数组号，产出字数组号和已排序数组，reduce处理子数组k路归并

### 执行流程

![mapreduce](/static/image/2021-08-30/mapreduce.jpeg)

1. 用户程序首先将输入文件分割成若干份确定大小的分区，然后在worker节点和master节点执行用户程序。
2. master节点分配map和reduce任务
3. map节点读取分区数据，产生**中间kv，存储在内存中**
4. map节点**周期性存储中间数据于磁盘**，在map完成后向master通知输出R个文件的位置和大小。master更新数据结构，通知reduce处理新的文件
5. reduce节点受到通知后，通过RPC读取map本地数据。当读取完所有map数据后（全部结束？），所有数据按key排序。
6. 用户程序的reduce函数开始执行。reduce的输出以追加方式写入结果文件，当reduce结束则原子性修改文件名。
7. 全部map reduce执行完毕后，master开始执行用户程序

**注意**：

1. map本地文件会生成几个？

   1. R个。当所有map结束后，reducer依次拉取各个map本地数据做reduce。

2. map和reduce函数是同时执行么？即reduce读map的一部分周期提交数据进行处理？

   - 阅读后文发现，不是同时执行的。

     > When a map task completes, the worker sends a message to the master and includes the names of the R temporary files in the message.

   - 注意map函数不可以与reduce节点的排序同时执行，因为reduce函数需要等待某个key结束了map，然后再做数据的排序。

3. 为什么reduce函数执行前必须要排序？

   - 排序后的kv对，可以在同一时刻只reduce一个list。当所有list被reduce后，一次性写入输出文件并原子命名。
   - 如果不进行排序，将同时处理大量不同的key，会需要大规模的线程（内存、切换时间）、内存（极端情况是所有数据）

4. master维护什么状态？

   - 各个节点的状态机模型：idle、in-progress、completed
   - 节点的identy信息
   - 每个完成的map产出的文件位置和大小

### 容错机制

#### Worker 容错

master会周期性ping各个worker，如果失败则说明节点失败。

| 任务类型 \ 崩溃时当前任务状态 | 正在执行                         | 执行完成            |
| ----------------------------- | -------------------------------- | ------------------- |
| map                           | 重新分配节点，该节点返回idle状态 | 重新分配节点执行map |
| reduce                        | 重新分配节点，该节点返回idle状态 | 不做处理            |

**注意**：

1. 为什么map在失败后，不能使用当前任务输出的中间kv？
   - 因为中间kv是存于内存，同时周期性写入的文件只是本地文件。也因此map节点失败后，只能重新分配并执行。
2. 为什么reduce在执行完成后，不用处理失败？
   - 因为reduce输出文件是全局公用的，reduce节点失败不影响存储。



#### Master 容错

- **方案一：恢复数据** - 将所有状态存储checkpoint，失败后恢复即可
- **方案二：let it crash** - 单节点的master不太可能失败，若失败则用户自行处理



#### 原子性提交

- 当map和reduce函数是确定性的（纯函数），那么节点通过提交原子性commit，来达到无错误的顺序执行。
  - map节点执行成功后，向master发送信息。master将忽略已经执行完的任务的信息，以避免冗余。
  - reduce节点执行成功后，依靠操作系统的原子性重命名（mv）来提供原子性。
- 当map和reduce函数是非确定性的（非纯函数），那么会提供更弱的方式。具体是什么，论文似乎没有提到。



### 调优：备份任务

一个使运行时间变长的常见原因是某个任务掉队。

原因有很多，比如硬盘速度太慢、CPU缓存禁用等。

解决方法是增加备份机制，当某些任务执行时长太久，则新分配i一个节点给此任务。当主备某一个完成后，则其他任务终止。



## Lecture 3 - GFS(2003)：海量分布式存储 - 单节点维护元数据、数据节点处理读写、数据副本

### 分布式存储难点：性能与容错的权衡

使用分布式的系统，从目标来看都是为了将数据分片（将数据分割放到大量的服务器上，从而并行取数据）以达到性能提升。

但是如果你在成百上千台服务器进行分片，你将会看见常态的故障。在许多系统中会为了容错而降低性能，这就说明分布式系统需要在性能和一致性之间做权衡。

- 提升性能 -> 引入分布式 -> **数据分片**
- 系统存在局部错误 -> **支持容错能力 -> 引入数据副本 -> 提供副本间一致性能力** -> 降低性能



### 关于一致性的错误设计：不安全请求的顺序

课程中介绍了分布式kv存储设计为多写的场景：你无法保证每个replica能够接收到完全相同顺序的写请求，这会导致副本状态不一致问题。

这里可以推广为分布式系统需要处理不安全请求（影响系统状态的请求）顺序问题。你可以设计保证不安全请求在多个replica上顺序完全相同，也可以设计为只有一个replica接受不安全请求。



## Paper : GFS

> https://pdos.csail.mit.edu/6.824/papers/gfs.pdf





## Lecture 4 - VMware FT(2010): Primary Backup Replication - 主备复制的方案、关注点和典型故障场景

> The Design of a Practical System for Fault-Tolerant Virtual Machines: https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf

VMware FT(Fault Tolarence)是指两个虚拟机的主备容错。它需要两个物理服务器，Primary虚机在其中一个物理服务器上，Backup在另一个物理服务器上。（将Primary和Backup运行在一台服务器的两个虚拟机里面毫无意义，因为容错本来就是为了能够抵御硬件故障）

### 两种备份方法 / 主备方案

这里介绍了两种复制方法：

1. State Transfer
   - 是指primary将自身**内存中的状态信息**定期发送给backup存储。当primary故障后，再从backup进行回复。
   - 需要注意的是，每次状态迁移需要进行一次大拷贝，但也可以做diff来减少传输量
2. Replicated State Machine
   - 将系统受到的一系列**外部输入**发送给backup进行存储。这基于一个事实：两个相同状态的系统在受到完全一致的外部输入后将保持一致、互为副本。

我们倾向于Replicated State Machine，是出于**数据传输量**的考虑：State Transfer显然需要更多的数据来做备份，而后者则只需存储client发送来的指令。但Replicated State Machine**需要对系统作出大量的假设**，较为复杂；而State Transfer只需要暴力存储状态即可。

当前的Replicated State Machine是在单核CPU下的方法：在**多核CPU下相同的指令并非造成相同的结果**。VMware后续推出了新的方法解决并行情况，但方案更倾向于状态迁移。

> 1. 在备份不一致的情况下，primary故障回复后导致混乱的问题如何处理？
>    - 后面的工作原理讲到：当backup确认受到外部输入后，再进行下一步工作（即输出控制）。所以避免了备份不一致的情况。属于强一致性。
> 2. 在Replicated State Machine中，随机操作如何处理？

### 主备同步的问题

一些主备同步中的重要问题：（不仅仅集中在Replicated State Macine方案上，其他方案也需要考虑）

- **同步级别、同步频率、状态定义**
  - 在VMware中，主备的状态是指primary内存中的每个bit，即主备在底层也是完全一致的。很少有系统如此设计备份方案，因为它过于困难（甚至需要考虑中断在主备中同一个位置进行）。他的优点是，在VMware FT支持的微处理器上，任何一个可运行的软件都可以具备容错性。你不需要考虑软件的任何逻辑和源码。
  - 然而大部分的系统类似GFS，备份数据是指应用程序级别数据chunk，每个针对chunk都保存有默认3个副本在不同的机架和服务器上。GFS只需要保证chunk副本的一致即可。
- **主备切换**：当系统primary故障后进行主备切换，在理想情形是应当没有任何客户端会注意到这里的切换。在切换过程中，必然会有异常，我们必须找到一种应对它们的方法。
- **备份故障**：当两个备份其中一个故障后，应当尽快上线新的备份避免所有备份宕机。
  - 注意：创建新的副本需要较大代价。因为此时新的副本没有一致的内部状态，所以创建时只能进行状态迁移，不能采用复制状态机。

### 工作原理

在真实场景下，一个局域网中存在着primary宿主机和backup宿主机，他们分别运行着primaryVMM和backupVMM (VMM，Virtual Machine Monitor)，用于监控主备VM。同时这个局域网中还存在者一些client（此处用于VM存储的disk server也可以算为client）。

#### 主备同步时机与流程

首先讲<u>主备同步的时机，并如何进行主备同步</u>。当client向primary发送一个请求分组后，将触发**primary host的中断，之后这个中断将数据送给VMM**。此时VMM可以发现该分组是需要发送给primary vm的，于是VMM开始如下两个操作：

1. 向**本地（primary）的vm模拟网络请求中断**，将数据发送给primary vm的应用程序中。（当primary VMM收到处理完的primary输出，并收到到backup的ACK后，再发送响应。这个过程被称为输出控制）
2. **向backup host发送一个相同的网络请求**，之后backup VMM将可以受到此分组。

此时主备vm都受到了相同的外部输入，他们会以相同的方式处理外部输入，并最终达到状态一致。最终，primary将网络响应发送给client，backup因为知道自己是备份所以丢弃响应。（论文中的Log Channel就特指局域网中priamry向backup VMM发送外部输入的信道）

#### 主备切换流程

其次，讲<u>主备切换</u>的过程。实际场景中，backup能够在一秒内受到很多条log，有一部分是primary的定时器中断（大概100次每秒）。当backup没有在一段时间内受到primary的定时器中断后，说明primary出现失败，需要主备切换了。

1. 首先backup不再接受来自primary VMM的log，而是接受网络输入作为外部输入源，同时不再丢弃输出分组。
2. backup在网络中做一些处理（？），使得client都转而访问backup。

> 1. Backup怎么让其他客户端向自己发送请求？
>
>    - Robert：（ARP欺骗）每个虚拟机也有一个唯一的MAC地址，当Backup虚机接手时，它会宣称它有Primary的MAC地址，并向外通告说，我是那个MAC地址的主人。
>
> 2. 在Replicated State Machine中，随机操作如何处理?
>
>    - VMware FT的设计者认为他们找到了所有类似的操作，对于每一个操作，Primary执行随机数生成，或者某个时间点生成的中断（依赖于执行时间点的中断）。而Backup虚机不会执行这些操作，Backup的VMM会探测这些指令，拦截并且不执行它们。VMM会让Backup虚机等待来自Log Channel的有关这些指令的指示。
>    - 关于设计伪随机：应该不能要求primary和backup使用同一个seed做随机。因为随机数场景在于各类加密算法，两台机器随机数完全相同可能打破一些算法的前提。

### 非确定性事件 （Non-Deterministic Events）

> https://zhuanlan.zhihu.com/p/190779044

通常情况下，代码执行都是直接明了的，但并不是说计算机中每一个指令都是由计算机内存的内容而确定的行为。这一节，我们来看一下不由当前内存直接决定的指令。这些指令在Primary和Backup的运行结果可能会不一样。这些指令就是所谓的非确定性事件。非确定性事件可以分成几类：

1. 客户端输入。
   - 当我们说输入的时候，我们实际上是指接收到了一个网络数据包。而一个网络数据包对于我们来说有两部分，一个是数据包中的**数据**，另一个是提示数据包送达了的**中断**。
   - 当网络数据包送达时，通常网卡的DMA（Direct Memory  Access）会将网络数据包的内容拷贝到内存，之后触发一个中断。操作系统会在处理指令的过程中消费这个中断。对于Primary和Backup来说，这里的步骤必须看起来是一样的，否则它们在执行指令的时候就会出现不一致。所以，这里的问题是，**中断在什么时候，具体在指令流中的哪个位置触发**
2. 怪异指令：有一些指令在不同的计算机上的行为是不一样的
   - 随机数生成器
   - 获取当前时间的指令，在不同时间调用会得到不同的结果
   - 获取计算机的唯一ID
3. 另外一个常见的非确定事件，即多CPU的并发。
   - 当服务运行在多CPU上时，指令在不同的CPU上会交织在一起运行，进而产生的指令顺序是不可预期的。
   - 另外，这里探究了论文未提即的log条目内容，教授猜测有三样内容：
     - 事件发生时的指令序号。因为如果要同步中断或者客户端输入数据，最好是Primary和Backup在相同的指令位置看到数据，所以我们需要知道指令序号。这里的指令号是自机器启动以来指令的相对序号，而不是指令在内存中的地址。比如说，我们正在执行第40亿零79条指令。所以日志条目需要有指令序号。对于中断和输入来说，指令序号就是指令或者中断在Primary中执行的位置。对于怪异的指令（Weird  instructions），比如说获取当前的时间来说，这个序号就是获取时间这条指令执行的序号。这样，Backup虚机就知道在哪个指令位置让相应的事件发生。
     - 日志条目的类型
     - 数据

> 1. 如果Backup领先了Primary会怎么样？
>    - 它会维护一个来自于Primary的Log条目的等待缓冲区，如果缓冲区为空，Backup是不允许执行指令的。如果缓冲区不为空，那么它可以根据Log的信息知道Primary对应的指令序号，并且会强制Backup虚机最多执行指令到这个位置。所以Backup总是落后于Primary至少一个Log。
> 2. 能不能输入送到Primary，输出从Backup送出？
>    - 这是一个很有意思的方法。Backup输出说明它已经完成一致性任务，不过primary仍需要获知backup是否收到log。如果没有primary没有感知到backup收到log，那么primary应该继续执行么？当然不应该，否则会出现不一致情况。

### 主备切换 & 主备故障的场景

#### 副本不一致下的主备切换

当primary VMM收到处理完的primary输出，并收到到backup的ACK后，再发送响应。这个过程被称为输出控制。

这属于强一致性，意味着网络消耗成为影响性能的重要因素。

#### 主备切换后的重复响应

当Backup的Log缓冲区仍有很多剩余未处理时，Primary由于故障而Backup触发接管机制。这时Backup的外部输入Log将引导vm发出重复的响应。

但是需要注意到，副本在TCP层面也进行了复制。这说明Backup知晓链接的TCP序列号信息，这样重复响应会被Client的TCP栈抛弃。同时，Backup和Client之间并没有真正保持TCP链接，所以Backup应该会受到Client的TCP Reset响应。（我猜测Backup可以不做处理，这样Client没有受到响应。那么client会有两种反应：请求没有到达primary，所以系统没有状态变化；或者响应没有到达client，所以系统已经发生变化。这本来就是client需要考虑的事情。所以backup在这个情况下，完全可以不处理Reset。）

通常而言，<u>分布式系统基本不可能保证不产生重复输出</u>。这需要其他机制来处理，一种可能是在应用层面设计序列号。

> 1. 主备在网络协议上是完全一致？IP地址都是一样的么？
>
>    需要注意的是，运行VM的物理服务器在网络传输上被设计为透明的。这意味着VM拥有与物理服务器一样的网络协议，它们拥有独立的IP和MAC（IP可能需要在物理机的网段中）。交换机、路由器等网络设备会正常执行它们的操作，并不会注意到VM的存在。

#### 主备网络链接断开：脑裂（Split Brain）

> **分布式场景下的定理：你无法判断另一个计算机是否真的挂了**

VMware的解决方法是主备依赖第三方的TestAndSet服务。当主备的网络通信断掉后，双方都会申请成为primary。TestAndSet服务相当于一个锁，它决定了主备之中谁应该成为priamry。

这里TestAndSet服务似乎是单点故障的受害者。但VMware肯定也考虑到这点，所以它应当也是有主备的。





## Paper：Raft

> http://nil.lcs.mit.edu/6.824/2020/labs/lab-raft.html

Raft是一个为了管理多副本日志的共识算法。一致性算法允许一组机器作为一致的组工作，同时可在一些成员出现故障时存活下来。它**强调容错性（崩溃容错和拜占庭容错，这里只讨论前者）。**

### 引入

Raft与其他共识算法相似（特别是VSR, viewstamped replication），区别在于：

- **Strong leader**：Raft使用了一种比其他共识算法更强的领导形式。
  - 提升系统性能：在一些无Leader的多副本系统（如Paxos）中，通常需要在一轮消息中确定一个临时Leader，然后在下一轮消息中再确认请求。这花费了两倍的时间。
  - 帮助理解Raft系统。
- **Leader election**：Raft使用随机计时器来选举领袖。这只在心跳包上增加了少量的机制，就能简单和迅速解决冲突。
- Membership changes：这允许集群在配置更改期间继续正常运行。

对比更复杂的Paxos，Raft通过下面的方法进行了简化：

- 分治：Raft将算法分解成**Leader选举、日志复制、安全性和成员变动**。
- 简化状态空间



### 复制状态机

与GFS和HDFS类似，Raft将上层应用程序作为复制状态机管理（见上文VMware FT）。Raft作为共识模块，<u>可以在节点失败的场景下，保证日志内容和顺序的最终一致性。</u>具体而言，Raft能够提供如下的属性：

- **安全性**（safety）：在**所有非拜占庭条件下（包括网络延迟、网络分区、丢包、包重复、包乱序）**，从不返回错误的结果。
- **可用性**：大多数节点正常运行并可相互通信情况下，系统保持正常运行。当节点失败重启后，能够恢复状态并重新加入集群。
- **不依赖时间**：错误的时钟和消息延迟在极端的场景下，会导致可用性问题。
- **性能**：只需过半的节点同步Log，那么就可以响应客户端。

Raft会以库的形式存在于服务中。从软件的角度来看，我们可以认为在某个节点的上层是有状态的应用程序代码，下层是raft模块。我们拿带raft的kv数据库做一个例子：

假设客户端将请求发送给Raft的Leader节点，在服务端程序的内部，应用程序只会将来自客户端的请求对应的操作向下发送到Raft层，并告知把这个操作提交到多副本的日志中，并在完成时通知我。**当且仅当Raft的Leader知道了过半节点的副本都有了这个操作的拷贝之后**。Raft层会向上发送一个通知到应用程序说：刚刚的操作，我已经提交给所有副本，现在你**可以真正的执行这个操作**了。

注意：

1. 对于client的读请求，client最少需要等待两倍RTT才能获得响应：一个RTT是client和leader间的往返，一个RTT是leader与半数follower并发AppendEntries的往返。
2. 如果客户端发送请求之后一段时间没有收到回复，它应该重新发送请求。



### Raft共识算法

![raft-fig-2](/static/image/2021-12-20/raft-fig-2.png)

每个节点都有一种临时角色：Leader、Follower和Candidate。他们的职能和状态转移如下：

- Leader：主要用于处理客户端请求、发送AppendEntries（心跳包&日志同步）
  - 变为Follower：受到高Term的VoteRequest & 高Term的AppendEntries & 高Term的AppendEntries响应
- Follower：（初始值）被动接受Leader的AppendEntries进行日志同步，接受Candidate的VoteRequest选主
  - 变为Candidate：选举定时器到期
- Candidate：选主时主动发送VoteRequest
  - 变为Leader：选举通过过半仲裁
  - 变为Follower：受到高Term的VoteRequest & 高Term的AppendEntries & 高Term的VoteRequestResponse

注意：

1. 其实<u>任何角色受到任何高任期的请求和响应，都会转变为对应节点的Follower</u>。
2. 每个RPC都会在响应超时情况下进行重试尝试，并且每个RPC都是并行执行。
3. 每个Term会将时间分割开来，它在整体上表现成逻辑时钟。



#### 选主流程

![request-vote-rpc](/static/image/2021-12-20/request-vote-rpc.png)

- **触发时机**：某个Follower / Candidate在选举定时内，没有收到Leader的AppendEntries
- **选主流程[发送者]**：
  1. 节点状态改变：`{Role=Candidate, Term+=1, VotedFor=self}`
  2. 并发发送`VoteRequest{Term, CandidateID, LastLogTerm, LastLogIndex}`给所有server
  3. 统计结果`VoteRequestResponse{Term, VoteGranted}`：
     
     - 确认选举没有结束（选举可被选举定时器和新的选举打断）
     - `Term > currentTerm` => 成为Follower：`{Role=Follower, Term, VotedFor=nil}`；<s>重置选举计数器</s>
     - `Votes == serverCount / 2 + 1`(为了不重复检查成为Leader，这里用相等判断) => 重置选举计数器；成为Leader：`{Role=Leader， []nextIndex, []matchIndex}`；初始化`{[]nextIndex=len(log), []matchIndex=-1}`
     - 选举超时 => 重新选主
- **选主流程[接收者]**：`VoteRequest{Term, CandidateID, LastLogTerm, LastLogIndex}`
  - `Term < currentTerm` => 反对票
  - `isTermEnough && isLogUpToDateEnough` => 支持票
    - 成为Follower：`{Role=Follower, Term, VotedFor=candidateID}`；重置选举计数器
  - `otherwise` => 反对票
    - 检查Term大小更新：`{Role=Follower, Term}`

**注意**：

- 这个RPC是幂等的。
- 最新的Log被定义为，有最高的Term和最高的Index。
- 一切带Term的节点交互过程里（req / resp）都需要检查并更新本节点`{Term, Role=Follower}`。
- 当Term相同时，对votedFor的检验才有意义。因为Follower当前Term的votedFor是上一次选举时的产物，而非本次选举的。
- 可以将选主流程认为是（在最终一致性角度）：在集群中识别`{LastLogTerm, LastLogIndex}`偏序集的过程。在实时情况上，你还需要判断`{Term, sendingTime}`。细节可见下一条。
- 其实，一个节点最终能不能成为Leader主要关注LogTerm&LogIndex。不关注Term的原因是，该节点在与高Term节点通信时会改变调整Term。同时因为节点拥有更新的Log，除非大多数节点没有更新的Log，那么该节点后续还是很可能成为Leader。（若没有成为Leader，那么这条Log后续很可能会被覆盖，客户端将收不到这条提交的Log）
- 会存在脑裂，但是不过半的小集群Leader不会提交Log。于是小集群Leader不会响应Client的请求，也不会执行Client的命令。
- 随机化的定时器可以解决Candidate同时请求投票，导致的系统一直投票死锁的情况。但是选举定时器的随机范围需要规范确定：
  - 下限：应当是心跳包时间间隔的n倍，这样能确保follower能够避免因为偶然的网络异常而触发选举
  - 上限：它影响了Leader失败后系统恢复速度。当故障频繁时，需要重点权衡。
    - 我们需要考虑在两个节点超时时间差之内，应当可容纳单趟VoteRequest RPC的时长。



#### 日志复制

![append-entries-rpc](/static/image/2021-12-20/append-entries-rpc.png)

每个Client请求包含由复制状态机执行的命令。Leader将命令附加到其日志作为新条目，然后与每个其他服务器并行的复制Log。当Log已提交时，Leader将Log应用于其状态机，并将该执行的结果返回给客户端。如果Followers崩溃或运行缓慢，或者如果网络数据包丢失，那么Leader将无限期重试。

- **触发时机**：定期AppendEntries & 客户端提交log接口

- **复制流程[发送者]**：
  1. 发送`AppendEntries `：注意需要根据nextIndex得到`prevLogTerm & prevLogIndex`
  
  2. 统计响应`AppendEntriesResponse{Term, Success}`：
  
     1. 确认自己不是Leader
  
     2. `Term > currentTerm` => 成为Follower：`{Role=Follower, Term}`
  
     3. 检查`success`：
  
        - `success` => 更新nextIdx成对方最后一个LogIndex+1；更新matchIndex为nextIndex-1；根据所有matchIdx更新commitIdx并提及Log给上层应用（后文讨论细节）
  
        - `!success` -> 对应server回退nextIndex（后文细节）
  
- **复制流程[接受者]**：
  
  - `Term < currentTerm` => 响应失败
  - 没有匹配PrevLogIndex的Log => 响应失败
    - 更新`{Term, Role=Follower}`重启计数器
    - 检查冲突Log，回复`{XTerm, XIndex, XLen}`
  - `otherwise` => 响应成功
    - 更新`{Term, Role=Follower}`重启计数器
    - Append对应Log
    - 更新CommitIndex，并提交Log给上层应用：`commitIndex = max(commitIndex, min(leaderCommit, lastLogIndex))`

**注意**：

- 这个RPC是幂等的。
- 对Leader控制的网络分区来说，当term和index一致，那么log一致。这是单节点leader能够保证的，它不会像多节点那样有冲突。
- 当prevLogTerm & Index不同时，不更新。一旦更新，那么从冲突点开始的所有log，复制append req的logs。与上一条结论结合，副本将类似区块链那样保证副本完全一致。
- 对于上层应用发来的**读命令请求**，仍需要Leader做一次半数以上的AppendEntries，验证当前Leader是系统唯一Leader，才能保证读到的commit操作结果不是脏数据（旧数据，线性一致性）。
- Leader只能commit与当前Term相等Term的Log：Leader只能提交当前Term的Log，这样可以**避免覆盖Leader更替间隙中已提交的日志**。
  - Leader只能提交当前Term的Log，即从接受该Log至今没有Leader更替。如果Leader（TermC）提交了之前TermA的Log，那么有可能导致覆盖TermB的已提交Log。有可能在TermA和TermB之间存在一些TermB的已提交Log，可以称为间隙已提交日志。

- 如果Follower的日志与Leader的日志不一致，在下一次AppendEntries中一致性检查将失败。RPC被拒绝后，Leader递减nextIndex并重试AppendEntries。最终，nextIndex将达到Leader和Follower日志匹配的点。
- 为了能够更快的恢复日志，Follower需要返回足够的信息给Leader，让Leader可以以一段Log为单位来回退，而不用每次只回退一条Log条目。优化方案有很多：
  - **按Term回退：**Follower返回xTerm、xIndex和xLen用来表示prevLogIndex的匹配情况（即冲突）
    - xTerm：指冲突Log的Term
    - xIndex：指xTerm最远冲突点，即xTerm的第一个LogIndex
    - xLen：指如果没有prevLogIndex对应的Log，那么缺多少补多少；此时xTerm=-1
    - **原理**：在Index一致情况下，如果Term不相等，那么Follower这一Term的Log都是错误Log，所以需要一次性退掉xTerm。如果对应Index没有Log，那么nextIndex回退xLen再检查
  - 二分查找冲突点：Leader首先携带空Entries选取中点进行查询，当Follower Reject后向前取二分，当Follower Accept时向后取二分。当冲突点找到后则可以携带数据。



#### 日志快照

![install-snapshot-rpc](/static/image/2021-12-21/install-snapshot-rpc.png)






#### 安全性

首先总结一下Raft的安全特性。这些特性在网络分区或故障中都能保证：

- **选举安全**：在任期内最多只能选出一位领导人。
  - 论证：因为Candidate是通过半数仲裁赢得选举，同时一个节点在同一个任期里只能投票给一个节点。在同一Term中选出两个Leader一定意味着至少存在一个节点给两个节点同时投同意票，这是不可能的。
- Leader仅能追加日志：Leader从不覆盖或删除其日志中的条目，它只添加新条目。
- **日志匹配**：如果两个日志包含一个具有相同Index和Term的条目，那么从零到给定Index的所有条目中的日志都是相同的。
  - 论证：
    1. 首先，当term和index一致，那么log内容一致。因为在相同Term中只能选出一个Leader，同时单节点Leader一定能够保证相同Index和Term下的Log内容一致。
    2. 其次，在Leader做AppendEntries时每个Log都有唯一的prevLogIndex和prevLogTerm，仅当被同步节点具有响应前置Log，它才能接受此Log并附加在前置Log之后（类似于区块链）。
    3. 所以，当两个节点（Leader节点同理）接受相同Index和Term的Log后，可以说明之前的所有Log都是相同的。
- **Leader完整性**：如果一个Log是已提交的，那么该Log将会出现在任何更高Term的Leader日志中。
  - 论证：
    1. 首先，已提交的Log是指大多数节点都存在此Log，称这个Log为LogX。
    2. 其次，成为Leader需要通过过半仲裁。那么持有LogX的节点和投赞成票的节点会**有交集**，至少存在一个拥有LogX的节点投赞成票。
    3. 所以可以认为当前Leader拥有LogX。
- **状态机安全**：如果一个服务器在给定Index上应用了一个Log到它的状态机，那么任何其他服务器会应用这个Index里相同的Log。（我的理解：在同一个已提交的Log的Index上，不会存在另一个不同内容的Log在相同Index上提交）
  - 论证：反证法
    1. 首先，应用相同Index而不同Log X的方式是获得半数以上Follower的AppendEntries同意。要获得同意，对Leader而言必须有：`{Term>=followerTerm, prevLogMatched}`。
    2. 所以，Follower的Term一定低于Leader的Term，同时此Log的Term一定小于等于Follower的Term。那么有`LeaderTerm > LogXTerm`。
    3. 但是，Leader完整性要求已提交Log会出现在任何高Term的Leader中。注意到`LeaderTerm > LogXTerm`同时LogX已提交。那么说明LogX的内容是没有改变的。推出矛盾，证明状态机安全成立。





## Lecture 6 & 7 - Raft(2014): Fault Tolerance

在之前的三个多副本系统中，都或多或少地使用了单节点去决定某个副本谁是主。

使用单节点来决定的优势在与，单节点的决策不会出现矛盾。但同时单节点又面临了单点故障的问题（Single Point of Failure）。正因为单节点没有决策矛盾，所以它被用来处理脑裂的场景：当局部故障出现后（主备heartbeat断开），应决定谁是主备份。

### 脑裂：为什么要用单节点决定主备份？

> - MapReduce复制了计算，但是复制这个动作，或者说整个MapReduce被一个单主节点控制。
>
> - GFS以主备的方式复制数据。它会实际的复制文件内容。但是它也依赖一个单主节点，来确定每一份数据的主拷贝的位置。
>
> - VMware FT，它在一个Primary虚机和一个Backup虚机之间复制计算相关的指令。但是，当其中一个虚机出现故障时，为了能够正确的恢复。需要一个Test-and-Set服务来确认，Primary和Backup虚机只有一个能接管计算任务。
>
> 这三个例子中，它们都是一个多副本系统（replication system），但是在背后，它们存在一个共性：它们需要一个单节点来决定，在多个副本中，谁是主（Primary）。

此处可以理解为如何设计分布式锁，首先回忆一下处理竞争的正确方式：让某个节点知晓自己优先请求到资源，而且其他节点也要能确认存在某个节点首先请求到资源。

假设设置一个多副本的TestAndSet服务（S1和S2），同时其中的多副本没有建立主备复制机制。即每次client（C1和C2）都要访问某个server去选主。这里我们考虑两个场景：

1. 每个client都需要访问所有server，如果响应一致则选主成功。这其实对提高系统容错性没有帮助，两台服务器都需要正常运行且网络链接正常。
2. 每个client只需要访问某个server，如果某个响应成功，则选主成功。但这又是一个典型设计错误：不安全请求顺序对多副本系统不确定。


上世纪80年代排除脑裂的两种技术：

1. 构建一个不可能出现故障的网络。不可能出现故障的网络一直在我们的身边：连接了CPU和内存的线路就是不可能出现故障的网络。如果客户端不能与一个服务器交互，那么这个服务器肯定是关机了。
2. 人工检查问题。



### 过半仲裁 Quorum

如果服务器的数量是奇数的，那么当出现一个网络分割时，两个网络分区将不再对称。且必然不可能有超过一个分区拥有过半数量的服务器。（所有服务器数量的一半，而不是当前开机服务器数量的一半）。如果系统有 2 \* F + 1 个服务器，那么系统最多可以接受F个服务器出现故障，仍然可以正常工作。

在过半票决这种思想的支持下，大概1990年的时候，有两个系统基本同时被提出。这两个系统指出，你可以使用这种过半票决系统，从某种程度上来解决之前明显不可能避免的脑裂问题。两个系统中的一个叫做Paxos，Raft论文对这个系统做了很多的讨论；另一个叫做ViewStamped Replication（VSR）。尽管Paxos的知名度高得多，Raft从设计上来说，与VSR更接近。



### 日志的作用

1. 保证操作顺序性：Log包含的term和index，对系统而言用于保证log的顺序性。每个log拥有唯一的term和index。
2. 临时存储：Follower需要在确定操作被committed，才能将其应用到副本状态机中。有些未提较的log可能在未来切换leader后，被替换而不复存在。
3. 备份重传：当新机器加入集群中时，状态中的log entry是空的。所以leader需要给它传输先前已有的数据。
4. 状态恢复：Log存储于非易失介质中，当节点重启后可以通过从头执行log，来恢复副本状态机的内存信息。



### 零散的注意点

1. 对于raft暴露出来的接口，事实上只有一个：Start(command)和对应的ApplyMsg{command, logIndex, valid?}响应通道。课程在这里选择使用异步的方式，让应用程序等待commited logs。



### 一些案例

- 假设Leader每秒可以执行1000条操作，Follower只能每秒执行100条操作，并且这个状态一直持续下去，会怎样？

Leader将会是系统中最新的副本，同时Follower的log将无限增长。**Raft中并无流控机制**（流量控制，并非拥塞控制）。所以生产环境下，如果需要最大化系统性能，Leader需要加入流控能力控制速度。

- **当系统所有节点宕机会发生什么？**

重启后，进行Leader选举。Leader会在下一个AppendEntries操作时，按照nextIndex（初始化为LastLogIndex）发送给Followers。此时Follower应当检查prevLogTerm和Index来确认最近一次Log是否为系统的最新Log。若是则发送success，Leader在多数成功下更新commitIndex。若否，则Leader**回退prevLog**Term和Index来检验该Follower最近Log，并计算最近的commitIndex。当commitIndex确认后，Raft将命令发送给上层应用。应用程序需要**按序进行每一个Log的操作**。（加粗的两个操作是最消耗时间的机制，Raft对这两种问题也提出了解决方案）

- 在单向的网络出现故障情况下，raft如何工作？

Leader将收不到自己心跳包响应，导致没有log可以提交，同时没有新的Leader被选举出来。解决这个问题的方法是，Leader在受不到一定的响应后自动卸任（不发送心跳包，可能是进入Follower状态）。这样新的Leader将会出现。

 

### 持久化与代价

- 持久化的存储可以确保当服务器重启时，服务器可以找到相应的数据，并将其加载到内存中。这样可以使得服务器在故障并重启后，继续重启之前的应用程序状态。
- 我们需要具备替换一个全新的空的服务器，并让该新服务器在集群内工作的能力。这是至关重要的，因为如果一些服务器遭受了不可恢复的故障，例如磁盘故障，你绝对需要替换这台服务器。同时，如果磁盘故障了，你也不能指望能从该服务器的磁盘中获得任何有用的信息。所以我们的确需要能够用全新的空的服务器替代现有服务器的能力。
- 在整个集群都同时断电停止运行的场景下，我们需要能够得到之前状态的拷贝，这样我们才能保持程序容错继续运行。

在论文中只有Log、currentTerm、votedFor三个状态需要持久化。下面依次介绍原因：

- Log：这是唯一可以用来恢复应用程序状态的记录，没有它不可能回复应用状态。
- votedFor：用以避免该节点在同一任期多次投票，导致集群中出现多个Leader的情况。
- currentTerm：当Leader挂掉后，其他节点如果根据本地Log最大Term来猜测本机Term的话，可能导致存在两个同一Term的不同Log的Leader。（？？？）

顺便再看一下不需要持久化的状态：

- commitIndex：Leader**必须**在恢复集群过程中通过matchIndex得到（因为Leader不知道数据是否同步）；Follower可以在下一次AppendEntries中同步得到。
- lastApplied：从头执行一遍Log，应用程序就不需要持久化。（存在压缩Log和快照优化）
- (Leader) nextIndex：从末尾开始匹配每个节点得到。
- (Leader) matchIndex：从0开始匹配每个节点得到。

![latency](/static/image/2021-12-20/latency.png)

在一个真实的Raft服务器上，这意味着将数据写入磁盘，所以你需要一些文件来记录这些数据。但向磁盘写数据是一个代价很高的操作（随机Seek：HDD 10ms，SSD 100 μs，DRAM 50ns）。所以这里的持久化操作的代价可能会非常非常高。10毫秒相比发送RPC（国内平均70ms）或者其他操作来说都太长了。如果你持久化存储在一个机械硬盘上，那么每个操作至少要10毫秒，这意味着你永远也不可能构建一个每秒能处理超过100个请求的Raft服务。这就是所谓的**synchronous disk updates**的代价。为了让磁盘的数据保证安全，同时为了能安全更新你的笔记本上的磁盘，文件系统对于写入操作十分小心，有时需要等待磁盘（前一个）写入完成。所以这（优化磁盘写入性能）是一个出现在所有系统中的常见的问题，也必然出现在Raft中。

如果你想构建一个能每秒处理超过100个请求的系统，这里有多个选择。

- 使用更快的非易失性存储设备。你可以使用SSD硬盘，或者某种闪存。SSD可以在0.1毫秒完成对于闪存的一次写操作，所以这里性能就提高了100倍。更高级一点的方法是，你可以构建一个电池供电的DRAM，然后在这个电池供电的DRAM中做持久化存储。
- 批量执行操作。如果有大量的客户端请求，或许你应该同时接收它们，但是先不返回。等大量的请求累积之后，再一次性持久化存储，发AppendEntries。注意，**每个节点在持久化数据后才能发送相关RPC**。这是因为不能在节点发送数据后节点宕机，导致忘记自己的数据。

> 1. 当你持久化存储一个Log或者currentTerm，如何确保这些数据实时的存储在磁盘中？（unix/linux下write函数写缓存&立即返回）
>    在一个UNIX或者一个Linux或者一个Mac上，为了调用系统写磁盘的操作，你只需要调用write函数，在write函数返回时，并不能确保数据存在磁盘上，并且在重启之后还存在。几乎可以确定（write返回之后）数据不会在磁盘上。所以，如果在UNIX上，你调用了write，将一些数据写入之后，你需要调用fsync。在大部分系统上，**fsync可以确保在正确返回时，所有之前写入的数据已经安全的存储在磁盘的介质上了**。之后，如果机器重启了，这些信息还能在磁盘上找到。fsync是一个代价很高的调用，这就是为什么它是一个独立的函数，也是为什么write不负责将数据写入磁盘，fsync负责将数据写入磁盘。因为写入磁盘的代价很高，你永远也不会想要执行这个操作，除非你想要持久化存储一些数据。



### 日志快照

快照解决的问题是：

- Log会持续增长。最后可能会有数百万条Log，从而需要大量的内存来存储。如果持久化存储在磁盘上，最终会消耗磁盘的大量空间。
- 服务器恢复时，需要通过重新从头开始执行这数百万条Log来重建自己的状态。当故障重启之后，遍历并执行整个Log的内容可能要花费几个小时来完成。

Raft会要求应用程序做一个快照，从Log中选取一个与快照对应的点，然后要求应用程序在那个点的位置做一个快照，同时赋予一个与最后一个Log相同的Term和Index。接下来Raft将会丢弃所有那个点之前的Log记录。注意：**快照是应用程序的产物，Raft并不理解其中的内容**。

这里会与无快照的Raft流程有冲突：

- 在节点重启后，需要将快照作为Log恢复。所以应用程序也需要能像Log那样读取并处理快照。
- 若某个Follower缺失Leader的快照之前的一些Log，同时Leader如果也要丢弃快照之前的Log。那么Follower将很难恢复并应用Log给应用程序。一种解决方式是Leader只能在matchIndex最小值前做快照，另一种解决方式是Leader不删除matchIndex最小值及其后的Log。但如果有一个Follower持续关机，那么Log快照将不能发挥其作用（Leader和其他节点都不能，因为其他节点也有成为Leader的可能）。所以InstallSnapshot被提出，它会清除落伍的Follower应用程序，并安装对应的快照，最后接受一系列AppendEntries。

> 1. 如果RPC消息乱序该怎么处理？
>    RPC系统不是完全的可靠和有序，同时Leader几乎肯定会并发发出大量RPC，其中包含了AppendEntries和InstallSnapshot。如果Follower收到了一条InstallSnapshot消息，但是这条消息看起来完全是冗余的，这条InstallSnapshot消息包含的信息比当前Follower的信息还要老，这时，Follower该如何做？
>    Raft论文图13的规则6有相应的说明。老师认为正常的响应是，Follower可以忽略明显旧的快照。

### 线性一致

通常来说，线性一致等价于强一致。一个服务是线性一致的，那么它**表现的就像只有一个服务器**，并且服务器**没有故障**，这个服务器每次执行一个客户端请求。

如何证明某个应用程序是线性一致地执行呢？**（我认为外在表现只能从客户端的历史请求入手）**：我们拿到所有历史请求（<u>注意这里是请求的接受和回复，而实际的处理过程会在这个请求的范围中某个点</u>）并对其排序，如果后继序列可以构建并且是无环的，那么说明系统是线性一致的。对于这个后继逻辑顺序，有两个限制条件：

1. 如果一个操作在另一个操作开始前就结束了，那么这个操作必须在执行历史中出现在另一个操作前面。
2. 执行历史中，读操作，必须在相应的key的写操作之后。

例子可见：https://zhuanlan.zhihu.com/p/208394772和后续。对于系统执行写请求，只能有一个顺序，所有客户端读到的数据的顺序，必须与系统执行写请求的顺序一致。

> - 所以说线性一致不是用来描述系统的，而是用来描述系统的请求记录的？
>   **线性一致的定义是有关历史记录或系统行为的定义，而不是系统的定义。**

**关于重传**

服务器处理重复请求的合理方式是，根据请求的唯一号或者其他的客户端信息来保存一个表。这样服务器可以记住是否执行过它，从而发送一个相同的回复，因为服务器不希望执行相同的请求两次（优化时间 / 读写幂等）。



## Lecture 8 & 9 - ZooKeeper(2010)：客户端顺序一致性

> - [一致性模型笔记](https://int64.me/2020/%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0.html)
>
> - http://nil.lcs.mit.edu/6.824/2020/papers/zookeeper.pdf

### 一致性保证：写线性一致性 & 客户端顺序一致性

与线性一致一样，这些保证与序列有关。Zookeeper有两个主要的保证，它们在论文的2.3有提及。总的说来，Zookeeper提供了客户端顺序一致性和线性一致的写。

- Linearizable writes：写请求线性一致
  - 如果一个写请求在另一个写请求开始前就结束了，那么Zookeeper实际上也会先执行第一个写请求，再执行第二个写请求。
- FIFO client order：**FIFO客户端顺序保证**。任何一个客户端的请求，都会按照客户端指定的顺序来执行
  - 写请求：会以这个客户端发送的相对顺序，加入到所有客户端的写请求中。所以，如果一个客户端顺序完成三个写操作，那么在最终整体的写请求的序列中，可以看到这个客户端的写请求以相同顺序出现。对于异步的请求，可以假设，客户端实际上会对它的写请求打上序号。
  - 读请求：**需要注意只经过副本去处理读**。读请求也会像上文的样子，客户端顺序完成三个读操作，最终会看到副本会依次做读请求。注意，处理读请求时Log的长度也会增长，后来的读请求会比之前的能看到更多的Log。

> - 如果一个客户端正在与一个副本读交互，之后这个副本故障了。客户端需要将读请求发送给另一个副本。这时，尽管客户端切换到了一个新的副本，FIFO客户端序列仍然有效。为什么？
>
> 这里工作的原理是，**每个Log条目都会被Leader打上zxid的标签**，这些标签就是Log对应的条目号。任何时候一个副本回复一个客户端的读请求，首先这个读请求是在Log的某个特定点执行的，其次回复里面会带上zxid，对应的就是Log中执行点的前一条Log条目号。**客户端会记住最高的zxid**，当客户端发出一个请求到一个相同或者不同的副本时，它会在它的请求中带上这个最高的zxid。这样，其他的**副本就知道，应该至少在Log中这个点或者之后执行这个读请求**。这里有个有趣的场景，如果第二个副本并没有最新的Log，当它从客户端收到一个请求，客户端说，上一次我的读请求在其他副本Log的这个位置执行。那么**在获取到对应这个位置的Log之前，这个副本不能响应客户端请求。**要么副本阻塞了对于客户端的响应，要么副本拒绝了客户端的读请求并说：我并不了解这些信息，去问问其他的副本，或者过会再来问我。（很像阻塞/非阻塞IO）

**FIFO客户端请求序列是对一个客户端的所有读请求，写请求生效**。所以，如果我发送一个写请求给Leader，在Leader  commit这个请求之前需要消耗一些时间，所以我现在给Leader发了一个写请求，而Leader还没有处理完它，或者commit它。之后，我发送了一个读请求给某个副本。这个读请求需要暂缓一下，以确保FIFO客户端请求序列。读请求需要暂缓，直到这个副本发现之前的写请求已经执行了。这是FIFO客户端请求序列的必然结果，（对于某个特定的客户端）读写请求是线性一致的。

这里还需要提一下`sync(path)`操作，它是指等待在`sync`操作前的所有写操作，本质上是写请求。是一个弥补非线性一致的方法。一般场景是这样的：客户端先发送`sync`再做读请求，那么副本会先sync请求后，再返回读请求。这个读请求可以保证看到sync对应的状态，所以可以合理的认为是最新的。

### 就绪文件

> https://zhuanlan.zhihu.com/p/215451863

我们假设有另外一个分布式系统，这个分布式有一个Master节点，而Master节点在Zookeeper中维护了一个配置，这个配置对应了一些file（也就是znode）。在这里我们需要一种原子效果的更新。因为只有这样，其他的客户端才能读出完整更新的配置，而不是读出更新了一半的配置。这是人们使用Zookeeper管理配置文件时的一个经典场景。那么原子更新是如何实现？

如果就绪文件**Ready file**存在，那么允许读这个配置。如果Ready file不存在，那么说明配置正在更新过程中，我们不应该读取配置。如果Master要更新配置，那么第一件事情是删除Ready file。之后它会更新各个保存了配置的Zookeeper  file（也就是znode），这里或许有很多的file。当所有组成配置的file都更新完成之后，Master会再次创建Ready file。为了确保这里的执行顺序，Master以某种方式为这些请求打上了tag，表明了对于这些写请求期望的执行顺序。之后Zookeeper Leader需要按照这个顺序将这些写请求加到多副本的Log中。

![ready-file](/static/image/2021-12-26/ready-file.jpeg)

所以，如果客户端看见了Ready file，那么副本接下来执行的读请求，会在Ready  file重新创建的位置之后执行。这意味着，Zookeeper可以保证这些读请求看到之前对于配置的全部更新。所以，尽管Zookeeper不是完全的线性一致，但是由于写请求是线性一致的，并且读请求是随着时间在Log中单调向前的，我们还是可以得到合理的结果。

![exists-before-ready](/static/image/2021-12-27/exists-before-ready.jpeg)

这里可能有的问题是，客户端可能会在这个就绪文件存在时，通过调用exist来判断Ready file是否存在。之后，随着时间的推移，客户端读取了组成配置的第一个file，但是，之后在读取第二个file时，Master可能正在更新配置。这样导致客户端读到的是一个不正常的，由旧配置的f1和新配置的f2组成的配置。

但实际上，客户端`exists`不仅会查询Ready file是否存在，还会建立一个针对这个Ready file的watch。客户端在请求`exists(path, watch=true)`后，当副本读到path相关的操作后，首先发送消息通知客户端。所以，`delete`操作会优先于任何写操作到达副本上，任何读操作会在这里被放弃。

> - 关于watch的原理
>
> 假设某个客户端与副本在交互，客户端发送了一个exist请求。相应的副本会生成一个watch的表单，表明哪些客户端watch了哪些file。如果收到了一个删除Ready file的请求，副本会查看watch表单，并且发现针对这个Ready file有一个watch。watch表单或许是以file名的hash作为key，这样方便查找。

### API

Zookeeper的API能够解决什么样的事情？

- Test-and-Set
- 集群通用配置信息：比如发布Master的地址
- 选举Master
- 服务注册

它的API中定位结构类似znode组成的树，znode会有三种类型

- Regular znode：永久的znode，除非删除掉。
- Ephemeral znode：短暂/会话znode，当会话结束时撤销。
- Sequentail znode：顺序znode，在实际创建时会在名字后添加序号。当有多个客户端创建同一个名字znode时，ZooKeeper保证没有命名冲突。

API包括3个写操作和3个读操作，详情可见论文2.2。下面是一些需要注意的地方：

- `create`是排他的操作，当多个客户端创建同一个名字znode时，保证只有一个客户端能受到创建成功的消息，其他客户端会受到失败消息。
- 所有写操作都带有`version`信息（`create`默认0），所以都是基于key级别的原子CAS操作模式。几乎所有读操作都有`watch`选项（除了`list`），当客户端受到文件变动时，需要做同步操作。（？）

这种API可以实现一系列有用的模式：

- 自旋锁：原子CAS提供的getData+setData
  - 需要注意的是这个方式针对客户端数量是`O(n^2)`的。如100个客户端同时请求修改，那么一共需要`n^2`的通信次数
  - 高负载的情况需要合理的等待机制。如raft中的随机等待时间，这时在处理未知数量客户端的合理方式。或者直接用下面的lock。
- 非扩展锁：利用`create(ephemeral=true)`和`exist(watch=true)`。当create成功则获得锁，不成功则exist监听删除变动做等待
  - 注意一定要用会话级别的znode文件。防止客户端宕机不释放锁。
  - 在`create`和`exist`之间如果锁已释放，那么不需要做watch等待，只需要判断exist



## Lecture 9 - Chain Replication with Apportioned Queries(2009)：另一种读写强一致复制方法

> - http://nil.lcs.mit.edu/6.824/2020/papers/craq.pdf

CRAQ采用的方式与Zookeeper非常相似，它通过将读请求分发到任意副本去执行，来提升读请求的吞吐量，所以副本的数量与读请求性能成正比。CRAQ有意思的地方在于，它在任意副本上执行读请求的前提下，还可以保证线性一致性（Linearizability）。

提醒：CR & CRAQ的目的是提升吞吐量。二者在响应时延的节点扩展性上，与Raft类算法相比显然会差不少。

### Chain Replication

在链式复制中，存在多个副本节点首尾链接，可以认为是节点的链表。对于写请求而言，顺序的从head处理完毕后再到tail，最终返回给客户端写请求的响应。对应读请求，则客户端应请求tail节点由它直接响应。

在没有故障时，从一致性的角度来说，整个系统就像只有TAIL一台服务器一样，TAIL可以看到所有的写请求，也可以看到所有的读请求，它一次只处理一个请求，读请求可以看到最新写入的数据。

![chain-replication](/static/image/2022-01-06/chain-replication.png)

**故障恢复**

关于故障回复，链复制则非常简单。当写请求到达Head但Head故障后，那么下一个节点则成为新的Head；当写请求到达Tail但Tail故障后，则前一个节点则充当Tail。当写请求到达中间节点时，故障节点将被去除，前一节点将传递一些最新的写请求给新后继节点。

注意：

- 单独的链复制方案很难解决脑裂：Head与下一个节点的网络通信断开，那么二者都会认为自己是Head让客户端发送写请求给自己。所以一般而言会存在Configuration Manager来作为外部权威机构，来检测节点活性从而更新链的配置。（CM认为挂掉的节点，无论它是否真的宕机，只要所有节点都有共识那么就是有效的，因为脑裂被单点解决了。加入第二个节点宕机，那么HEAD需要不停的尝试重发请求。**节点自己不允许决定其他节点的死活**。）
- 但是，如果某两个相邻节点间网络不能通信，那么Configuration Manager的信息会导致两者不停重发请求。这里就需要Configuration manager来考虑节点间的通信情况。

对比Raft类算法，Chain Replication有这些差异：

- 链复制的网络瓶颈会比Raft更高。Raft中Leader负责给所有Folliower发送AppendEntries，而链复制中每个节点只会与下一个节点做交互。
- 读写负载会落在不同节点上。（可能会有更高的吞吐量）Head只会处理写请求，而只有Tail能处理读请求。
- 更简单的故障恢复。
- （更慢的写请求处理时间。）实际上Raft除了要2倍RTT的处理时长外，还要有更复杂的选主、恢复节点等的延时。如果考虑更高的写性能，你可以用更短的链来做复制。
- （存在队头阻塞问题。）当某一个节点运行缓慢时，链复制会消耗更多的时间与Raft。因为Raft可以多数通过commit。Raft在抵御短暂的慢响应方面表现的更好。

带有Configuration Manager的Chain Replication架构极其常见，这是正确使用Chain Replication和CRAQ的方式。在这种架构下，像Chain  Replication一样的系统不用担心网络分区和脑裂，进而可以使用类似于Chain  Replication的方案来构建非常高速且有效的复制系统。比如在上图中，我们可以对数据分片（Sharding），每一个分片都是一个链。其中的每一个链都可以构建成极其高效的结构来存储你的数据，进而可以同时处理大量的读写请求。同时，我们也不用太担心网络分区的问题，因为它被一个可靠的，非脑裂的Configuration Manager所管理。

### Chian Replication with Apportioned Queries

![chain-replication-with-apportioned-queries](/static/image/2022-01-06/chain-replication-with-apportioned-queries.png)

与CR相比，CRAQ使得每个节点都能处理读请求。他们的做法如下：

1. 所有节点都带有一个存储对象的版本，和版本对应的可读状态。这里的可读状态是dirty / clean，具体指这条记录是否被committed
2. 当一个节点收到写请求后，立即将数据以新版本号存储。
   - 如果该节点是Tail，那么设置状态为干净，并响应客户端。同时Tail节点会通知前面的节点更新干净状态。（具体是链式通知，还是并发通知论文2.3并没有说。我认为是链式通知，否则会引入Tail的通知瓶颈）
   - 如果不是Tail，那么设置为脏状态，转发请求给后继节点。
3. 当一个节点受到读请求后，如果最新版本是干净的，那么立马回复最新版数据；如果是脏的，那么请求Tail节点询问对应数据的最新版本号，再回复对应版本数据。
4. 当节点收到Tail的状态通知后，更新对应版本为干净状态，并删除前面的所有版本的数据。

注意：在CRAQ中，读写仍然是强一致性的。写请求返回后的读写请求一定会感知到新的数据。



## Lecture 10 - Aurora(2017)：变种Qourum的容错能力、只接受Log的块存储服务、带缓存的只读副本

> - http://nil.lcs.mit.edu/6.824/2020/papers/aurora.pdf
> - https://zhuanlan.zhihu.com/p/232345104

### 架构演变

在MySQL基础上，结合Amazon自己的基础设施，Amazon为其云用户开发了改进版的数据库，叫做RDS。对于RDS来说，有且仅有一个EC2实例作为数据库。这个数据库将它的data page和WAL  Log存储在EBS，而不是对应服务器的本地硬盘。当数据库执行了写Log或者写page操作时，这些写请求实际上通过网络发送到了EBS服务器。所有这些服务器都在一个AZ中。下面是MySQL镜像方案的架构：

![mirrored-mysql](/static/image/2022-01-09/mirrored-mysql.png)

每一次写操作，例如数据库追加日志或者写磁盘的page，数据除了发送给AZ1的两个EBS副本之外（EBS通过Chain Replication机制交互），还需要通过网络发送到位于AZ2的副数据库。副数据库接下来会将数据再发送给AZ2的两个独立的EBS副本。之后，AZ2的副数据库会将写入成功的回复返回给AZ1的主数据库，主数据库看到这个回复之后，才会认为写操作完成了。

但如论文中表1所示，RDS的写操作代价极高，就如你所预期的一样高，因为需要写大量的数据。即使如之前的例子，执行类似于  x+10，y-10，这样的操作，虽然看起来就是修改两个整数，每个整数或许只有8字节或者16字节，但是对于data  page的读写，极有可能会比10多个字节大得多。因为每一个page会有8k字节，或者16k字节，或者是一些由文件系统或者磁盘块决定的相对较大的数字。这意味着，哪怕是只写入这两个数字，当需要更新data page时，需要向磁盘写入多得多的数据。如果使用本地的磁盘，明显会快得多。

接下来介绍Aurora的解决方案：

![aurora](/static/image/2022-01-09/aurora.png)

1. 现在替代EBS的位置，有6个数据的副本，位于3个AZ，每个AZ有2个副本。所以现在有了超级容错性，并且每个写请求都需要以某种方式发送给这6个副本。
   - 数据库服务发送给存储服务的数据只有Log，而非data page等大数据。这节约了相当多的带宽用量。
   - Aurora抛弃了Chain Replication，它并不需要6个副本都确认了写入才能继续执行操作。这里是一个变种的Quorum，具体而言是Write Quorum为4、Read Qourum为。那么只要4个副本写入成功，数据库就可以继续执行操作。
2. 存储服务器内存最终存储的还是数据库服务器磁盘中的page。
   - 当一个新的写请求到达时，新的Log条目，它会立即被追加到影响到的page的Log列表中。
   - 当读请求到来时，才立即执行这个Log，来更新EBS本地的data page。
3. Aurora不仅有可读写的主数据库实例，同时还有多个数据库的只读副本。
   - 只能支持一个写入者的原因是，Log需要按照数字编号。如果有多个数据库以非协同的方式处理写请求，那么为Log编号将会非常非常难。
   - 当向只读数据库发送读请求后，只读数据库需要弄清需要查询哪些data page，之后直接从存储服务器读取，同时会缓存读取到的page。
   - 只读数据库也需要更新自身的缓存，所以主数据库也会将它的Log的拷贝发送给每一个只读数据库。只读数据库用这些Log来更新它们缓存的page数据，进而获得数据库中最新的事务处理结果。（这意味着只读数据库会落后主数据库一点，通常来说不会是一个大问题。）（对只读服务器而言，是否是最终一致性呢？只读数据库是否应该作为Read Qourum或者是N的一员？）
   - 数据库背后的B-Tree结构非常复杂，可能会定期触发rebalance。中间状态的数据是不正确的，只有在rebalance结束了才可以从B-Tree读取数据。但是只读数据库直接从存储服务器读取数据库的page，它可能会看到在rebalance过程中的B-Tree。这时看到的数据是非法的，会导致只读数据库崩溃或者行为异常。

这里再提一下Aurora的容错目标：

- 对于写操作。如果只有一个AZ挂了，那么写操作不受影响。
- 对于读操作。当一个AZ加上另一个处于其他AZ的服务器挂了之后（即AZ+1台服务器），读操作不受影响。
- 容忍暂时的慢副本。Aurora期望能够在出现短暂的慢副本时，不像Chain Replication那样阻塞，而是仍然能够继续执行操作。
- 如果一个副本挂了，备份数据是争分夺秒的。通常来说服务器故障不是独立的，如果一个服务器挂了，通常意味着有很大的可能另一个服务器也会挂，因为它们有相同的硬件，或许从同一个公司购买，来自于同一个生产线。如果其中一个有缺陷，非常有可能会在另一个服务器中也会有相同的缺陷。所以，当出现一个故障时，第二个故障可能很快就会发生。对于Aurora的Quorum系统，有点类似于Raft，你**只能从局部故障中恢复**。所以这里需要快速生成新的副本（Fast Re-replication）。期望能够尽可能快的根据剩下的副本，生成一个新的副本。

接下来，Aurora的变种Qourum会很有用。

### Qourum Replication

Aurora使用的是一种经典quorum思想的变种。Quorum系统背后的思想是通过复制构建容错的存储系统，并确保即使有一些副本故障了，读请求还是能看到最近的写请求的数据。

假设有N个副本。为了能够执行写请求，必须要确保写操作被W个副本确认，W小于N。所以你需要将写请求发送到这W个副本。如果要执行读请求，那么至少需要从R个副本得到所读取的信息。这里的W对应的数字称为Write Quorum，R对应的数字称为Read Quorum。这是一个典型的Quorum配置。这里的关键点在于，W、R、N之间的关联。Quorum系统要求，任意你要发送写请求的W个服务器，必须与任意接收读请求的R个服务器有重叠。这意味着，R加上W必须大于N（ 至少满足R + W = N + 1 ），这样任意W个服务器至少与任意R个服务器有一个重合。

这里还有一个关键的点，客户端读请求可能会得到R个不同的结果。现在的问题是，客户端如何知道从R个服务器得到的R个结果中，哪一个是正确的呢？**通过不同结果出现的次数来投票（Vote）在这是不起作用的**，因为我们只能确保Read Quorum必须至少与Write  Quorum有一个服务器是重合的，这意味着客户端向R个服务器发送读请求，**可能只有一个服务器返回了正确的结果**。对于一个有6个副本的系统，可能Read  Quorum是4，那么你可能得到了4个回复，但是只有一个与之前写请求重合的服务器能将正确的结果返回，所以这里不能使用投票。在Quorum系统中使用的是**版本号**（Version）。所以，每一次执行写请求，你需要将新的数值与一个增加的版本号绑定。之后，客户端发送读请求，从Read Quorum得到了一些回复，客户端可以直接使用其中的最高版本号的数值。

如果你不能与Quorum数量的服务器通信，不管是Read Quorum还是Write Quorum，那么你只能不停的重试。

Aurora采用的变种Qourum是指N=6，W=4，R=3。它能够实现上一节描述的Aurora的容错目标：

- 对于写操作。W等于4意味着，当一个AZ彻底下线时，剩下2个AZ中的4个服务器仍然能完成写请求。
- 对于读操作。R等于3意味着，当一个AZ和一个其他AZ的服务器下线时，剩下的3个服务器仍然可以完成读请求。
- 对于慢副本。Quorum系统本身可以剔除暂时的慢副本。
- 对于快速生成副本。当3个服务器下线了，系统仍然支持读请求，但是却不能支持写请求。所以当3个服务器挂了，变种Quorum系统有足够的服务器支持读请求，并据此重建更多的副本，但是在新的副本创建出来替代旧的副本之前，系统不能支持写请求。

## Lecture 11 - Frangipani：缓存一致性 & 原子更新 & WAL故障恢复

> - http://nil.lcs.mit.edu/6.824/2020/papers/thekkath-frangipani.pdf
> - https://timilearning.com/posts/mit-6.824/lecture-11-cache-consistency-frangipani
> - http://nil.lcs.mit.edu/6.824/2020/papers/frangipani-faq.txt

Frangipani是一个分布式网络文件存储的客户端，它在系统内核中实现了文件系统。对应的，Petal作为它的服务端，是共享虚拟磁盘服务。Petal包含文件系统的数据结构，例如文件内容、inode、目录、目录的文件列表、inode 和块的空闲状态。

![frangipani-layering](/static/image/2022-01-10/frangipani-layering.png)

这个系统在工作站（或者说系统中）里面做了大量的缓存，并且文件的修改可以在本地缓存完成。因为这样数据可以在微秒级别读出来，而不是毫秒级别的从文件服务器获取它们。注意这里的缓存是支持Write-Back的。

（缓存有两种：Write-Direct在数据更新时同时写cache和存储、Write-Back在数据替换出cache时更新存储）

在这个系统中，有三个主要的挑战：

- **缓存一致性**：当有人在大厅里说自己在文件系统里面做了修改，其他人应该能看到这个修改。缓存一致性，在这里我认为就是在缓存的系统中的读写强一致性。
- **原子性更新**：我们希望写操作不会与相同时间其他工作站的操作相互干扰。即使对于复杂的操作，涉及到修改很多状态，我们也希望这些操作表现的好像在一个时间点发生。
- **故障恢复**：由于 Write-Back 缓存，可能会在本地的缓存中堆积了大量的修改。如果我的工作站崩溃了，但是这时这些修改只有部分同步到了 Petal，还有部分仍然只存在于本地。不管如何，其他客户端/应该看到一个一致的文件系统，而不是一个损坏了的文件系统数据。

需要注意的是：

- 本论文是1997年发布的，所以硬件资源不高，而且它的目标是50人的小工作组。所以这不是分布式存储的主要应用场景。真正的应用场景是一些大型的数据中心、大型网站、大数据运算，在这些场景中，文件系统的接口相比数据库接口来说，就不是那么有用了。
- 而且，在大数据的场景下，缓存就显得累赘。如果你读取 10TB 的数据，缓存基本上没什么用，并且会适得其反。所以，随着时间的推移，Frangipani 在一些场合还是有用的，但是并不符合在设计新系统时候的需求。

### 缓存一致性 & 原子更新：锁服务

在 Frangipani 系统中还有第三类服务器：锁服务器。在锁服务器里面，有一个locks表单。我们假设对于每一个文件都有一个锁，它可能会被某个工作站所持有。同时，每个工作站都会记录跟踪它所持有的锁，和锁对应的文件内容。所以在每个工作站中，Frangipani 模块也会有一个 lock 表单，表单会记录文件名、对应的锁的状态和文件的缓存内容。

当一个 Frangipani 服务器决定要读取文件，比如读取目录 `/`、读取文件 `A`、查看一个 inode，首先，它会向一个锁服务器请求文件对应的锁，之后才会向 Petal 服务器请求文件或者目录的数据。收到数据之后，工作站会记住，本地有一个文件 X 的拷贝，对应的锁的状态，和相应的文件内容。

每一个工作站的锁至少有两种模式。工作站可以读或者写相应的文件或者目录的最新数据，可以在创建，删除，重命名文件的过程中，如果这样的话，我们认为锁在 Busy 状态。只要系统调用结束了，工作站会在内部释放锁，现在工作站不再使用那个文件。但是从锁服务器的角度来看，工作站仍然持有锁。工作站内部会标明，这是锁是 Idle 状态，它不再使用这个锁。

这里的锁在使用上有一些规则：

- 工作站不允许持有缓存的数据，除非同时也持有了与数据相关的锁。实际上，我认为这里的**锁是请求对某个文件的缓存能力**。仅当持有写锁时，客户端才有一份可写的数据缓存；同样，只有获得读锁才能有读的缓存。
- 释放锁之前，应先向 Petal 存储系统写数据，再从客户端 lock 表单中删除锁和缓存。这里可以说释放缓存的能力，但在这之前需要将缓存写回。

下面介绍客户端与锁服务之间的缓存一致性协议 / 接口：

- Request。指客户端请求锁服务获得文件的锁。
- Grant。指锁服务授权客户端这个文件锁。注意这里Request和Grant是异步的，锁服务接受Request后会再请求其他客户端释放锁。
- Revoke。指锁服务请求客户端释放锁。
  - 如果工作站收到 Revoke 消息时，它还在使用锁（Busy状态）。那么直到它完成了相应的文件系统操作，才会放弃锁。
  - 如果是Idle状态，那么首先客户端要同步元数据的WAL到Petal，接着将文件数据写入Petal，最后再释放锁。
  - 工作站会每隔 30 秒会将所有修改了的缓存写回到 Petal 中
- Release。客户端根据锁的状态来放弃锁，是Revoke的响应。二者异步。

### 故障恢复：记录元数据的WAL、故障恢复代理人

Frangipani 与其他的系统一样，需要通过预写式日志WAL，实现故障可恢复的事务：（似乎原子性的逻辑(事务、分布式锁)都需要提供WAL来恢复）

- 当工作站向 Petal 写入任何数据之前，它会在自己的Petal Log列表中追加一个 Log 条目。此Log会描述整个的需要完成的操作。
- 只有当这个描述了完整操作的 Log 条目安全的存在于 Petal 之后，工作站才会开始向 Petal 发送数据。

所以如果工作站可以向 Petal 写入哪怕是一个数据，那么描述了整个操作、整个更新的 Log 条目必然已经存在于 Petal 中。

除了经典的WAL外，Frangipani还提到Petal的Log列表是一个环形空间，且每个Log都需要自增的序号（用于检测Log结尾）。同时每个Log还会描述每个操作，包括数据块号、版本号和一些数据。注意，Log 只包含了对于元数据的修改，比如说文件系统中的目录、inode、bitmap 的分配。Log 本身**不会包含需要写入文件的数据**。（所以故障恢复是不会恢复文件内容的，这与现代Unix文件系统缓存一样。引用见FAQ。）

Frangipani 总是会先将自身的 Log 先写入到 Petal。这意味着如果发生了故障，那么发生故障时可能会有这几种场景：

- 要么工作站正在向 Petal **写入 Log**，所以这个时候工作站必然还没有向 Petal 写入任何文件或者目录。
- 要么工作站正在向 Petal **写入修改的文件**，所以这个时候工作站必然已经写入了完整的 Log。

假设一个其他的工作站需要崩溃了的工作站所持有的一个锁，锁服务器会发出 Revoke 消息，但是锁服务器永远也不会从崩溃了的工作站收到 Release 消息。Frangipani 出于一些原因对锁使用了租约，当租约到期了，锁服务器会认定工作站已经崩溃了，之后它会初始化恢复过程。实际上，锁服务器会通知另一个还活着的工作站说：看，工作站 1 看起来崩溃了，请读取它的 Log，重新执行它最近的操作并确保这些操作完成了，在你完成之后通知我。

那么详细来谈故障场景：

- 当WAL未写入时崩溃。当其他代理人 WS2 执行恢复，查看崩溃了的工作站的 Log 时，发现里面没有任何信息，自然也就不会做任何操作。之后 WS2 会释放 WS1 所持有的锁。
- 当WAL部分写入时崩溃。执行恢复的工作站 WS2 会检查每个 Log 条目，并重新向 Petal 执行 WS1 的每一条 Log。当 WS2 执行完 WS1 存放在 Petal 中的 Log，它会通知锁服务器，之后锁服务器会释放 WS1。注意这里会检查Log完整性，存在校验和机制。
  - 这里说明在事务层面故障回复不是原子性的，或者说针对每个文件是原子性的。
- 当块数据写入时崩溃。执行恢复的工作站 WS2 并不知道 WS1 在哪个位置崩溃的，它只能看到一些 Log 条目。所以WS2 会以相同的方式重新执行 Log。尽管部分修改已经写入了 Petal，WS2 会重新执行修改。（这里是怎么知道要从哪个操作开始执行恢复？应该是每次释放锁只有一个Log，它包含了所有操作，也就是为什么需要递增序号）

这里有一个时序的例子能够说明当前的方法还有缺陷：

```
WS1:   delete(/a)                 CRASH
WS2:                create(/a)
WS3:                                        RECOVER
```

当WS3恢复WS1的WAL时，不能直接执行delete操作，因为对应文件已经不是原有的文件了。所以我们不能只是不经思考的重新执行 WS1 的 Log，WS1 的 Log 在我们执行的时候可能已经过时了，其他的一些工作站可能已经以其他的方式修改了相同的数据，所以我们不能盲目的重新执行 Log 条目。Frangipani 是这样解决这个问题的，通过对每一份存储在 Petal 文件系统**块数据增加一个版本号**，同时将**版本号与 Log 中描述的更新关联**起来。如果一个工作站没有故障，并且成功的将数据写回到了 Petal。这样元数据的版本号会大于等于 Log 条目中的版本号。如果有其他的工作站之后修改了同一份元数据，版本号会更高。

## Lecture 12 - Pessimistic Distributed Transaction

事务的特性被总结为ACID，而这里要谈到的分布式事务会谈到其中两部分：第一个是并发控制（隔离性）第二个是原子提交。

### 悲观并发控制：两段锁

首先先提一下可串行化：并行的执行一些事物得到的结果，与按照某种串行的顺序来执行这些事务，可以得到相同的结果。实际的执行过程或许会有大量的并行处理，但是这里**要求得到的结果与按照一次一个事务的串行执行结果是一样的**。比如对两个并发事务AB而言，可串行化的调度可以保证所有情况下，都有与下面两种情况完全相同的结果：

```
S1: {A1, A2, A3, B1, B2, B3}
S2: {B1, B2, B3, A1, A2, A3}
```

并发控制主要有两种策略：悲观并发控制和乐观并发控制。

- **悲观并发控制**：**在事务使用任何数据之前，它需要获得数据的锁**。如果一些其他的事务已经在使用这里的数据，锁会被它们持有，当前事务必须等待这些事务结束，之后当前事务才能获取到锁。在悲观系统中，**如果有锁冲突，就会造成延时等待**。所以这里需要为正确性而牺牲性能。
- **乐观并发控制**：不用担心其他的事务是否正在读写你要使用的数据，你直接继续执行你的读写操作，通常来说这些执行会在一些临时区域，**只有在事务最后的时候，再检查冲突**是不是有一些其他的事务干扰了你。如果有一些其他的事务在同一时间修改了你关心的数据，并造成了冲突，**那么你必须要 Abort 当前事务，并重试**。

所以悲观并发控制会专注于锁机制。两阶段锁是最常见的锁机制，它是指某个事务中对锁的操作分为连续的获取和释放：

- 在使用任何数据之前，在执行任何数据的读写之前，先获取锁。
- 事务必须持有任何已经获得的锁，直到事务提交或者 Abort，你不允许在事务的中间过程释放锁。

注意：

- 为什么需要在事务结束前一直持有锁？
  - 因为不这样做的话，会让事务之间互相影响，导致调度结果是非可串行化的。
- 两阶段锁会非常容易造成死锁，如 `T1{get(x), get(y)} T2{get(y), get(x)}`
  - 事务有各种各样的策略，包括了判断循环，超时来判断它们是不是陷入到死锁中。如果是的话，数据库会 Abort 其中一个事务，撤回它所有的操作，并表现的像这个事务从来没有发生一样。

### 原子提交：两阶段提交

在一个分布式环境中，数据被分割在多台机器上，如何构建数据库或存储系统以支持事务？具体来说，如何应付错误，甚至是由多台机器中的一台引起的部分错误。这种部分错误在分布式系统中很常见。所以，在分布式事务之外，我们也**要确保出现错误时，数据库仍然具有可序列化和原子性**。

原子提交协议有很多，其中一种是两阶段提交（Two-Phase Commit）。它是指需要执行的任务会以某种方式分包在多个服务器上，每个服务器需要完成任务的不同部分。所以不仅在分布式数据库中会出现它，其他领域的分布式系统也会有类似的机制。

两阶段提交中存在一种角色，事务协调者。他们接受客户端的事务，并将具体命令发送给各个事务参与者，最后由协调者来判断事务提交或回退。最终的结果是，要么每个参与者都提交了变动，要么都没有提交。所以2PC能够保证原子性操作的主要原因是，作为单独节点TC不会发出不一致的Commit/Abort消息。如果每个参与者自己决定事务提交，那么会有很多难以处理的不一致问题。

类似于两段锁，事务参与者会维护一个锁的表单，用来记录锁被哪个事务所持有。两阶段提交的完整过程如下：

1. 客户端发送一个事务给事务协调者TC。

2. 事务协调者生成TID，并将每条命令依次发送给参与者执行。

   1. 参与者根据TID和具体命令在某个粒度上上锁
   2. 参与者会在这里实际执行命令，并结果返回给事务协调者。

   - （如果命令间没有依赖关系，似乎可以通过并发来提升性能）

3. 当所有命令都被执行后，TC将发送Prepare消息给所有参与者，询问能否准备提交。

   1. 参与者在这里可以返回No来一票否决。于是TC将触发事务回退abort。
      - 否决的原因，比如它们因为这个事务会引起死锁，或许它们在故障重启后并完全忘记了这个事务。
   2. 持久化事务的修改、该TID的所有的锁、和事务的prepare状态。这会在故障恢复时起作用。
   3. 响应Yes给TC。**这说明无论是否存在任何外部意外事件，参与者保证可以提交该事务。**

4. 当所有参与者返回Yes后，那么TC先持久化事务信息，再发送Commit消息给所有参与者（**这说明无论是否存在任何外部意外事件，协调者保证可以提交该事务**）；或者事务被一票否决后，TC发送Abort给所有参与者来回退事务
   1. 参与者在这里持久化所有变更；或者根据Log回退事务
   2. 并在这里释放所有TID对应的锁
   3. 最后返回ACK作为响应
   4. 参与者在这里可以将TID对应的持久化日志删除
5. 当所有ACK被返回后（或者在abort事务后），TC将事务结果返回给客户端
   1. 这里TC可以在ACK之后，将TID对应的持久化信息删除。



**故障恢复**

对于参与者：

- 它可能在回复 Prepare 消息之前就崩溃了。
  - 那么它可以单方面的回复No来撤销事务

- 它可能在回复Prepare Yes消息之后崩溃。这说明无论是否存在任何外部意外事件，参与者保证都可以提交该事务。
  - 在回复 Prepare 之前，它必须确保记住当前事务的中间状态，记住所有要做的修改，记住事务持有的所有的锁，这些信息必须在磁盘上持久化存储。
  - 当它重启恢复时，通过查看自己的 Log，它可以发现自己正在一个事务的中间，并且对一个事务的 Prepare 消息回复了 Yes。
  - 当参与者最终收到了 Commit 而不是 Abort，那么通过读取 Log，参与者就知道如何完成它在事务中的那部分工作。
- 它可能在收到 Commit 之后崩溃了。
  - 参与者有可能在处理完 Commit 之后就崩溃了。但是这样的话，它就完成了修改，并将数据持久化存储在磁盘上了。这样的话，故障重启就不需要做任何事情，因为事务已经完成了。
  - 但因为TC没有收到 ACK，那么TC会再次发送 Commit 消息。当参与者重启之后，收到了 Commit 消息时，它可能已经将 Log 中的修改写入到自己的持久化存储中、释放了锁、并删除了有关事务的 Log。这里参与者可以记住事务的信息，但是这会消耗内存，所以实际上它会完全忘记已经在磁盘上持久化存储的事务的信息。那么**对于一个它不知道事务的 Commit 消息，参与者会简单的 ACK 这条消息。**

对于协调者：

- 如果事务协调者在发送 Commit 消息之前就崩溃。
  - 在重启后不需要任何操作，TC默认这个事务被撤回了。因为没有一个参与者会 Commit 事务。
  - 但参与者可以在自己的 Log 中看到事务，又从来没有收到 Commit 消息。那么事务的参与者会向事务协调者查询事务，**事务协调者会发现自己不认识这个事务，它必然是之前崩溃的时候 Abort 的事务，响应abort**即可。
- 协调者在发送完一个或者多个 Commit 消息之后崩溃。这里不允许TC忘记相关的事务，因为这里需要最终决定是否应该提交或回退事务。
  - 在发送任何 Commit 消息之前，它必须先将事务的信息持久化。
  - 当事务协调者故障重启时，对于执行了一半的事务，事务协调者会向所有的参与者重发 Commit 消息或者 Abort 消息，以防在崩溃前没有向参与者发送这些消息。这就是为什么参与者需要准备好接收重复的 Commit 消息的一个原因。

考虑网络问题：

- 事务协调者发送了 Prepare 消息，但是并没有收到所有的 Yes/No 消息
  - **重新发送一轮 Prepare 消息**。这表明自己没有收到全部的 Yes/No 回复。事务协调者可以持续不断的重发 Prepare 消息。但是如果其中一个参与者要关机很长时间，我们将会在持有锁的状态下一直等待。
  - **撤销事务**。如果一个崩溃了的参与者重启了，向事务协调者发消息说，我并没有收到来自你的有关事务 95 的消息，事务协调者会发现自己并不知道到事务 95 的存在，因为它在之前就 Abort 了这个事务并删除了有关这个事务的记录。这时，事务协调者会告诉参与者说，你也应该 Abort 这个事务。
- 如果参与者等待 Prepare 消息超时
  - **撤销事务**。如果事务协调者上线了，再次发送 **Prepare 消息，B 会说我不知道有关事务的任何事情并回复 No**。
- 如果参与者等待 Commit / Abort 消息超时
  - 或许TC在很久一段事件中断电，但其他事务在等待锁的释放。所以我们应该尽早的 Abort 事务，并释放锁。但参与者不允许 Abort 事务，它必须无限的等待 Commit 消息，这里通常称为 Block。
  - **Block行为是两阶段提交里非常重要的一个特性**。在特定的故障中，你会很容易的陷入到一个需要等待很长时间的场景中，因为参与者会一直持有锁，并阻塞其他的事务。所以各种2PC的变种会尽量让这部分尽可能轻量化，甚至对于一些变种的协议，对于一些特定的场景都不用等待。（这里可以让TC作为副本系统，降低宕机可能性）
- 如果TC没有受到所有的ACK
  - 它会假设丢包了并**重发 Commit 消息**。如果一个参与者收到了一个 Commit 消息，但是它并不知道对应的事务，因为它在之前回复 ACK 之后就忘记了这个事务，那么参与者会再次回复一个 ACK。（因为它之前已经完成对这个事务的 Commit 或者 Abort，然后选择忘记这个事务了）
  - （或许这里不需要接受ACK？必须接受，因为这能确保参与者接受到Commit信息）

### 总结

两阶段提交在大量的将数据分割在多个服务器上的分片数据库或者存储系统中都有使用。

两阶段提交有着极差的名声：因为**有多轮消息的存在，它非常的慢**；同时它**有大量的写磁盘**操作。

因此，你只会在一个小的环境中看到两阶段提交。你或许可以在银行内部的系统中看见两阶段提交，但是你不会在不同的银行之间转账看到它。**两阶段提交永远不会在物理分隔的不同组织之间被使用，因为它可能会陷入到 Block中**。你不会想将你的数据库的命运寄托在其他的数据库不在错误的时间崩溃，从而使得你的数据库被迫在很长一段时间持有锁。不过有很多2PC变种，试图解决性能问题。

**2PC与Raft**

你可以发现Raft与2PC很相似：有一个 Leader（事务协调者），将消息发送给 Follower（事务参与者），Leader 只能在收到了足够多 Follower 的回复之后才能继续执行。但注意2PC与Raft是本质上不同的协议：

- Raft 的意义在于，将数据复制到多个参与者得到高可用，即使部分参与的服务器故障了或者不可达，系统仍然能工作。Raft 能做到这一点是因为**所有的服务器都在做相同的事情**。
- 两阶段提交中，每个参与者都在做事务中的不同部分，**参与者完全没有在做相同的事情**。所有的参与者都必须完成自己那部分工作，这样事务才能结束，**所以这里需要等待所有的参与者。**

然而，是有可能结合这两种协议的。因为两阶段提交对于故障来说是非常脆弱的，在故障时它可以有正确的结果，但是不具备可用性。结合Raft提供的容错性，我们可以这样设计系统：

- 事务协调器会是一个复制的服务，包含了三个服务器，我们在这 3 个服务器上运行 Raft，其中一个服务器会被选为 Leader，它们会有复制的状态，它们有 Log 来帮助它们复制，我们只需要等待过半服务器响应就可以执行事务协调器的指令。事务协调器还是会执行两阶段提交里面的各个步骤，并将这些步骤记录在自己的 Raft 集群的 Log 中。
- 每个事务参与者也同样是一个 Raft 集群。最终，消息会在这些集群之间传递。

这说明我们可以结合两种思想来同时获得高可用和原子提交。
