# 计算机网络


## 基础


### Q：五层协议的体系结构分别是什么？每一层都有哪些协议？

> https://blog.csdn.net/cainv89/article/details/46885197

- **应用层**：应用层不仅要提供应用进程所需要的信息交换和远地操作，还要作为互相作用的应用进程的用户代理；
  - HTTP协议，FTP，SMTP协议，DNS协议

- **运输层**：任务是负责主机中两个进程间的通信；
  - TCP，UDP协议

- **网络层**：网络层负责的是分组选择合适的路由；
  - IP协议，RIP，OSPF路由协议

- **数据链路层**：将在网络层交下来的数据报组装成帧（frame)，两个相邻结点间的链路实现帧的传输；
  - PPP协议、以太网协议CSMA/CD

- **物理层**：透明地传输比特流。
  - 蓝牙、wifi、usb等




### Q：为何有MAC地址还要IP地址？

> https://www.zhihu.com/question/21546408/answer/149670503

核心思路是 IP 提供了子网划分的能力。

1. **简化路由计算**：随着网络中的设备逐渐增多，路由变得越来越困难了。IP协议可以把网络划分成很多个子网。在路由的时候，路由器可以把属于某个子网的数据发送给这个子网的网关，把子网看成一个整体来进行路由匹配。对于目的地在其他子网的数据包，路由器只需要让数据包到达那个子网即可，而剩下的工作就由子网内部解决了。
2. **降低存储空间**：如果我们只用 MAC 地址的话，我们会发现路由器需要记住每个 MAC 地址所在的子网是哪一个。而MAC地址一共有48位，每个路由器是不可能存储这些MAC地址到端口的映射的。



### Q：为何有IP地址还要MAC地址？

> https://www.zhihu.com/question/21546408/answer/149670503

IP地址是需要分配的，而MAC地址是硬件固有的。在分配 IP 地址的过程中，为链路层提供访问的能力，我们还需要用 MAC 地址来区分不同的设备。




## TCP



### Q：TCP特性？如何实现？

TCP 提供一种**面向连接的、可靠的**字节流服务

- **可靠传输**：TCP 使用校验和，ACK确认和重传机制来保证。（**乱序冗余**：TCP 使用累积确认保证数据的顺序不变和非重复）
- **流控机制**：TCP 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制



### Q：TCP和UDP的区别？

> - https://blog.csdn.net/xiaobangkuaipao/article/details/76793702
> - https://www.cnblogs.com/jingliming/p/4477264.html

|          | TCP                                          | UDP                                      |
| -------- | -------------------------------------------- | ---------------------------------------- |
| 面向连接 | 面向连接                                     | 无连接                                   |
| 可靠性   | 可靠                                         | 不可靠                                   |
| 传输模式 | 字节流传输                                   | 用户数据报                               |
| 传输效率 | 低                                           | 高                                       |
| 所需资源 | 高                                           | 低                                       |
| 场景     | 通信数据可靠（文件传输，邮件传输，远程登录） | 通信速度要求高的场景（域名转换，视频流） |



1、TCP面向连接；UDP是无连接的，即发送数据之前不需要建立连接

2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP尽最大努力交付，即不保证可靠交付

Tcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。

3、UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。

4.每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

5、TCP对系统资源要求较多，UDP对系统资源要求较少。




### Q：拥塞控制和流量控制都是什么，两者的区别？

> https://blog.csdn.net/ailunlee/article/details/53716367

**流量控制**

- 控制发送者的发送速度，避免发送过快，接收者来不及接收，导致分组丢失。
- 滑动窗口协议实现，动态的调整窗口大小，控制发送者发送速度。

**拥塞控制**

- 作用于网络，防止过多的数据注入到网络中，避免出现网络负载过大的情况。（TCP被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量）
- 慢启动、拥塞避免、拥塞发生和快速恢复调整拥塞窗口`cwnd`



### Q：[TODO] 拥塞控制和流量控制的具体过程？



### Q：谈谈TCP为什么要三次握手？为什么要四次挥手？

> - https://blog.csdn.net/zhaobudaofangxia/article/details/55260259
> - https://zhuanlan.zhihu.com/p/53374516
> - https://draveness.me/whys-the-design-tcp-three-way-handshake/

**三次握手**：(验证双方的收发能力正常)

    第一次。A跟B说，我要建立连接了			SYN 		(new SEQ)
    第二次。B跟A说，OK那我也建立连接			SYN + ACK 	(new SEQ)
    第三次。A跟B说，嗯，我知道了。			ACK

**第三次握手解决历史链接问题**：

- 如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求。如果在较差的网络中，发送方连续发送多次建立连接的请求，那么接收方只能选择接受或者拒绝请求，它并不清楚这一次请求是不是由于网络拥堵而早已过期的连接。
- 所以，TCP 选择使用三次握手来建立连接，接收方当收到请求时会将发送方发来的 SEQ+1 发送给对方，这时由发送方来判断`SEQ`是否是历史连接。并用`RST`或`ACK`回应。
- 使用三次握手和 RST 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的



**四次挥手**：（二四验证收到断开链接请求）

    第一次。A跟B说，我要断开连接了                         FIN
    第二次。B跟A说，好的我不再接收你的信息了                ACK
    第三次。B跟A说，我传给你的信息传完了,你可以关闭连接了    FIN
    第四次。A跟B说，好的我关闭连接了                       ACK



### Q：TIME_WAIT状态是什么？为什么需要2MSL来等待关闭？MSL、RTT和TTL的区别？

> - https://draveness.me/whys-the-design-tcp-time-wait/

TCP 协议中包含 11 种不同的状态，TCP 连接会根据发送或者接收到的消息转换状态。

使用 TCP 协议通信的双方会在关闭连接时触发 `TIME_WAIT` 状态，关闭连接的操作其实是告诉通信的另一方**自己没有需要发送的数据**，但是它仍然**保持了接收对方数据的能力**，一个常见的关闭连接过程如下：

1. 当客户端没有待发送的数据时，它会向服务端发送 `FIN` 消息，发送消息后会进入 `FIN_WAIT_1` 状态；
2. 服务端接收到客户端的 `FIN` 消息后，会进入 `CLOSE_WAIT` 状态并向客户端发送 `ACK` 消息，客户端接收到 `ACK` 消息时会进入 `FIN_WAIT_2` 状态；
3. 当服务端没有待发送的数据时，服务端会向客户端发送 `FIN` 消息；
4. 客户端接收到 `FIN` 消息后，会进入 `TIME_WAIT` 状态并向服务端发送 `ACK` 消息，服务端收到后会进入 `CLOSED` 状态；
5. 客户端等待**两个最大数据段生命周期**（Maximum segment lifetime，MSL）的时间后也会进入 `CLOSED` 状态；

从上述过程中，我们会发现 `TIME_WAIT` 仅在主动断开连接的一方出现，被动断开连接的一方会直接进入 `CLOSED` 状态，进入 `TIME_WAIT` 的客户端需要等待 2 MSL 才可以真正关闭连接。TCP 协议需要 `TIME_WAIT` 状态的原因和客户端需要等待两个 MSL 不能直接进入 `CLOSED` 状态的原因是一样的：

- **阻止延迟数据段**：防止对端关闭前发送的数据段，被被其他使用相同源地址、源端口、目的地址以及目的端口的 TCP 连接延迟接受；
  - 至于为什么是两倍，RFC文档中没有解释。一般认为这个报文段可能是自己发出的，然后对端接受并恢复，一共两倍。
- **保证连接关闭**：保证 TCP 连接的远程被正确关闭，即对端收到 `FIN` 对应的 `ACK` 消息；
  - 当服务端还没有收到 ACK 消息时，客户端的新链接发送 SYN 消息请求握手时会收到服务端的 RST 消息，连接建立的过程就会被终止。
  - 如果客户端等待 2 MSL 的时间，那么无论服务端有没有受到`ACK`（如果没受到服务器重发`FIN`，这会在2MSL时间内），客户端都可以关闭或响应。

**MSL、RTT和TTL的区别**

- **MSL**：Maximum Segment Lifetime，任何TCP报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
  - RFC793不严谨地定义它为两分钟长，早期Linux就定义它为60秒。
- **TTL**：Time To Live，存储了一个ip数据报可以经过的最大路由数。
- **RTT**：Round-Trip Time，TCP数据段往返时间，一些算法可以动态估计它。



### Q：播放视频用TCP还是UDP？为什么？

TCP 和 UDP 是质量和实时性的权衡。
拿视频网站来说，你完全可以缓冲 20s 再播放，不会带来什么影响，但如果画面有马赛克之类的东西出现肯定是不好的，所以用 TCP。
而对于视频聊天，如果缓冲 5s，相信整个聊天已经没法愉快的进行了，而这时出现一些画面质量的损失也可以被接受，所以用 UDP。



### Q：TCP KeepAlive

TCP KeepAlive 的基本原理是，隔一段时间**给连接对端**发送一个**探测包**，如果收到对方回应的 **ACK**，则认为连接还是存活的，在超过一定重试次数之后还是没有收到对方的回应，则丢弃该 TCP 连接。

局限：

1. TCP KeepAlive 监测的方式是发送一个 probe 包，会给网络带来额外的流量
2. 只能在内核层级监测连接的存活与否，而连接的存活不一定代表服务的可用。



### Q：ACK攻击是什么

当主机在接收到ACK标志位的数据包的时候，需要检查该数据包所表示的**连接四元组**是否存在，检查该数据包所表示的**状态是否合法**，然后再向对应进程传递该数据包。当发包速率很大的时候，主机操作系统将耗费大量的精力接收报文、判断状态，同时要**主动回应RST报文**，正常的数据包就可能无法得到及时的处理。




## HTTP




### Q：HTTP报文格式？

> https://blog.csdn.net/holmofy/article/details/68492045

- **HTTP请求**：请求行、请求头、空白行、请求体
  - 请求行：Method + URI + Version（空格分隔）
- **HTTP响应**：响应行、响应头、空白行、响应体
  - 响应行：Version + Status + Description（空格分隔）




### Q：了解哪些响应状态码？

> - https://blog.csdn.net/oops_qu/article/details/75675702

| http状态返回代码 | 代码     | 说明                                                         |
| ---------------- | -------- | ------------------------------------------------------------ |
| **100**          | **继续**           | **请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。**                   |
| 101              | 切换协议           | 请求者已要求服务器切换协议，服务器已确认并准备切换。                                                        |
|                  |                    |                                                                                                             |
| **200**          | **成功**           | **服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。**                                           |
| 201              | 已创建             | 请求成功并且服务器创建了新的资源。                                                                          |
| 202              | 已接受             | 服务器已接受请求，但尚未处理。                                                                              |
| 203              | 非授权信息         | 服务器已成功处理了请求，但返回的信息可能来自另一来源。                                                      |
| **204**          | **无内容**         | **服务器成功处理了请求，但没有返回任何内容。在`OPTIONS`请求的响应中常见。**                                           |
| 205              | 重置内容           | 服务器成功处理了请求，但没有返回任何内容。                                                                  |
| 206              | 部分内容           | 服务器成功处理了部分 GET 请求。                                                                             |
|                  |                    |                                                                                                             |
| 300              | 多种选择           | 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 |
| **301**          | **永久移动**       | **请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。** |
| **302**          | **临时移动**       | **服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。**                        |
| 303              | 查看其他位置       | 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。                                   |
| **304**          | **未修改**         | **自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。**                             |
| 305              | 使用代理           | 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。                           |
| 307              | 临时重定向         | 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。                            |
|                  |                    |                                                                                                             |
| 400              | 错误请求           | 服务器不理解请求的语法。                                                                                    |
| **401**          | **未授权**         | **请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。**                                           |
| **403**          | **禁止**           | **服务器拒绝请求。**                                                                                        |
| 404              | 未找到             | 服务器找不到请求的网页。                                                                                    |
| **405**          | **方法禁用**       | **禁用请求中指定的方法。**                                                                                  |
| 406              | 不接受             | 无法使用请求的内容特性响应请求的网页。                                                                      |
| 407              | 需要代理授权       | 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。                                              |
| 408              | 请求超时           | 服务器等候请求时发生超时。                                                                                  |
| 409              | 冲突               | 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。                                         |
| 410              | 已删除             | 如果请求的资源已永久删除，服务器就会返回此响应。                                                            |
| 411              | 需要有效长度       | 服务器不接受不含有效内容长度标头字段的请求。                                                                |
| 412              | 未满足前提条件     | 服务器未满足请求者在请求中设置的其中一个前提条件。                                                          |
| 413              | 请求实体过大       | 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。                                                |
| 414              | 请求的 URI 过长    | 请求的 URI（通常为网址）过长，服务器无法处理。                                                              |
| 415              | 不支持的媒体类型   | 请求的格式不受请求页面的支持。                                                                              |
| 416              | 请求范围不符合要求 | 如果页面无法提供请求的范围，则服务器会返回此状态代码。                                                      |
| 417              | 未满足期望值       | 服务器未满足”期望”请求标头字段的要求。                                                                      |
|                  |                    |                                                                                                             |
| 500              | 服务器内部错误     | 服务器遇到错误，无法完成请求。                                                                              |
| 501              | 尚未实施           | 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。                               |
| **502**          | **错误网关**       | **服务器作为网关或代理，从上游服务器收到无效响应。**                                                        |
| **503**          | **服务不可用**     | **服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。**                                       |
| **504**          | **网关超时**       | **服务器作为网关或代理，但是没有及时从上游服务器收到请求。**                                                |
| 505              | HTTP 版本不受支持  | 服务器不支持请求中所用的 HTTP 协议版本。                                                                    |




### Q：GET和POST的区别？

> https://www.cnblogs.com/huaxingtianxia/p/5895236.html

GET在浏览器回退时是无害的，而POST会再次提交请求。
GET请求会被浏览器主动cache，而POST不会，除非手动设置。
GET请求只能进行url编码，而POST支持多种编码方式。
GET请求在URL中传送的参数是有长度限制的，而POST么有。
GET参数通过URL传递，POST放在body中。



注意`100 continue`在GET和POST上都可以存在，并没有限制HTTP方法。

100 Continue的目的是对，HTTP客户端希望在发送之前查看一下服务器是否会接受这个实体，这种情况进行优化。

如果客户端在向服务器发送一个实体，并愿意在发送实体之前等待100 Continue响应，那么客户端就要发送一个携带了值为100  Continue的Expect请求首部。如果客户端没有发送实体，就不应该发送100 Continue  Expect首部，因为这样会使服务器误以为客户端要发送一个实体。



### Q：HTTP1.0和1.1的区别？

> - https://blog.csdn.net/linsongbin1/article/details/54980801/
> - https://www.jianshu.com/p/7bfec28236c3

主要在于长连接、节约带宽和新的缓存策略。

- **长连接**：`connection: keep-alive`

  - HTTP1.1 支持长连接和流水线处理。但长连接中每个请求都是**串行**的，会产生队头阻塞问题。

- **节约带宽**

  - `range`头信息，可以向服务器请求数据的一部分。

  - `content-encoding`提供双方的编码方式，以便压缩信息。

  - `100 Continue`状态码：客户端在每个请求时首先发送header，服务器检查有效性，返回`100`或`4xx`状态码。

- **HOST域**

  - IP地址绑定一个HOST域名，每个IP可能绑定不同域名。

- **缓存策略**

  - 除了HTTP1.0 提供的`If-Modified-Since`和`Last-Modified`，HTTP1.1 又提供了`If-Unmodified-Since`。

  - `If-Modified-Since`: （若修改再下载）客户端尝试下载最新版本的文件，若修改则200，若未修改则304。

  - `If-Unmodified-Since`:（若未修改再下载） 断点续传(一般会指定Range参数)，若未修改则200，若修改则412。

- **错误通知**：更多的错误码



### Q：HTTP1.1和2.0的区别？

> https://segmentfault.com/a/1190000016975064

主要是二进制分帧和多路复用。

- **二进制分帧**

  - 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码

  - 通信都在一个TCP连接上完成，这个连接可以承载任意数量的双向数据流

- **多路复用**

  - 相比较与HTTP1.1的piplining，多路复用对请求提供了**并发**的能力，消除了队头阻塞问题。

- **头部数据压缩**

  - HTTP1.1对消息体进行gzip压缩，或本身就是压缩过的内容；对请求头和请求行明文传输。

  - HTTP2.0在基础上使用HPACK算法对头进行压缩。

- **服务器推送**

  - HTTP1.1对每个资源都做请求；HTTP2.0 引入服务器推送，允许服务器推送请求之外的内容。





### Q：在地址栏打入URL后会发生什么？

> https://github.com/skyline75489/what-happens-when-zh_CN

- **检查 HSTS 列表**

  - 浏览器检查自带的“预加载 HSTS（HTTP严格传输安全）”列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站
  - 其次在服务器返回的响应中，有一个特殊的头部，指示浏览器对于此网站，强制使用 HTTPS 进行访问<br>`Strict-Transport-Security: max-age=31536000; includeSubdomains; preload`
  - （注意SSL剥离攻击：中间人拦截此响应头，让用户在HTTP上做传输）


- **DNS 查询**

  - 浏览器检查域名是否在缓存当中；有则返回

  - 检查域名是否在本地 Hosts；有则返回

  - 进行ARP查询DNS(DNS在子网)或网关(DNS不在子网)的MAC，向 DNS 服务器发送一条 DNS 查询请求


- **ARP 过程**

  - 查询 ARP 缓存；有则返回

  - 查看路由表，选择接口发送ARP请求；如果下一个设备是：
    - 目标 / 路由器：返回ARP应答
    - 交换机：查MAC表，如果有结果则向端口发送；若无则向其他端口广播
    - 集线器：向其他端口广播


- **TCP 握手**
- **TLS 握手**
- **HTTP 协议**



### Q：DNS解析过程如何？

以下是迭代式：注意还有递归式

```
浏览器DNS缓存 -> 操作系统DNS缓存 -> 本地host文件 -> 本地DNS服务器
本地DNS服务器 -> 根DNS服务器
             -> 顶级DNS服务器
```



### Q：1.0短链接、1.1长连接&流水线、2.0多路复用的区别？

> - https://www.cnblogs.com/gotodsp/p/6366163.html
> - https://www.cnblogs.com/Paul-watermelon/p/10467662.html

- **短链接**：HTTP/1.0使用短连接。客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。客户端浏览器每遇到一个Web资源，浏览器就会重新建立一个HTTP会话(TCP连接)。
- **长连接**：HTTP/1.1默认使用长连接。`Connection:keep-alive`。当一个网页打开完成后，TCP连接不会关闭，客户端会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件中设定这个时间。**在下一个请求发出之前，必须响应TCP连接上的每个HTTP请求。**
- **流水线**：HTTP/1.1 Pipeline解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；**可以立即进行TCP链接上的每个HTTP请求，而无需等待先前请求的响应返回，回复将以相同顺序返回。**
- **多路复用**：HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；**可以立即进行TCP链接上的每个HTTP请求，而无需等待先前请求的响应返回，回复将以任意顺序返回。**




### Q：HTTPS原理及认证过程

> - https://hit-alibaba.github.io/interview/basic/network/HTTPS.html

**对称加密**

- 双方使用同一个密钥去加密和解密数据。
- 特点是速度快，适合于对大数据量进行加密。<br>缺点是密钥安全管理困难
- 常见的对称加密算法有DES、3DES、TDEA、Blowfish、RC5和IDEA。
- **明文 + 加密算法 + 私钥 => 密文**<br>**密文 + 解密算法 + 私钥 => 明文**

**非对称加密**

- 用公钥或私钥中的任何一个进行加密，用另一个进行解密。
- 私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。
- 花费时间长、速度慢。
- 在非对称加密中使用的主要算法有：RSA、Elgamal、Rabin、D-H、ECC等。
- **明文 + 加密算法 + 公钥 => 密文， 密文 + 解密算法 + 私钥 => 明文**<br>**明文 + 加密算法 + 私钥 => 密文， 密文 + 解密算法 + 公钥 => 明文**

**HTTP + TLS1.2 通信过程**

1. 客户端发送`Client Hello`：（协议版本、加密算法、压缩算法）、**客户端随机数**
2. 服务器返回`Server Hello`：（协议版本、加密算法、压缩算法）、证书公钥、证书链、**服务端随机数**等
3. 客户端进行`Change Cipher Spec`：
   - 证书验证，若验证失败则放弃后续访问。
   - 再次生成一个**随机字符串（premaster）**，并用非对称加密给服务器。这表明**通知服务器**后续消息都要用对称密钥加密。
   - （客户端可以根据三个随机数生成对话密钥，并且可以直接发送数据）
4. 服务器进行`Change Cipher Spec`：
   - 接受数据用非对称加密的密钥进行解密。
   - 拿到随机串后，根据三个随机数生成对话密钥，发送响应**通知客户端**之后的消息用对称密钥加密，完成TLS1.2握手。

**CA认证**

> CA机构（Certificate Authority）即颁发数字证书的机构。是电子交易、网络数据交流中权威的受信任的第三方机构，承担公钥体系中公钥的合法性检验的责任。

- 服务器的证书首先在CA机构中通过申请；客户端验证证书方法是向权威CA机构校验
- 证书验证的过程依赖于证书信任链，即一个证书要依靠上一级证书来证明自己是可信的，最顶层的证书被称为根证书，拥有根证书的机构被称为根 CA。根证书一般是操作系统自带的。



### Q：QUIC是什么？HTTP3.0是什么？

> - https://network.51cto.com/art/202009/625999.htm
> - https://zhuanlan.zhihu.com/p/32553477

Quic即快速UDP互联网连接，由 google 提出的使用 udp 进行多路并发传输的协议。

Quic 相比现在广泛应用的 http2+tcp+tls 协议有如下优势：

- **连接建立延时低** : 0RTT建立链接(曾有过链接) vs 4.5RTT链接 

- **改进的拥塞控制**

- **多路复用**：在一条 QUIC 连接上可以并发发送多个请求，互相之间没有依赖（类似HTTP2，但解决了它在TCP层面的队头阻塞）

- **加密认证的报文**

相当于QUIC包含了HTTP2.0多路复用、TLS安全加密、TCP拥塞控制。

HTTP3.0，也称作HTTP over QUIC，而QUIC是基于传输层UDP上的协议。即HTTP3.0 + QUIC + UDP

相当于QUIC包含了HTTP2.0多路复用、TLS安全加密、TCP拥塞控制。




### Q：为什么 HTTPS 需要 7 次握手以及 9 倍时延

> https://draveness.me/whys-the-design-https-latency/

(HTTPS 使用安全套接字层SSL保证数据传输的安全，随着传输层安全协议TLS的发展，目前我们已经使用 TLS 取代了废弃的 SSL 协议)

- TCP 协议 — 通信双方通过三次握手建立 TCP 连接；1.5 RTT；
- TLS 协议 — 通信双方通过四次握手建立 TLS 连接；2 RTT；
- HTTP 协议 — 客户端向服务端发送请求，服务端发回响应；1 RTT；

**TLS**

TLS 的作用是构建安全的传输通道（本身不提供可靠性保障）。在通信双方建立可靠的 TCP 连接之后，我们就需要通过 TLS 握手交换双方的密钥了。

TLS 握手的关键在于利用通信**双方生成的随机字符串**和**服务端的公钥**生成一个双方经过协商后的密钥，通信的双方可以使用这个**对称的密钥加密**消息防止**中间人**的监听和攻击，保证通信的安全。




### Q：Cookie / Session / Token 

> https://zhuanlan.zhihu.com/p/129227994

HTTP 协议是一种`无状态协议`，即每次服务端接收到客户端的请求时，都是一个全新的请求，服务器并不知道客户端的历史请求记录；Session 和 Cookie 的主要目的就是为了弥补 HTTP 的无状态特性。

- **Cookie**

  - 服务器发送到浏览器的 Cookie，浏览器会进行存储，并与下一个请求一起发送到服务器。

  - 响应头`Set-Cookie`，请求头`Cookie`工作原理。

- **Session**

  - 客户端请求服务端，服务端会为这次请求开辟一块`内存空间`，存储客户端在同一个会话期间的一些记录。

  - 服务器第一次返回响应时，带有`Set-Cookie：SESSIONID=XXXXXXX`；<br>客户端在本机客户端设置此Cookie，该 Cookie 的过期时间为浏览器会话结束；<br>客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息；<br>服务器每次读取请求头中的 Cookie 信息，获取SessionId，获得状态。

  - 负载均衡后，需要Session数据库提供一致性能力。

- **Token**

  - 服务器生成加密令牌，客户端请求带上Token，服务器校验。一般放在cookie里。

  - **无状态**：减轻服务器的压力，减少频繁的查询数据库




### Q：如何实现跨域？

- 图片ping & jsonp
- WebSocket
- CORS
- 其他



### Q：跨域资源共享 CORS 原理？

> http://www.ruanyifeng.com/blog/2016/04/cors.html

浏览器在异步请求资源时，自动添加一些附加的头信息。当响应到达后，在响应头中对实际情况和服务器的跨域配置做检查和匹配。如果不匹配那么拒绝这次响应，做`onError`回调。

实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。

浏览器将CORS请求分成两类：简单请求和非简单请求。

**基本流程**

1. 自动在头信息之中，添加一个`Origin`字段。说明请求来自哪个源（协议 + 域名 + 端口）。

   - 若为简单请求，则直接请求
   - 若为非简单请求，则发送`OPTION`方法，对`Access-Control-Allow-*`系列头部进行预检查，而后进行正常通信。检查方法同下文。

2. 服务器返回一个正常的HTTP回应。客户端检查是否存在`Access-Control-Allow-*`字段。

   - 若不存在，则浏览器的xml请求调用onerror回调

   - 若存在且与`Origin`相同，则正常返回


一些访问控制头：

- **Access-Control-Allow-Origin**：允许对应的Origin
- **Access-Control-Allow-Methods**：允许对应的Methods
- **Access-Control-Allow-Credentials**：是否允许带有Cookies
- **Access-Control-Expose-Headers**：允许包含的Header

# 操作系统


## 基础

### Q：什么是协程？与线程有什么区别？举一些例子？

> - https://github.com/LeoYang90/Golang-Internal-Notes/blob/master/Go%20%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96.md

协程是**一种程序运行的方式**，允许执行被挂起与被恢复。可以与它相比较的概念是子例程（即函数）：

- 协程可以通过让步`yield`，来调用或切换到其它协程上，当该协程再次被调用时将从`yield`处继续执行。
- 协程间是互相平等的关系。
- 多个协程之间的执行权，是由协程根据代码（调用或让步）自主分配，从而切换不同协程持有的函数栈。

协程的要点在于**执行权的唯一性和函数栈的自主切换**，它强调的是并发而非并行：

- 典型的协程是语言层级的构造，可看作一种形式的控制流；而线程是系统层级的构造，由操作系统和CPU来支撑并行。
- 所以，在协程之间的切换不应该涉及任何系统调用。

**JavaScript中的协程**

ES6 提供了一种半协程的实现，即Generator。协程有能力控制在它让位之后哪个协程立即接续它来执行，而生成器不能，它只能把控制权转交给调用生成器的调用者。如果是完全执行的协程，任何函数都可以让暂停的协程继续执行。

**Golang中的协程**

goroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多(M:N)的线程模型。

Go语言中支撑整个scheduler实现的主要有4个重要结构，分别是M、G、P、Sched。

- `M`指的是`Machine`，一个`M`直接关联了一个内核线程。由操作系统管理。
- `P`指的是`processor，代表了`M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接。
- `G`指的是`Goroutine`，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。

在程序启动时，创建N个线程执行schedule调度协程。调度首先从M个协程中寻找一个要执行的协程，运行该协程直到需要调度其它协程时才返回，保存协程状态回到调度第一步。具体而言：

- **对于线程**：在 Go 进程启动之后，干个物理线程进入调度函数，M从P取出（或工作窃取）可运行的协程执行，如果没有那么睡眠。

- **对于协程**：

  - **创建过程**：新创建的协程会先保存在本地队列或全局队列中。（本地满了去全局）等待被取出执行。
  - **网络调用 / 非阻塞调用**：当G执行之后，调度程序会将G保存上下文并切出M，M会继续循环寻找下一个。
    - 当 G 获得了想要的数据后，sysmon 线程会将 G 放入队列当中，等待着调度运行。
    - 注意：golang把socket的调用都封装成NONBLOCK，后面调用poll，runtime_pollWait

  - **系统调用**：当G发生了`syscall` 或阻塞操作。
    - 此时M物理线程大概率已经陷入内核，没有办法运行下一个G，这个系统调用只能占用一个物理线程。但是这个时候 M 实际上可能只是等待内核的 IO 数据，并不会占用 CPU。
    - 这时候，`sysmon`线程会检测到M已经阻塞，把这个线程M从P摘除，然后再创建一个新的线程尝试调度占用 CPU；
    - 当系统调用结束时候，这个 M 会尝试获取一个空闲的 P 执行。如果获取不到 P，那么这个线程 M 会 park 它自己(休眠)，加入到空闲线程中。



### Q：进程和线程的区别？

> - https://stackoverflow.com/questions/200469/what-is-the-difference-between-a-process-and-a-thread

最典型的差异是：线程是在共享存储空间中运行的，而进程在单独的存储空间中运行。

下面是一些OS原理上的区别：

- 进程是资源分配的最小单位，线程是CPU调度的最小单位。
- **开销**：
  - **创建或撤销**进程时，系统要为之分配或回收资源，如内存空间、I/O 设备等。
  - 在进行**进程切换**时，主要开销在与虚拟内存的切换（TLB之类的东西）；而同一进程中线程切换时，只需保存和设置少量寄存器内容。
- **通信**：线程间可以通过直接读写同一进程中的数据进行通信。但进程间相互独立，需要使用譬如管道，信号，消息队列，共享内存，套接字等通信机制。



### Q：进程如何管理？

> - https://segmentfault.com/a/1190000037765907

**进程控制块PCB**

PCB是进程存在的唯一标识，这意味一个进程一定会有对应的PCB：

- **进程管理信息**：进程ID、父进程ID、进程组、优先级、开始时间、使用CPU时间等
- **存储管理**：**虚拟内存信息**：页目录指针、代码段数据段起止指针、栈区堆区起止指针、命令行参数&环境变量起止指针
- **文件管理**：文件描述符等

**PCB如何组织**

- **线性表**
- **链表**：包含执行指针、就绪指针、阻塞指针
  - Linux使用双向链表组织PCB，且每个进程的PCB都存在内核空间。
- **索引**：包含执行指针、就绪指针、阻塞指针，每个指针指向一个索引表



### Q：进程的状态模型、切换过程和调度算法？

> - https://segmentfault.com/a/1190000037765907

**七状态模型**

- **状态类型**：新建、就绪、就绪挂起、运行、阻塞、阻塞挂起、终止
- **`就绪 -> 运行`**：当操作系统内存在着调度程序，当需要运行一个新进程时，调度程序选择一个就绪态的进程，让其进入运行态。
- **`运行 -> 就绪`**：运行态的进程，会占有CPU。每个进程会被分配一定的执行时间，当时间结束后，重新回到就绪态。
- **`运行 -> 阻塞`**：进程请求调用系统的某些服务，但是操作系统没法立即给它（比如这种服务可能要耗时初始化，比如I/O资源需要等待），那么它就会进入阻塞态。
- **`阻塞 -> 就绪`**：当等待结束了，就由阻塞态进入就绪态。
- **`运行 -> 终止`**：当进程表示自己已经完成了，它会被操作系统终止。
- **就绪挂起**：为了解决内存占用问题，可以将一部分内存中的进程交换到磁盘中，这些被交换到磁盘的进程，会进入挂起状态。
- **阻塞挂起**

**切换过程**

1. 保存CPU上下文环境：保存程序计数器和其他寄存器的值到当前进程的私有空间中
2. 更新PCB：主要包括状态更变
3. 将当前进程移到就绪队列或者阻塞队列
4. 根据调度算法，选择就绪队列中一个合适的新进程，将其PCB更改为运行态
5. 更新内存管理的数据结构
6. 新进程内对堆栈所保存的上下文信息载入到CPU的寄存器和程序计数器，占有CPU

**进程调度算法**

- **先来先服务**
- **短作业优先**：按照最短长度排队。
- **时间片轮转**：每一个进程会被分配一个时间片。时间片结束，会被抢占式到就绪队列。CPU切换至其他进程。
- **优先权调度算法**：按优先级排队，如果多个进程优先级相同，则按照先来先服务的方式依次执行。
  - Linux调度程序跟踪进程，动态周期性计算出优先级，依照优先级排队调度。
- **多级反馈队列**：基于时间片轮转和优先级调度。多个就绪队列，赋予每个就绪队列优先级，优先级越高的队列进程的时间片越短
  - 如果进程在一级队列取出并在时间盘中没有结束运行，那么进入下一个就绪队列。
  - 仅当第i级队列为空时，才调度第i+1级队列的进程
  - 当有一个更高优先级的进程进入，则会停下第i级的进程，让它回到第i级队列尾部，CPU转而执行更高优先级的进程



### Q：进程间通信？ 

> - https://segmentfault.com/a/1190000037765907

以 Unix/Linux 为例，介绍几种重要的进程间通信方式：

- **共享内存**：多个进程可以读写同一块内存区域。
  - Linux的实现：进程之间通过映射同一个普通文件实现共享内存，即`mmap`。

- **管道**：多个生产者，生产一些数据，将其放置到共享缓冲区中，由消费者从缓冲区中取走数据。
  - 缓冲区同一时间内只允许生产者或者消费者一方访问。
  - 当缓冲区满了，生产者添加数据阻塞；当缓冲区空了，消费者读取数据阻塞。
- **消息通信**
  - **直接通信**：sender直接发消息发给receiver，把消息挂在接收进程的消息队列中，接收进程从消息队列中获取消息
  - **间接通信**：消息不直接发送给接收者，而是发送到一个共享数据结构。该结构是一种消息队列，也称为信箱。通过进程ID收发消息。
- **信号量**：信号量本质是一个计数器，当多进程共享内存时，用于保护共享内存仅由N个进程使用。
- **信号**：是一种异步通信，进程需要为信号设置相应的监听处理。常用于一些异常情况下的进程间通信。




### Q：死锁的产生和避免? 

> https://www.cnblogs.com/fangrong/p/5271724.html

- **原因**：系统资源竞争、程序推进顺序非法

- 死锁产生的四个必要条件：

  - **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，必须等待直到该资源被释放为止。

  - **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。

  - **非抢占：**资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。

  - **循环等待：**有一组等待进程{P0，P1，P2，...，Pn}，P0等待的资源被P1占有，P1等待的资源被P2占有，Pn等待的资源被P0占有。

- 死锁解决方案：
  - **死锁预防**：在程序运行前阻止发生死锁。设置某些限制条件，破坏产生死锁的四个必要条件中的一个或几个。
  - **避免死锁**：在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。
    - 安全状态：能找到一个分配资源的序列能让所有进程都顺序完成。
    - 银行家算法：采用预分配策略检测分配完成时系统是否处在安全状态。
  - **死锁监测**：无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取措施解除死锁。
    - 死锁监测：化简资源分配图
    - 死锁解除：资源剥夺，撤销进程，进程回退



### Q：基本分页和请求分页如何管理内存？

**基本分页**

固定分区会产生内碎片，动态分区会产生外碎片；为了尽量避免内存碎片，提出基本分页存储。

它将主存空间分为固定相等的小块，作为主存的单元。进程在申请内存时，以页为单位进行请求。（进程中为页，内存中为页框，外存中为块。无外碎片，平均半个页的内碎片。）

- **页表**：
  - 便于寻找页面对应的物理块，系统在内存中为每个进程维护一些页表。
  - 实际上是物理块号的数组，其索引为页号。
- **基本地址变换机构**：
  - 逻辑地址结构： `| 页号 | 页内偏移量 |`
  - 计算页表中对应页号地址，取出块号拼接偏移量。
- **快表**
  - 具有并行查找能力的高速缓冲器，用于提升地址变换速度（减少一次查页表的访存）。
  - 实际上为`| 页号 | 块号 |`的数组
  - 在原有变换流程基础上，首先查找快表，取出块号拼接偏移量。
- **两级页表**
  - 为了压缩页表大小，不去存储无用的页表项，系统在内存中为每个进程维护一张二级页表。
  - 逻辑地址结构： `| 一级页号 | 二级页号 | 页内偏移量 |`
- **页面大小取舍**
  - 太小：页表过大（浪费内存），地址转换频繁（浪费时间）
  - 太大：内碎片过大（浪费内存）

**请求分页** 

虚拟内存的一种实现方式。虚存基于时空局部性，当内存暂时不使用时换出至外存。系统为用户提供了一个比物理空间大得多的虚拟空间，故称虚存。

只需一部分页面装入内存，程序即可运行。当需要访问不在内存中的页面时，通过**请求调页**功能调入，同时置换不用的页面至外存。

- **地址变换机构**：首先查找快表，（若不存在）再查找页表；查看页表是否已调入，**（若缺页）产生缺页中断，请求调页**。
  - **缺页中断机构**：CPU遇到缺页中断后，阻塞缺页进程；若进程内存中无空闲页框，则按**页面置换算法**淘汰某页，再调入目标页面。

- **页面置换算法**：LRU实现使用哈希表+双向链表，读写移动至表头，替换时删除表尾。
- **页表**：为了发现和处理请求页面时，页面是否存在和调出等问题，加入另外一些字段。（如访问位，修改位等）



### Q：页面置换算法？

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断请求调页。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法的主要目标是使页面置换频率最低：

- **最佳（OPT）**：所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

- **最近最久未使用（LRU）**：虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。
  - 当使用某个页时，将它放置在队头。当驱逐某个页时，排出队尾元素。

- **时钟算法（CLOCK）**：维护环形链。每个元素都有一个计数位。
  - 当使用一个页时，计数位设置为1。
  - 当驱逐某个页时，如果页面的位设置为1，设置为零；如果不是，则驱逐它。



### Q：什么是中断？什么是系统调用 ？

**中断（interrupt）**是指在计算机运行过程中，当发生某个事件后，CPU 会停止当前程序流，转而去处理该事件，并在处理完毕后继续执行原程序流。

- **外中断**：由外部设备（如：磁盘，网卡，键盘，时钟）产生，用来通知操作系统外设状态变化。
  1. **外设** 将中断请求发送给中断控制器；
  2. **中断控制器** 根据中断优先级，有序地将中断传递给 CPU；
  3. **CPU** 进行中断处理：
     - **关中断**
     - **保存断点**：将原来的程序的断点（即程序计数器PC）保存起来
     - **中断服务程序寻址**：取出中断服务程序的入口地址送入程序计数器PC
     - **保存现场**：程序状态字寄存器PSWR和某些通用寄存器的内容
     - **执行中断服务程序**：如何执行？切换进程PCB还是什么？
     - **恢复现场**
     - **开中断**
- **内中断**：源自CPU执行指令内部的事件，如程序的非法操作码、地址越界、算术溢出、虚存系统缺页及陷入指令等引起的事件。



### Q：CPU Cache的结构？写入方式？ CPU间缓存一致性？

> - [10 张图打开 CPU 缓存一致性的大门](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247486479&idx=1&sn=433a551c37a445d068ffbf8ac85f0346&chksm=f98e48a5cef9c1b3fadb691fee5ebe99eb29d83fd448595239ac8a2f755fa75cacaf8e4e8576&scene=21#wechat_redirect)

**CPU Cache的结构**

CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。

CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成。CacheLineSize被大多数操作系统和CPU定义为64B，从主存中加载数据到缓存一次加载一个缓存行。

**写入方式**

那在什么时机才把 Cache 中的数据写回到内存呢？

- **写直达（Write Through）**：写缓存的同时，写入主存。缓存没有脏数据。
- **写回（Write Back）**：当缓存行被驱逐时，写入主存。缓存有脏数据并能做脏标记，掉电数据丢失。
  - 常见的淘汰策略主要有LRU和Random两种。



### Q：CPU Cache如何解决缓存一致性问题？ 

> - [MESI - Intel 奔腾系列 CPU的缓存一致性协议](https://blog.csdn.net/vcj1009784814/article/details/106544494)

由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的缓存一致性的问题。如CPU0写入数据x后，CPU1读出发现数据没变。这是因为更新在缓存中，要解决这一问题，需要同步两个不同核心里面的缓存数据：

- **写传播**：某个 CPU 核心里的 Cache 数据更新时，必须要把写入事件传播到其他核心的 Cache。
  - 注意是写入事件，而不是CPU核心去读主存。这样就不会有下面串行化的问题了。
- **串行化**：某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的。
  - 防止CPU2和CPU3对CPU1和CPU0对同一个数据的操作顺序感知反了，导致2和3中cache数据不同。
  - 解决它需要某种并发控制保证顺序：如锁或乐观控制等。

针对以上问题，Intel奔腾系列使用了**总线嗅探（Bus Snooping）+MESI协议**，AMD使用了相似的协议。

- **总线嗅探**：当核心修改了L1 Cache变量，那么通过总线把写入事件广播给其他所有的核心，然后每个核心监听总线上的广播事件，把该数据更新到自己的L1 Cache。
  - **总线负载**：不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这会加重总线负载。
  - **不保证串行化**
- **MESI协议**：用状态机机制降低了总线带宽压力，同时做到缓存一致性。
  - 数据状态将根据事件做转换，这个过程中可能触发其他总线事件、同时缓存读入或写出到主存。
  - 该协议将事件约定为两种：本地CPU读写`PrRd / PrWr`，嗅探到的总线读写`BusRd / BusRdX`、总线写但本地包含这个数据`BusUpgr`、总线Flush`Flush / FlushOpt`。
  - 该协议对L1Cache约定了四种状态（以下省略了更新状态的步骤）：
    - **Modified已修改**：脏标记。
      - 本地自由读。远端读写时写入主存。
    - **Exclusive独占**：只有该CPU持有该数据。
      - 本地自由读写。与主存无交互。总线写会置`Invalidated`。
    - **Shared共享**：有多个CPU持有该数据。
      - 本地自由读。与主存无交互。总线写会置`Invalidated`。
    - **Invalidated已失效**：禁止使用，需要重新读主存。
      - 本地不可读。本地读写是需要读主存。



### Q：程序的装入和链接是什么？动态链接库与静态的区别？

> - https://blog.csdn.net/hguisu/article/details/5713099

将用户程序变为在内存中执行的进程，通常都要经过以下几个步骤：

- **编译**：编译器将代码编译成CPU可执行的目标代码，产生了若干个目标模块.o（机器码程序段）。
  - 目标代码中以0为基址顺序进行编址，在这里每条指令和操作数的地址统称为逻辑地址 。
- **链接**：链接器将目标模块（程序段），以及它们所需要的库函数链接在一起，形成装入模块.out。
  - 将模块链接起来，需要修改**模块程序段相对地址**，让总体在一个0~N的地址空间；将**调用逻辑变成跳转地址**。
  - **静态链接**：一次性链接所有模块，形成一个完整的可运行程序。其中模块线性排列。
    - **优缺点**：与环境无关，移植方便；浪费空间。
    - 静态链接库在此时起效。
  - **装入时动态链接**：在装入内存时边装入边链接。外部模块调用事件引起装入程序寻找并装入外部目标模块。
    - **优点 - 依赖更新**：若依赖库更新，那么用户只需要更新动态库即可增量更新。
    - 动态链接库在此起效。
  - **运行时动态链接**：在运行时需要模块时，才进行链接。
    - **优点 - 节省内存**：不仅可加快程序的装入过程，而且可节省大量的内存空间。如错误处理的模块，如果程序不出现错误则不会装入内存。
    - 动态链接库在此起效。
- **装入**：装入程序将装入模块装入物理内存。确定装入内存的实际物理地址，并修改程序中与逻辑地址，即**地址重定位**。
  - **绝对装入**：按照物理内存的位置，给逻辑地址赋予实际的物理地址。不支持虚存。
  - **静态地址重定位**
  - **动态地址重地位**



## Linux

### Q：Linux怎么创建一个进程？

1. **申请PCB**：分配PID，申请空白的PCB，若PCB申请失败，创建失败。
2. **分配资源**：为新进程的程序和数据及用户栈分配必要的内存空间。
3. **初始化PCB**：包括进程标识符，处理机状态（寄存器状态），进程调度信息（状态，优先级），进程控制信息（程序和数据的地址）。
4. **进入就绪队列**：如果就绪队列能够容纳新进程，则新进程插入就绪队列，等待调度执行。



### Q：Linux如何管理内核空间和用户空间？

> - https://blog.51cto.com/wushank/1406480
> - https://blog.51cto.com/liangchaoxi/4045975

![linux-memory-space-layout](/static/image/2022-03-02/linux-memory-space-layout.jpeg)

**物理地址空间布局**

- **`ZONE_DMA`**：专门供I/O设备的DMA使用。因为DMA使用物理地址访问内存，不经过MMU，并且需要连续的缓冲区。
- **`ZONE_NORMAL`**：内核能够直接使用的区域。
- **`ZONE_HIGHMEM`**：高端内存，内核不能直接使用。

**虚拟地址空间布局**

- **内核空间**：
  - `ZONE_ HIGHMEM`：用户数据、页表(PT)等不常用数据放在ZONE_ HIGHMEM里，只在要访问这些数据时才建立映射关系(kmap())。
  - `ZONE_NORMAL`：与内核线性空间存在直接映射关系，所以内核会将频繁使用的数据如kernel代码、GDT、IDT、PGD、mem_map数组等放在ZONE_NORMAL里。
  - `ZONE_DMA`

- **用户空间**：
  - 参数、全局环境变量
  - 栈区
  - `mmap`：将普通文件被映射到进程地址空间，进程可以像访问普通内存一样对文件进行访问，不必再调用read / write等操作。
    - 进程之间通过映射同一个普通文件实现共享内存。
  - 堆区
  - 未初始化数据区
  - 数据区
  - 代码区

**虚拟地址与物理地址的映射**

32位Linux将4G的线性地址空间分为2部分，0~3G为user space，3G~4G为kernel space。

- 物理空间中的`ZONE_DMA`和`ZONE_NORMAL`被线性映射到虚拟内核空间低地址区域，共896M。
- 其余空间都映射到`ZONE_HIGHMEM`中。



### Q：[TODO] waitqueue如何工作？回调和等待事件在哪里体现？



### Q：fork操作干了什么事？

`fork`会对父进程程序段、数据段、堆段以及栈段创建拷贝，以此创建新进程映像。大部分现代 UNIX 实现(包括 Linux)采用两种技术来避免拷贝：

- **代码段**：内核将每一进程的代码段标记为只读，那么父子进程可共享同一代码段。
  - 在为子进程创建代码段时，进程页表项均指向与父进程相同的物理内存页帧。
- **数据段、堆和栈**：写时复制。
- **文件**：子进程会获得父进程所有文件描述符的副本，对应的描述符均指向相同的打开文件句柄。



### Q：Futex是什么？原理如何？

> - https://www.cnblogs.com/muahao/p/9327728.html

Futex(Fast Userspace mutex)，是为了解决大部分场景下无竞争同步的Mutex，需要在获取和释放时进入内核检查竞争的大量开销问题。

Futex是一种用户态和内核态混合的同步机制：

- 首先，用户程序通过`mmap`做进程间共享内存，创建一个futex同步变量。也就是位于共享内存的一个整型计数器。
- **获取锁**：当前进程对futex原子性减1，并检查futex：
  - 如果同步变量`>=0`，则没有竞争发生， 进程照常执行。
  - 如果同步变量`<0`，则意味着有竞争发生，需要调用futex系统调用的`futex_wait`**休眠当前进程**。
- **释放锁**：当前进程对futex进行原子性加1，并检查futex：
  - 如果同步变量`>0`，则没有竞争发生，进程照常执行。
  - 如果同步变量`==0`，则意味着有竞争发生，需要调用futex系统调用的futex_wake操作唤醒一个或者多个等待进程。

这里的原子性加减通常是用CAS(Compare and Swap)完成的，与平台相关。



### Q：Linux IO模式 
> https://segmentfault.com/a/1190000003063859

**用户空间与内核空间**

操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。

对32位Linux而言，它的寻址空间（虚拟存储空间）为4G。Linux 将最高的1G字节，供内核使用，称为内核空间，而将较低的3G字节，供各个进程使用，称为用户空间。

在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据先被拷贝在文件系统的页缓存，然后才会拷贝到应用程序的地址空间。所以，对于一次IO访问：

1. 等待数据准备： 数据会先被拷贝到**操作系统内核的缓冲区**中
2. 拷贝到进程中：从操作系统内核的缓冲区拷贝到**应用程序的地址空间**。

正因这两个阶段，linux系统产生了下面五种网络模式的方案。

- **阻塞 IO**

  - 当用户进程调用 `recvfrom / read / write` 系统调用后，内核准备数据并拷贝至内核空间，直到内核将数据拷贝到用户空间，用户进程才退出阻塞状态。

  - 在两个过程中，用户进程是一直阻塞的。
  - 在linux中，默认socket都是BLOCKING。

- **非阻塞 IO**：可以让我们周期性地检查（轮询，poll）某个文件描述符上是否可执行从内核空间拷贝数据到用户空间。

  - 当用户进程调用 `recvfrom / read / write` 系统调用后，内核立即返回到用户进程，并后台准备数据拷贝至内核空间； 当内核在数据缓冲区中准备好数据时，用户进程再次调用`recvfrom`并阻塞，等待内核拷贝数据。
  - 用户第一个过程可不断调用IO，kernel不断返回error，直至第一个过程结束。  用户第二个过程调用后进程阻塞。
  - **注意**：本质是跳过内核准备数据阶段，它可以在`connect/accept/send/recv`中使用，返回的FD可以在`select / poll`做搭配。

  - 在linux中，socket可以设置为`O_NONBLOCK`

- **IO 多路复用**

  - 当用户进程调用 `select / poll` 系统调用后，对每个文件描述符：内核准备数据并拷贝至内核空间。当其中一个文件在内核空间准备就绪后，用户进程解除阻塞，选择文件描述符调用`read`让内核拷贝至用户空间。
  - 用户第一个过程阻塞，直至kernel结束第一过程，解除阻塞。用户第二个过程调用IO后阻塞。
  - **注意**：使用`O_NONBLOCK`，用户进程可以在第一步不阻塞，干别的事情。

  - **优点**：单进程可以同时处理多个网络连接IO。如果处理的连接数不是很高的话，使用多路复用IO不一定比使用多线程+阻塞IO性能更好。


- **异步 IO**
  - 当用户进程调用 aio_read 系统调用后，内核立即返回。并后台准备数据拷贝至内核空间和用户空间，完毕后向用户进程发送信号。
  - 两个过程皆不阻塞。

- **信号驱动IO**
  - 进程为通知信号绑定Handler函数，并设置监听的文件描述符属主。当 I/O 操作就绪时，内核为进程发送一个信号，然后调用信号处理函数。

由于非阻塞式I/O和多进线程都有各自的局限性，下列备选方案往往更可取：

- **I/O 多路复用**：允许进程同时检查多个文件描述符以找出它们中的任何一个是否可执行I/O 操作。
- **信号驱动 I/O**：是指当有输入或者数据可以写到指定的文件描述符上时，内核向请求数据的进程发送一个信号。进程可以处理其他的任务，当 I/O 操作可执行时通过接收信号来获得通知。当同时检查大量的文件描述符时，相比 select()和 poll()有显著的性能提升。
- **epoll**：允许进程同时检查多个文件描述符。当同时检查大量文件描述符时，能提供更好的性能。



### Q：select / poll / epoll？
> https://zhuanlan.zhihu.com/p/93609693

**select / poll**

在 Linux 内核层面，select和pol都使用了相同的内核poll函数。select的返回值等行为完全可以通过一些语言层面的转换成poll。

以下是系统调用select和poll之间的一些区别：

- **上限限制**：select的参数和返回值`fd_set`对于被检查的文件描述符数量有一个上限限制，poll没有限制。
- **重新初始化参数**：select的参数`fd_set`同时也保存返回值，如果重复调用的话，必须重新初始化它。而poll通过独立的两个字段来处理。
- **超时精度**：select()提供的超时精度（微秒）比 poll()提供的超时精度（毫秒）高。
- **FD关闭可感知**：如果被检查的文件描述符关闭了，poll()会准确告诉我们是哪一个文件描述符关闭了。与之相反，select()只会返回−1，并设错误码为EBADF。用户需要自行在描述符上I/O调用来检查错误码。



**epoll**

Linux 的 epoll（event poll）主要优点如下：

- 当检查大量的文件描述符时，epoll 的性能扩展性性比 select()和 poll()高很多。
- epoll API 既支持水平触发也支持边缘触发。与之相反，select()和 poll()只支持水平触发，而信号驱动 I/O 只支持边缘触发。

epoll的实现如下：

- 首先`epoll_create`创建一个epoll文件描述符，底层同时创建一个红黑树，和一个就绪链表。
  - 红黑树存储所监控的文件描述符的节点数据，就绪链表存储就绪的文件描述符的节点数据；
- `epoll_ctl`将会添加新的描述符，通过**红黑树判断文件描述符是否存在**。如果有，则立即返回。
  - 如果没有，在树上插入新的节点，并且**通过`waitqueue`告知内核注册回调函数**。
  - 每次 socket 状态变化，内核就可以**快速从红黑树查询**进程是否关心这个 socket，将该节点插入到就绪链表里面。
  - 再根据触发条件（LT和ET）判断是否出参。
- `epoll_wait`将会接收到消息，并且将数据拷贝到用户空间，清空链表。



**性能差异**

![select-poll-epoll-perf](/static/image/2022-02-24/select-poll-epoll-perf.png)

其实在Linux内核中，三者都使用了相同的内核poll函数。那么为什么 epoll 的性能表现会更好？当检查大量的文件描述符时，select和poll都会遇到一些问题：

- **每次调用内核O(n)检查**：
  - 每次调用select或poll，内核都**必须检查所有**被指定的文件描述符，看它们是否处于就绪态。
  - 通过`epoll_ctl`添加的FD，会注册在回调中。当调用`epoll_wait`后，通过`waitqueue`唤醒进程，直接返回就绪链表。
- **每次调用拷贝FD**：
  - 每次调用select或poll时，程序都必须传递所有需要FD数据结构到内核。
  - `epoll_wait`不携带FD参数，通过`waitqueue`唤醒进程，直接返回就绪链表。
- **每次调用用户O(n)检查**：
  - select()或 poll()调用完成后，程序必须**检查返回的数据结构中的每个元素**，以此查明哪个文件描述符处于就绪态了。
  - `epoll_wait`直接返回就绪链表。
  - （这里所花费的时间与上面两个相比微不足道）

二者糟糕的性能扩展性源自这些 API 的局限性：内核不会在每次调用后就记录下等待FD，而且没有回调机制。

epoll相比于select并不是在所有情况下都要高效：

- 有少于1024个文件描述符监听，且大多数socket都是活跃态。select要比epoll更为高效，因为epoll会有更多次的系统调用，用户态和内核态会有更加频繁的切换。
- epoll的应用场景在于需要监视大量的文件描述符，但大部分处于空闲状态，只有少数文件描述符处于就绪态。

|            |                       select                       |                       poll                       |                            epoll                             |
| :--------- | :------------------------------------------------: | :----------------------------------------------: | :----------------------------------------------------------: |
| 操作方式   |                        遍历                        |                       遍历                       |                       `waitqueue`回调                        |
| 底层实现   |                        数组                        |                       链表                       |                        红黑树 + 链表                         |
| IO效率     |      每次调用都进行线性遍历，时间复杂度为O(n)      |     每次调用都进行线性遍历，时间复杂度为O(n)     | 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到readyList里面，时间复杂度O(1) |
| 最大连接数 |              1024（x86）或2048（x64）              |                      无上限                      |                            无上限                            |
| fd拷贝     | 每次调用select，都需要把fd集合从用户态拷贝到内核态 | 每次调用poll，都需要把fd集合从用户态拷贝到内核态 |  调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝   |



### Q：边缘触发ET & 水平触发LT？epoll为什么在ET模式下搭配非阻塞IO？

> - https://juejin.cn/post/6844903878685622285

这是两种文件描述符准备就绪的通知模式：

- **水平触发LT**：如果文件描述符上可以非阻塞地执行 I/O 系统调用，此时认为它已经就绪。
  - 其实内核缓冲区有数据，就可以触发可读信号。
  - 所以当LT触发时，可以先读一半数据，水平触发会再次有效，亦然可以继续读没有读完的数据。
- **边缘触发ET**：如果文件描述符自上次状态检查以来有了新的 I/O 活动（比如新的输入），此时需要触发通知。
  - 当内核缓冲区从无到有，或从满到不满，可以触发可读信号。
  - 当ET触发时，先读一半数据而剩一半的话，边缘触发不会再进行通知。所以，ET模式需要一直读，直到`EAGAIN`表示缓冲区已空。

**epoll为什么在ET模式下搭配非阻塞IO？**

提供一个场景：

- A与B通过套接字在文件描述符rfd上建立了一个连接。
- A在epoll上注册一个文件描述符rfd。
- B向这个文件描述符写2kB的数据。
- epoll_wait告诉A：B发了数据过来，你可以读了。
- A粗心大意**只读取了1kB数据**，还有1kB的数据忘记读了，就以为自己读完了。
- 这时候epoll_wait调用完成。

这里注意阻塞IO是不要求用户一直读到缓冲区为空的，所以这容易让用户忘记缓冲区仍有数据。而非阻塞IO是要做到读`EAGAIN`才行的。

> An  application  that  employs the EPOLLET flag **should** use nonblocking file descriptors to avoid having a blocking read or write starve



### Q：有哪些方法可以监控内核Metrics？

> - https://manjusaka.itscoder.com/posts/2022/01/31/a-simple-introduction-about-network-monitoring-in-linux-kernel/
> - https://www.cnblogs.com/xinghuo123/p/13782009.html
> - https://arthurchiao.art/blog/trace-packet-with-tracepoint-perf-ebpf-zh/
> - https://www.iserica.com/posts/brief-intro-to-ebpf/

**The Proc Filesystem**

PROC文件系统是UNIX的操作系统中的一个特殊文件系统，它在层次文件的结构中呈现有关进程和其他系统信息的信息，提供更方便和标准化的方法，用于动态访问在内核数据而不是直接访问内核内存。PROC文件系统提供内核空间和用户空间之间的通信方法。例如，显示进程信息`pc`和网络信息的`netstat`都使用PROC文件系统获取其数据，而无需使用任何专门的系统调用。

具体举例：

- **进程信息**：`/proc/<PID>/`
  - **`/proc/<PID>/cmdline`**：启动该进程的命令行
  - **`/proc/<PID>/environ`**：环境变量的名字和值
  - **`/proc/<PID>/status`**：进程的基本信息，包括运行状态、内存使用。如`Pid / PPid`、线程个数`Threads`，驻留集大小`VmRSS`。
  - **`/proc/<PID>/task`**：包含子任务的目录硬链接
- **网络信息**
  - **`/proc/net/tcp`**：连接状态、本地地址端口、远程地址端口、慢启动阈值等
  - **`/proc/net/nf_conntrack`**：存在的网络连接
- **设备信息**
  - **`/proc/cpuinfo`**：各种CPU信息，如架构、Cache大学、核数等

**netlink + sock_diag**

但`procfs`通信方式都是同步的，只由用户态主动发起向内核态的通信，内核无法主动发起通信。

而Netlink是一种**异步全双工的通信方式**，它支持由内核态主动发起通信，用户态则基于socket  API，内核发送的数据会保存在接收进程socket 的接收缓存中，由接收进程处理。

一些语言的社区会对netlink做包装：

```go
package main

import (
	"fmt"
   	
	"github.com/vishvananda/netlink"
	"syscall"
)

func main() {
	results, _ := netlink.SocketDiagTCPInfo(syscall.AF_INET)
	
	for _, item := range results {
		if item.TCPInfo != nil {
			fmt.Printf("Source:%s, Dest:%s, RTT:%d\n", item.InetDiagMsg.ID.Source.String(), item.InetDiagMsg.ID.Destination.String(), item.TCPInfo.Rtt)
		}
	}
}
```



**eBPF + tracepoint / kprobe**

eBPF用于提供一种安全、友好的Linux内核态程序执行环境。eBPF程序是基于内核事件驱动的，在内核中特定事件发生时，用户编写的eBPF程序会被内核中的eBPF虚拟机即时编译执行。人们可以很方便地在Linux运行时动态扩展和丰富内核的能力。

eBPF的核心思想与BPF一脉相承，BPF用户在内核中处理和分析网络数据包，并过滤无关数据包。避免将大量数据包发送到用户态，节省了数据搬运的开销：

- **构建**：eBPF程序的目标文件是可以被eBPF虚拟机解释执行的eBPF字节码。
  - 除了用纯C写，还可以调一些三方库比如python的`bcc`
- **验证**：内核会先用eBPF Verifier验证程序的合法性：检查权限、程序是否导致内核崩溃、是否出现死循环。
- **注册与执行**：eBPF程序在完成构建后，需要“挂载”到内核上的对应事件上，当事件产生时，触发内核调用对应的eBPF程序。

```python
from bcc import BPF

bpf_text = """
BPF_RINGBUF_OUTPUT(tcp_event, 65536);

enum tcp_event_type {
    retrans_event,
    recv_rst_event,
};

struct event_data_t {
    enum tcp_event_type type;
    u16 sport;
    u16 dport;
    u8 saddr[4];
    u8 daddr[4];
    u32 pid;
};

TRACEPOINT_PROBE(tcp, tcp_retransmit_skb)
{
    struct event_data_t event_data={};
    event_data.type = retrans_event;
    event_data.sport = args->sport;
    event_data.dport = args->dport;
    event_data.pid=bpf_get_current_pid_tgid()>>32;
    bpf_probe_read_kernel(&event_data.saddr,sizeof(event_data.saddr), args->saddr);
    bpf_probe_read_kernel(&event_data.daddr,sizeof(event_data.daddr), args->daddr);
    tcp_event.ringbuf_output(&event_data, sizeof(struct event_data_t), 0);
    return 0;
}

TRACEPOINT_PROBE(tcp, tcp_receive_reset)
{
    struct event_data_t event_data={};
    event_data.type = recv_rst_event;
    event_data.sport = args->sport;
    event_data.dport = args->dport;
    event_data.pid=bpf_get_current_pid_tgid()>>32;
    bpf_probe_read_kernel(&event_data.saddr,sizeof(event_data.saddr), args->saddr);
    bpf_probe_read_kernel(&event_data.daddr,sizeof(event_data.daddr), args->daddr);
    tcp_event.ringbuf_output(&event_data, sizeof(struct event_data_t), 0);
    return 0;
}

"""

bpf = BPF(text=bpf_text)


def process_event_data(cpu, data, size):
    event = bpf["tcp_event"].event(data)
    event_type = "retransmit" if event.type == 0 else "recv_rst"
    print(
        "%s %d %d %s %s %d"
        % (
            event_type,
            event.sport,
            event.dport,
            ".".join([str(i) for i in event.saddr]),
            ".".join([str(i) for i in event.daddr]),
            event.pid,
        )
    )


bpf["tcp_event"].open_ring_buffer(process_event_data)


while True:
    bpf.ring_buffer_consume()
```



# 数据库




## 数据库系统原理

> - <https://blog.tanglizi.one/post.sh?name=2022-02-19_[CMU15-445]_数据库原理知识点总结.md>

### Q：内链接和外链接是什么？

- **内连接：**`from A [inner] join B on a.id=b.id`

  - **等值连接**

  - **不等连接**： 连接条件使用`>、>=、<=、<、!>、!<、<>`

- **外连接**：`from A left [outter] join B on a.id=b.id` / `full join`
  - **左外连接**：以左关系为准链接，右关系中可以存在Null
  - **右外连接**：以右关系为准链接，左关系中可以存在Null
  - **全外连接**：同时以左右关系为准链接，左右关系中都可以存在Null




### Q：如何理解数据库的范式？

> https://blog.csdn.net/zymx14/article/details/69789326

- **第一范式**：确保每一列的原子性
- **第二范式**： 在1NF上，任何非主属性依赖于主属性
  - 如果一个关系满足1NF，并且除了主键以外的其它列，都依赖与该主键，则满足二范式(2NF)，第二范式要求每个表只描述一件事。
- **第三范式**：在2NF基础上， 任何非主属性不依赖于其它非主属性
  - 在2NF基础上消除传递依赖
- **BCNF**：主键不**部分**依赖与码



可能出现的问题：

- **数据冗余**：每条记录都含有相同信息

- **删除异常**：删除所有学生成绩，就把课程信息全删除了

- **插入异常**：学生未选课，无法记录进数据库

- **更新异常**：调整课程学分，所有行都调整



### Q：关系型和非关系型数据库的优劣？

关系型数据库是指采用了关系模型来组织数据的数据库，即在二维表模型上支持多表查询、级联删除等，突出表现在表之间的关系。

- **优点**

  - **容易理解**：二维表的结构容易理解。

  - **使用方便**：通用的SQL规范
  - **易于维护**：事务ACID对数据提供了更好的持久化一致性保障。

- **缺点**
  - **读写效率**：支持更多功能意味着效率降低，如事务并发控制、原子性保证、故障回复方法等。

**何时使用关系型数据库**

- **关系型查询**：需要支持多表查询、级联删除等。
- **事务支持**：体现在原子性、故障恢复、一致性上。



**何时用非关系型数据库**

NoSQL主要指非关系型的、分布式的，且一般不支持事务的数据存储系统。适合存储非结构化数据，比如：文章、评论：

- 这些数据通常用于模糊搜索，例如全文搜索，适合存储较为简单的数据。
- **水平扩展**：NoSQL更加容易，在数据增长的速度是难以预期情况使用。
- **非关系型查询**：按照key获取数据效率很高，但是对于join或其他结构化查询的支持就比较差。



### Q：当谈到Replica和Shard时到底在讨论什么？

- **Replicating**
  - **同步模型**：主备同步模型、同步/异步复制
  - **读写分离**：主从一致性如何
  - **故障恢复**：故障发现（单节点故障处理 / 多节点共识机制） + 主备切换/选举主节点 + 脑裂解决方式
- **Sharding**：
  - **分片策略**：水平扩缩容的方案
  - **分布式事务**：原子提交协议
  - **重定向策略**：客户端缓存 / 服务端转发



### Q：当谈到事务的实现时，我们在讨论什么？

- **原子性**：回滚机制、故障恢复协议
- **持久性**：故障恢复协议
- **一致性**：完整性约束、故障恢复协议
- **隔离性**：支持哪些隔离级别，如何实现



### Q：BTree vs B+Tree？

- B树所有节点既存放键也存放数据，而B+树只有叶子节点存放Tuple
- B树的叶子节点都是独立的，B+树的叶子节点有单向链表。
- B树的检索过程可能还没到叶子节点，检索就结束了。而B树的检索效率就很稳定，每次都是从根节点到叶节点的过程。



## MySQL - InnoDB

注意：InnoDB中一个页大小16K。

### Q：`char`和`varchar`使用场景？

|                  | char(32)                                                     | varchar(32)                                |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------ |
| 占用空间         | 固定32字符（如果数据长度不够32将用空格补齐）                 | 跟随实际存储内容长度，但不超过32           |
| 空格处理         | 检索时会去掉尾部空格（数据本身有空白符也会被去掉）           | 不会对空格处理                             |
| 是否记录字段长度 | 否                                                           | 是。额外拿出空间记录字段数据长度（字符数） |
| 适用场景         | 存储的数据长度基本一致，不需要空格，eg 手机号、UUID、密码加密后的密文 | 数据长度不一定，长度范围变化较大的场景     |



### Q：MySQL三种存储引擎InnoDB、MyISAM、MEMORY的区别？

同一个数据库也可以使用多种存储引擎的表：

- **InnoDB**：默认事务型引擎
  - **事务支持**：支持回滚、故障恢复、SQL92隔离级别
  - **支持外键**
  - **并发控制**：行锁表锁、间隙锁、MV2PL
  - 内存和存储要求：高
- **MyISAM**：
  - **不支持事务**
  - **不支持外键**
  - **并发控制**：只支持表锁
  - MyISAM支持压缩表
- **Memory**：数据全部放在内存中，掉电后表结构存在，但数据会丢失。
  - **不支持事务**
  - **不支持外键**
  - **索引：**默认哈希索引
  - **并发控制**：只支持表级锁。
  - <u>MySQL内部使用的临时表就是Memory表</u>。



### Q：临时表什么时候产生？

> - https://zhuanlan.zhihu.com/p/126144198

临时表是指排除掉输出的表和使用的持久化表以外，引擎在计算时生成的临时的表。

你可以通过SQL前面加上`explain`去查询Query Plan，在`Extra`中存在`using temporary`就是指使用临时表。一些使用临时表的场景：

- **导出表**：在`FROM`语句中出现的一种临时的表，如子查询、`JSON_TABLE`函数。
- **公共表**：`WITH`定义的表
- **子查询 / semi-join**：在`where`中出现的子查询和`in / not in`算符。
- **排序和聚合子句不同时**：相同时，聚合使用`sorting`的算法降低开销；不同时使用`Hashing`方法降低成本。
  - 注意`DISTINCT`也是一种聚合



### Q：为什么不用外键？外键的作用？

> - https://draveness.me/whys-the-design-database-foreign-key/

外键是数据库的为保证**引用完整性**提供的工具。最常见的也就是 `RESTRICT`（默认类型） 和 `CASCADE` 两种，它们带来的额外开销就是不使用外键的理由：

- **`RESTRICT` / 一致性检查**：在更新(insert / update / delete)时，对外键的记录是否存在进行一致性检查；
  - 可以选择在应用程序中模拟（可能带来的开销更大），或者不处理一致性。
  - 插入/修改时，检查更新的引用是否存在；删除时，检查本记录是否被引用。
- **`CASCADE` / 级联删除**：在更新主键或删除记录时触发；
  - **导致雪崩**：一条记录的删除可能会被放大到几十倍，对磁盘的随机读写会带来巨大的开销。应用层可以做拆分削峰。



### Q：索引的功能种类？B+Tree和Hash索引的区别？

> - [数据库两个神器索引和锁(修订版) ](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484721&idx=1&sn=410dea1863ba823bec802769e1e6fe8a&chksm=ebd74430dca0cd265a9a91dcb2059e368f43a25f3de578c9dbb105e1fba0947e1fd0b9c2f4ef&token=1676899695&lang=zh_CN#rd)
> - [MySQL 的覆盖索引与回表](https://zhuanlan.zhihu.com/p/107125866)

**按功能分类索引**

- **主键索引**：InnoDB存储引擎的表会存在主键（唯一非null），如果建表的时候没有指定主键，则会使用第一非空的唯一索引作为聚集索引，否则InnoDB会自动帮你创建一个不可见的、长度为6字节的row_id用来作为聚集索引。
- **单列索引**：单列索引即一个索引只包含单个列
- **组合索引**：组合索引指在表的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用。<u>使用组合索引时遵循最左前缀原则。</u>
  - **最左匹配原则**：从最左边的索引匹配开始，遇到范围查询则开始线性查找。如有索引 `(a,b,c,d)`，查询条件 `a=1 and b=2 and c>3 and d=4`，最后的`d=4`是没有二分的。
- **唯一索引**：索引列的值必须唯一，但允许有空值。若是组合索引，则列值的组合必须唯一。主键索引是一种特殊的唯一索引，不允许有空值
- **普通索引**：是MySQL中的基本索引类型，允许在定义索引的列中插入重复值和空值

**按数据结构分类**

- **B+树索引**
  - InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，一个节点就是一个页
  - B+ 树索引只能找到数据行对应的页，然后数据库把整个页读入到内存中，并在内存中查找具体的数据行。
  - B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度
- **哈希索引**
  - 由InnoDB存储引擎自动优化创建
  - 哈希索引没法利用索引完成**排序**
  - 不支持**最左匹配原则**
  - 在有大量重复键值情况下，哈希索引的效率也是极低的：**哈希碰撞**问题。
  - **不支持范围查询**




### Q：MySQL 多版本并发控制？

> https://www.zhihu.com/question/263820564/answer/289269082

当谈到MVCC时，我们其实再说MVCC设计的四个部分：**并发控制协议**、**版本存储**、**GC**、**索引管理**。

**并发控制协议 - MV2PL**

MySQL通过MV2PL实现了MVCC。这里的并发控制是指在两个事务在同一个对象上发生了写写冲突时的解决方案，因为版本链是不能有分叉的。

**版本存储**

每个Tuple会带有一个上一个版本指针，它们形成了一个版本链（version chain）。索引总是指向链的Header，线程将遍历链，直到找到正确的版本。

MySQL实现的是Time-Travel Storage + N2O + Delta方法：

- **Time-Travel Storage**：MySQL将最新版本存在聚簇索引上，而历史版本存储于回滚段（Rollback Segment）Undo Tablespaces上。
- **N2O**：按照从新到旧的方式做链表。
- **Delta**：同时存储每次更新的Undo Log，所以Undo Log不止在故障恢复里使用（不知道格式是否一致）。
  - 存储类似：`TxID | RollPtr | ... | Payload`

**GC**

> - https://dev.mysql.com/doc/refman/8.0/en/glossary.html

MySQL把版本GC称作purge，具体而言是一种后台清理的策略。后台线程定期扫描表并寻找可回收的版本。

如果配置了`innodb_max_purge_lag`的话，那么针对超过它版本个数的Tuple，DML操作都会稍微延迟一下用于GC。

不知道MySQL是怎么打标记的，也不知道有没有用脏页BitMap优化。

**索引管理**

DBMS需要在创建新版本后维护所有索引。此处MySQL中除了一个聚簇索引外，其他全是二级索引，他们需要回表不必做更新。聚簇索引原地更新即可。



### Q：MySQL的行锁和表锁是什么？如何支持多粒度锁？

> - https://zhuanlan.zhihu.com/p/67793185

**表锁**

需要注意的是，表锁是显式调用而且使用了一次封锁技术。即我们会在会话开始的地方使用 lock 命令将后面所有要用到的表加上锁，在锁释放之前，我们只能访问这些加锁的表，不能访问其他的表，最后通过 unlock tables 释放所有表锁。这样人为地将S2PL中获取锁的阶段缩小了，那么死锁也就不存在了。

**行锁**

- **InnoDB的行锁是基于索引的**，所以只有通过**索引条件**检索数据**才使用行级锁**
- 即使这个表没有索引，会使用非空的唯一列的索引代替；如果没有这种列，会定义一个隐藏的主键。所以 InnoDb 的表一定会有主键索引。
- 如果查询是通过二级索引的，那么会在二级索引的Tuple和聚簇索引的对应Tuple上加锁。
- 对于范围查询而言，会一次一个地加锁。

**意向锁**

意向锁的意义在于提供一种优化：当申请表锁时可以不用扫描检查每一个行锁是否冲突。如果节点处于意图模式，则显式锁定将在树的较低级别执行。

- **Intention-Shared (IS) / 意向共享锁**：当事务给行加共享锁前，必须先取得该表的IS锁。表示使用共享锁在较低级别上显式锁定。
- **Intent-Exclusive (IX) / 意向独占锁**：当事务给行加独占锁前，必须先取得该表的IX锁。表示使用排他锁或共享锁在较低级别上显式锁定。

**间隙锁**

是一种加在两个列值之间的锁，或者加在索引之前或之后。

- 使用间隙锁可以防止其他事务在这个范围内插入或修改记录，保证两次读取这个范围内的记录不会变，从而不会出现幻读现象。
- 间隙锁唯一的作用就是为了防止其他事务的插入，所以加间隙锁没有读写锁的概念。
- 只有RR隔离级别才有间隙锁。

**Next-key 锁**

是记录锁和间隙锁的组合，它指的是加在某条记录以及这条记录前面间隙上的锁。

- 只有 RR 隔离级别才有NextKey锁



### Q：MySQL如何解决死锁？

**Deadlock Detection / 死锁检测**

系统在后台线程中周期性地检查事务等待图。当DBMS检测到死锁时，它将中止其中一个事务以打破这个循环。

- **终止因素**：选择哪一个事务来终止呢？常见的考虑因素有：年龄、锁个数、等待它的事务数等。许多系统使用这些因素的组合。
- **回滚范围**：在选择一个受影响的事务中止之后，DBMS还可以决定回滚该事务的更改的范围。它可以回滚整个事务，也可以回滚到足以打破死锁的某个操作。

![deadlock-detection](/static/image/2022-02-20/deadlock-detection.png)



### Q：MVCC或RR隔离等级为什么能解决部分幻读？

> - https://www.cnblogs.com/xuwc/p/13873293.html

快照读中MVCC利用历史数据可以<u>避免部分幻读</u>；而当前读时将会用**NextKey锁**解决幻读。

**快照读 & 当前读**

- **快照读**：指MVCC下的`select`语句。
- **当前读**：`insert / update / delele`还有`select ... for update / lock in share mode`都是当前读。
  - 所有当前读使用NextKeyLock，防止幻读。

这里有一些可以解决幻读的例子：`T1SelectAll, T2Insert, T1UpdateAll(locked)` / `T1SelectAllShare, T2Insert(locked)`

**为什么MVCC不能解决快照读下的幻读？**

`T1SelectAll, T2Insert, T2Commit, T1UpdateAll, T1SelectAll`

步骤4会出现幻读情况，因为此时不是通过ReadView去检查数据，而是用当前读直接修改数据。这使得新数据TxID变成当前TxID，所以最后的快照读会出现幻读。所以如果全程使用NextKey的话就不会出现幻读。



### Q：InnoDB如何实现事务？

**原子性 - 回滚机制 / 故障恢复协议**

原子性是指当事务不能提交的情况下，需要有回滚机制将相关操作撤销。跟大多数数据库一样，这里通过回滚日志（undo log）实现。回滚时的具体操作见数据库原理总结里的ARIES协议。注意：

- **需要回滚的情况**：发生死锁、用户回滚操作、一致性不满足、系统崩溃重启。
- **级联回滚**：当事务1读到将要回滚的事务2时，事务1需要被级联回滚。

**持久性 - 故障恢复协议**

详见数据库原理总结。

一旦事务被提交，数据必须被持久存储。关注点在崩溃或重新启动后，提交的事务的所有更改必须是持久的。这里需要考虑内存中的脏页写回磁盘的问题。

- **Fuzzy Checkpointing / 模糊检查点**：DBMS定期在将Buffer Pool中的脏页写的地方设置checkpoint，用于在恢复时最小化重放日志量。**Fuzzy Checkpoint**不需要暂停事务执行，也不需要等待所有活动事务执行完毕。
- **ARIES故障恢复协议**：analysis、redo、undo。

- **Partial Page Write / 部分页写入**：当某一个页在写入时掉电，导致页不完整，从而找不到对应的redo log条目或事务号。
  - MySQL通过doublewrite buffer解决：在写数据页之前，先把新数据页顺序地写到doublewrite磁盘文件，然后再写到数据页。
  - 当故障恢复时会检查checksum判断页是否不完整，如果不完整再从doublewrite文件里恢复即可。

**一致性 - 完整性约束 / 故障恢复协议**

> - https://dev.mysql.com/doc/refman/8.0/en/constraints.html

MySQL的ACID文档没有提到关于完整性保证的内容，不过提到了故障回复。其实也可以说一致性跟故障回复沾边，故障恢复第二个阶段就是为了恢复一致性状态。

- **主键约束 / 唯一键约束**：（可以通过`IGNORE`来绕过这个约束）
- **外键约束**：指外键的行存在

**隔离性- 隔离级别实现**

> - https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_read-uncommitted

InnoDB只实现了SQL92中提高的4中隔离级别，默认是可重复读：

- **读未提交**：不加锁，没有进行隔离
- **读已提交**：（MV-2PL：语句级别快照隔离）**每次读**时生成快照ReadView
- **可重复读**：（MV-2PL：事务级别快照隔离）**首次读**时生成快照ReadView
- **读未提交**：S2PL



### Q：MySQL主备集群 ？

> - https://www.diaosi.love/archives/mysql%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8F%8A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1
> - https://dev.mysql.com/doc/refman/8.0/en/mysql-innodb-cluster-introduction.html
> - https://dev.mysql.com/doc/refman/8.0/en/group-replication-primary-secondary-replication.html
> - https://dev.mysql.com/doc/refman/8.0/en/group-replication-summary.html

- **Replicating**

  - **同步模型**：复制状态机（通过记录操作的binlog）、异步复制、持续复制

    - **典型复制模式**：异步复制
    - ①当Master节点进行insert、update、delete操作时，会按顺序写入到binlog中。
      - ②salve从库连接master主库，Master有多少个slave就会创建多少个binlog dump线程。
    - ③当Master节点的binlog发生变化时，binlog dump 线程会通知所有的salve节点，并将相应的binlog内容推送给slave节点。
      - ④I/O线程接收到 binlog 内容后，将内容写入到本地的 relay-log。
    - ⑤SQL线程读取I/O线程写入的relay-log，并且根据 relay-log 的内容对从数据库做对应的操作。
    - **半同步变体**：当Master节点受到从节点apply之后的ACK后，才做commit
    - **GroupReplication**：（似乎是5.7引入的）在读写事务发生时**原子性广播**，所有节点以相同的顺序受到写数据集合，要么都受到要不都不受到。（其实是变体Paxos）不是强一致副本的原因是，主节点不是在所有节点提交后再响应客户端，而是当写集合确认受到后立即响应（从节点仍需要relay&apply）。
  - **读写分离**：最终一致性；半同步变体的不一致状态更短一点；只读事务任意读，读写事务需要Proposal达到最终一致性
  - **故障恢复**：TODO（分布式恢复、故障迁移）
    - **典型模式**：没找到文档
    - **GroupReplication**：没有监控节点，只是Cluster节点间使用共识机制Paxos变体的XCom做错误容忍和**故障迁移**选举

- **Sharding**：原生不支持，不过有很多开源组件可以搭配来做这件事。不过MySQL文档中声明自己支持XA，也就是2PC的一种接口规范。

**WAL和Binlog的区别**

- Redo Log是属于InnoDB引擎功能，Binlog是属于MySQL Server自带功能，并且是以二进制文件记录。
- Redo Log属于物理日志，记录该数据页更新状态内容，Binlog是逻辑日志，记录更新过程。
- Redo Log日志是循环写，日志空间大小是固定，Binlog是追加写入，写完一个写下一个，不会覆盖使用。
- Redo Log作为服务器异常宕机后事务数据自动恢复使用，Binlog可以作为主从复制和数据恢复使用。Binlog没有自动crash-safe能力。



### Q：MySQL高并发解决方案？

MySQL 高并发环境解决方案：

- **增加缓存**
- **分库分表分片**：降低单点数据库压力。垂直切分 & 水平切分。
- **读写分离**：提高读吞吐量。
- **主备集群**：提供存储冗余，缓解单点故障问题。

注意原生MySQL似乎不支持分片，有很多开源组件可以搭配来做这件事。



### Q：AUTO_INCREMENT原理？为什么会不连续？

在 MySQL 8.0 中，`AUTO_INCREMENT` 计数器的初始化行为发生了改变，每次计数器的变化都会写入到系统的重做日志（Redo log）并在每个检查点存储在引擎私有的系统表中。

 InnoDB 存储引擎提供的 `innodb_autoinc_lock_mode` 配置控制的，该配置决定了获取 `AUTO_INCREMENT` 计时器时需要先得到的锁，该配置存在三种不同的模式，分别是传统模式（Traditional）、连续模式（Consecutive）和交叉模式（Interleaved），其中 MySQL 使用连续模式作为默认的锁模式：

- **传统模式**
  - 在包含 `AUTO_INCREMENT` 属性的表中插入数据时，**所有**的 `INSERT` 语句都会获取**表级别**的 `AUTO_INCREMENT` 锁，该锁会在当前语句执行后释放；
- **连续模式**
  - `INSERT ... SELECT`、`REPLACE ... SELECT` 以及 `LOAD DATA` 等批量的插入操作需要获取**表级别**的 `AUTO_INCREMENT` 锁，该锁会在当前语句执行后释放；
  - **简单的插入语句**（预先知道插入多少条记录的语句）只需要获取获取 `AUTO_INCREMENT` 计数器的X锁并在获取主键后直接释放，不需要等待当前语句执行完成；
- **交叉模式**
  - 所有的插入语句都不需要获取**表级别**的 `AUTO_INCREMENT` 锁，但是当多个语句插入的数据行数不确定时，可能存在分配相同主键的风险；

主键不连续主要有两个情况：删除某个主键的记录、并发时插入操作回滚。



### Q：UUID vs 自增主键？为什么不推荐使用UUID作为主键？

- **UUID的缺点**
  - uuid是无序的， 插入数据时会发生页分裂，速度慢。
  - uuid占的空间大，二级索引也要存储，需要读数据时一般会认为需要的io次数多。
- **自增ID的缺点**
  - 高并发负载下，主键的上界并发插入会导致间隙锁竞争。
  - Auto_Increment锁机制会造成自增锁的抢夺



## Redis

> - https://zhuanlan.zhihu.com/p/91539644

### Q：Redis的特点和优势？

- **操作原子性**：Redis有着更为复杂的数据结构并且提供对他们的原子性操作。
- **数据类型**：string、hash、list、set、zset
- **支持过期时间**
- 支持事务：（其实也不是真事务）



### Q：Redis的数据类型和使用场景

> - https://www.cnblogs.com/lizhenghn/p/5322887.html
> - https://zhuanlan.zhihu.com/p/91539644
> - https://xie.infoq.cn/article/98c984f6462aec99ffc0c3b42

- **String**：
  - **内部存储**：默认是简单字符串SDS，遇到数字操作时会转成数值型进行计算
  - **场景**：缓存、计数器、Session。
- **Hash**：存储一系列kv对，逻辑上是单层Map。
  - **内部存储**：一位数组ZipList，当数量足够转换为HashTable。
  - **场景**：比较有限，可以做类似Key的聚合
- **List**：字符串列表。
  - **内部存储**：双向链表QuickList
  - **场景**：轻量消息队列、利用`lrange`做分页功能。
- **Set**：
  - **内部存储**：数组intset或值为nil的HashTable。
  - **场景**：分布式去重、集合命令做交并差。
- **ZSet**：命令中多了一个权重参数score，集合中的元素能够按score进行排列。
  - **内部存储**：数组ZipList或者跳表SkipList
  - **场景**：排行榜、取TopN。



### Q：Redis为什么能做到操作原子性？事务原子性和隔离性？

> - https://stackoverflow.com/questions/43259635/is-redis-set-command-an-atomic-operation

**操作原子性**

因为Redis是单线程的，所有的命令都需要一个一个的执行。但是事务不同，事务间的命令可能cross，所以有额外的保护机制。

**事务原子性**

> - https://segmentfault.com/a/1190000023951592

| 命令    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| MULTI   | 标记一个事务块的开始                                         |
| EXEC    | 执行所有事务块内的命令                                       |
| DISCARD | 取消事务，放弃执行事务块内的所有命令                         |
| WATCH   | 监视一个（或多个）key，如果在事务执行之前这个（或多个）key被其他命令所改动，那么事务将被打断 |
| UNWATCH | 取消 WATCH 命令对所有 keys 的监视                            |

**原子性**不被保证。当事务中的一条语句执行出错（Hash命令用在String上），那么这个事务不会回退，而是跳过它继续执行（如果语法有误，那么在入队和`EXEC`时会报错）。

为什么不支持原子性或者回退呢？官方回答是这样可以保证Redis内部简单快速。真是大道至简呢。

**事务隔离性**

单机事务并发控制非常简单：当`EXEC`发生时把事务当作操作执行，所以单机下造成串行调度。但是注意这里的**隔离性**是指从`MULTI`输入开始时刻到`EXEC`执行时刻间没有监听的数据改变，这需要配合`WATCH`实现乐观并发控制：

- 在`MULTI`之前紧挨着`WATCH`，可以设置监视键；当 `EXEC` 被调用时，对所有键的监视都会被取消。
- 当事务执行过程中监视键改变，那么整个事务将被打断，不再执行， 直接返回失败。
- **原理**：`watched_keys`字典会存储`<key, clientList>`的映射，当对`key`的写入生效时遍历这个链表，将对应客户端的键的`REDIS_DIRTY_CAS`打开。当客户端提交EXEC时，服务器本地检查此标志，服务器会放弃执行这个事务，回复空。

> - 分布式事务：https://segmentfault.com/a/1190000040321750

那么分布式事务Redis支持么?我们讲分布式事务一般是指在多个分片上保证事务ACID，如原子性提交、分布式Join等。

那么关于原子性提交，我认为Redis使用`WATCH`应该就能做乐观并发控制，不过要对`watched_keys`做共识副本，如Raft等共识策略。



### Q：Redis集群是什么？Sharding和replicating如何做？

> - https://redis.io/topics/cluster-spec

**[Replicating] Master-Replica with Sentinel 哨兵模式**

> - https://redis.io/topics/sentinel
> - https://pdai.tech/md/db/nosql-redis/db-redis-x-sentinel.html

讨论Replica时我们讲哪些话题？主备同步模型、同步/异步复制、是否读写分离（主从一致性）、故障恢复（故障发现（单节点故障处理 / 多节点共识机制） + 主备切换/选举主节点 + 脑裂）

- **主备同步模型**：从节点首次复制使用RDB全量更新，往后使用AOF增量**异步复制**。（State Transfer + Replica State Machine）
  - 多个从节点宕机后，不要一起重启。这可能导致主节点IO剧增而宕机。
- **读写分离 / 主从一致性**：是读写分离 + 最终一致性。因为主从是异步复制的，没有多余的一致性保证。
- **故障恢复**：
  - **故障发现**：Sentinel哨兵模式，利用一种形式Gossip共识机制，用于心跳监控主从的独立进程。通常N个哨兵互相监控，同时监控所有主从。
  - **选举主节点 / 主备切换 / 处理脑裂**：
    - **Subjectively Down (SDown) / 主观下线**：单个哨兵检测网络不通
    - **Objectively Down (ODown) / 客观下线**：半数以上哨兵检测网络不通
    - **#1 Qourum**：首先某个哨兵发现master宕机，那么标记状态为SDown，请求其他节点投票：是否转变为ODown + 我是否成为发起ODown的主哨兵
    - **#2 Elect**：主哨兵筛选并排序出适合变为主的从节点。
    - **#3 通知**：主哨兵针对不同角色发不同消息：新Master解除从节点、其他节点认新Master、客户端通过Pub/Sub获知新主节点。



**[Sharding] - Cluster 集群模式**

讨论Sharding时我们讲哪些？分片策略（扩缩容）、分布式事务（原子提交协议）、重定向策略。

- **分片策略**：哈希槽。
  - 集群中有16384个哈希槽，每个key通过效验取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。
  - **扩缩容**：

- **重定向策略**：是由工作节点查询分片对应的节点，客户端受到重定向响应再去对应节点查询。
  - **MOVED**：MOVED重定向说明键对应的槽已经明确指定到新的节点，因此需要更新slots缓存。
  - **ASK**：ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是临时性的重定向，客户端不会更新slots缓存。

- **故障恢复**：集群中每个分片都有一个slave节点做故障恢复。
  - **故障检测**：节点间心跳监控每个其他节点。当节点间发现主观下线PFail，利用Gossip通知各个节点，Qourum到达后广播Fail状态。
  - **Failover 主备切换 / 故障转移**：各个主节点选择从节点，通过Qourum做共识，最后替换。



### Q：Redis分布式锁是什么？如何实现？

> - https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce

- **使用`setnx`+`expire`**
  - **问题**：这两个命令并不是原子性的，如果在执行`expire`服务器宕机，那么重启后这个key将会一直存在。

- **使用`set`扩展命令**：`set k v ex 5 nx`，超时5s不存在才写入
  - **问题**：锁被提前释放 & 锁被误删。
  - **解决方案**：不用长任务、用value来做CAS（用Lua脚本做`set + del`原子性）
- **Redisson**：通过不断询问任务结束来增加超时时间，处理提前释放问题。
- **Redlock**：Sentinel集群（异步复制）下的分布式锁，使用经典Qourum思想。
  - 客户端向N个节点请求锁，仅当N/2+1个节点同意，则申请成功。
  - 当客户端申请失败或使用结束后，向N个节点发送释放锁。
  - **等待申请锁**：客户端计时超时时间，避免服务器端 Redis 已经挂掉的情况下，死等响应结果。
  - **锁的可用时间**：客户端计算真正的锁可用时间：失效时间 = 当前时间 - 获取时时间
  - **故障恢复**：节点宕机的情况下，不要立即重启，而是等待锁的有效时间过了后重启。



### Q：单线程的redis为什么这么快

> 抱歉找不到下面这个图的原推了

- 纯内存操作
- 单线程操作，避免了频繁的上下文切换
- 采用I/O多路复用

![why-redis-fast](/static/image/2022-03-02/why-redis-fast.jpeg)



### Q：Redis持久化机制

Redis 提供了 RDB 和 AOF 两种持久化方式：

- **RDB**：fork子进程，把内存中的数据以快照形式压缩写入磁盘，保存在单一文件中
  - 快照保存完成之前如果宕机，这段时间的数据将会丢失。
  - 保存快照时可能导致服务短时间不可用。
- **AOF**：以追加文本日志的形式，记录每一个写操作
  - 支持每秒同步、每次修改同步和不同步。



### Q：Redis过期删除策略 & 驱逐策略

**过期删除策略**

- **定时删除**：Redis不用它。用一个定时器来负责监视key，过期则自动删除。
  - 虽然内存释放及时，但十分消耗CPU资源。

- **定期删除**：每隔100ms随机抽查key删除
  - redis默认每隔100ms检查，是否有过期的key，有过期的key则删除。
  - 将所有的key检查一次，而是先随机抽取进行检查，如果只采用定期删除策略，会导致很多key到时间没有删除。
- **惰性删除**：在获取某个key的时候，redis会检查是否过期，如果过期那么删除。

**淘汰策略**

当内存占用达到`maxmemory`的时候，根据不同的驱逐策略淘汰kv：

- **no-enviction**：禁止删除数据，新写入操作会报错
- **volatile-lru**：默认值。从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
- **volatile-ttl**：从已设置过期时间的数据集中挑选最少TTL的数据淘汰
- **volatile-random**：从已设置过期时间的数据集中任意选择数据淘汰
- **allkeys-lru**：从数据集中挑选最近最少使用的数据淘汰
- **allkeys-random**：从数据集中任意选择数据淘汰
- 还有**volatile-lfu**、**allkeys-lfu**：先根据使用频率淘汰最少的，如果有多个那么选择LRU。



### Q：缓存场景问题：缓存雪崩、缓存穿透是什么？缓存预热和更新的方法？

**缓存场景下的问题**

- **缓存雪崩**
  - 原有缓存失效，新缓存未到期间（在同一时刻出现大面积的缓存过期），原本应该访问缓存的请求都去查询数据库了，对数据库CPU和内存造成巨大压力。
  - **解决方法**：用锁或者队列的方式保证不会有大量的线程对数据库一次性进行读写，避免失效时大量的并发请求落到底层存储系统上。将缓存失效时间分散开。

- **缓存穿透**
  - 用户查询数据，在数据库中没有，自然在缓存中也不会有。这样就导致用户查询的时候在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）
  - **解决方法**：内存存储布隆过滤器。

**缓存预热和更新的方法**

- **缓存预热**
  - 缓存预热系统上线后，将相关的缓存数据直接加载到缓存系统。这样可以避免用户请求的时候，先查询数据库，再将数据缓存的问题。

- **缓存更新**
  - 定期清理过期的缓存
  - 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。



### Q：Redis中查询大量Key需要注意什么？

- **使用`keys`**：如果使用Keys指令，那么会导致线上服务阻塞。
- **使用`scan`**：可以无阻塞的提取出指定游标的一些Key。
  - 它返回一个新游标，客户端需要在下次scan时用它 来延续之前的迭代过程。
  - 有一定的重复概率，需要客户端做一次去重。



### Q：缓存与数据库不一致怎么处理？

> - https://zhuanlan.zhihu.com/p/59167071

关于缓存的使用，一般来说有三种模式：（与OS的两种cache不同在于多了cache-aside）

- **Cache-Aside / 旁路缓存**：由应用程序处理未命中
  - **读流程**：读缓存，如果未命中。则读数据库并更新缓存。
  - **写流程**：更新数据库，删除旧缓存。
- **Write Through / 写穿透**：由缓存（或中间件）来处理未命中
  - **读流程**：读缓存，如果未命中，由缓存读数据库、做响应并更新缓存。
  - **写流程**：缓存（中间件）更新数据库，再更新缓存。
- **Write Back / 写回**
  - **读流程**：读缓存。
  - **写流程**：写缓存，缓存满后或者脏数据过多，批量写回。
  - <u>无一致性保证，所以需要故障回复机制。</u>

**在Cache-Aside模式里，如何处理写不一致问题？**

- **先更新缓存，再更新数据库**：不使用
  - 数据库可能宕机或提交失败，造成缓存数据比数据库更新的情况。（因为数据库事务才是决定数据是否以写入的唯一标准）
- **先更新数据库，再更新缓存**：不使用
  - **更新丢失** ：`A_DB, B_DB, B_CACHE, A_CACHE`，这会造成B的更新丢失，或者说缓存不保证最新。我认为这是没有办法解决的，除非通过一些保证读写顺序的方法（S锁读取+X锁写入删除缓存，或者读写消息队列）。
  - **写多读少 / 写入成本高**：这种场景下，删除缓存懒加载的方式更好。

- **先删除缓存，再更新数据库**：解决了写多读少

- **先更新数据库，再删除缓存**：解决了写多读少

这里想讨论一下**延时双删**的策略：`DelCache, WriteDB, Sleep, DelCache`

- 它想解决在step1～2之间，其他客户端读到旧数据存入缓存的问题。
- **为什么不用超时时间**：可以在写入缓存时加超时时间，做到相似作用。不过缓存的效率就变低了。
- **最终一致性**：仍然是最终一致性，只不过不一致的时长更小（step2~step3之间）而已。
- **后台删除**：后台维护一个清除缓存线程，工作线程可以把step3~4交给它然后直接响应。
- Sleep的时长如何确定：稍大于`ReadDB + WriteCache`的时长

结论：上述方法都不能解决最终一致性问题，不过可以在降低不一致时间、降低写入成本上很有效。

**如果想做到强一致呢？**

那么必须调整读写顺序，让读请求（DB+Cache）发生在写请求（DB）之前：

- **DB的保证**：如果直接读数据库，不希望读到旧数据，那么使用**读已提交**隔离等级。
- **Cache的保证**：需要保证`ReadCache, WriteDB`之间的顺序
  - **消息队列**：读写请求入队即可保证一次只做一个请求，把未命中读数据库并更新缓存的操作原子化。
  - **加锁**：在更新缓存前，S锁读取数据库。同时在写入数据库时，用X锁并删除缓存。

# 云原生

## Docker

### Q：Docker是什么？架构如何？容器启动过程？

docker是一个开源的应用容器引擎，让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的linux服务器。容器是开销很低的一种沙箱。

**架构 / 容器创建过程**

![docker-architecture](/static/image/2022-02-27/docker-architecture.gif)

- **runc** ：作用是创建容器。是开放容器计划（OCI）容器运行时标准的参考实现，所以它只接受OCI标准的镜像。
- **containerd-shim**：当runc进程创建容器并退出后，作为容器的父进程。
- **containerd**：是容器运行时，管理容器生命周期、镜像和容器存储、容器网络。Docker镜像在这里被转换成OCI标准镜像。
- **daemon**： 功能包括镜像管理、镜像构建、REST API、身份验证、安全。



### Q：镜像、容器和层的区别？

- **层**： 在 Dockerfile配置文件中完成的每一条配置指令，即表示一个层。
- **镜像** ：由一系列只读层组成。
- **容器**：由镜像和读写层组成，结合一些Linux的隔离方法形成可运行的容器。



### Q：容器隔离的方法？

![container-isolation](/static/image/2022-02-27/container-isolation.gif)

- **namespace**：每个容器都有自己的命名空间来做进程间隔离

  - **进程ID命名空间**：提供互相隔离的**进程树**，每个容器都有自己的PID为1的进程，且不能看到其他容器或主机的进程树。 

  - **网络命名空间**：提供互相隔离的**网络栈**。网络栈中包括接口（IP地址端口）、iptables规则和路由表。

  - **挂载点命名空间**：提供互相隔离的**文件系统**。包括隔离的根目录，且不能看到其他容器或主机的目录。

  - **进程内通信命名空间**：IPC命名空间提供**共享内存**。IPC提供的共享内存在不同容器间也是互相独立的。

  - **用户命名空间**：将容器内**用户映射到主机**的不同用户上。常见的如将容器内的root用户映射到非 root 用户上。
  - **UTS命名空间**：独立的**主机名**。

- **ControlGroup**：控制组用于限额硬件资源。

  - CGroup限制容器共享主机资源的大小，比如 CPU、RAM 以及硬盘 I/O。

- **Capability / 系统权限**：控制容器进程可用的权限，类似RBAC角色控制。比如在底层，root用户是由许多能力组成的，如`CAP_CHOWN`（修改文件所有权）、`CAP_NET_BIND_SERVICE`（允许将socket绑定到系统端口号）、`CAP_SYS_BOOT`（允许重启系统）
- **MAC 强制访问控制**：采用主流 Linux MAC 技术来约束的访问控制。



### Q：容器和虚拟机的区别？

- 虚拟机是在硬件的基础上虚拟出多个操作系统。虚拟机的额外开销在于虚拟出的操作系统，它会消耗更多资源。
- 容器没有虚拟多余的操作系统。它只是在Linux上做了一些资源隔离，并维护一个进程。



### Q：Docker缓存机制？减少镜像大小的方法？

Docker使用层创建镜像，Dockerfile中每一个命令都会创建一个新的层，每层都包含执行命令前后的状态之间镜像的文件系统更改。缓存机制就是为了在构建新镜像时，尽量复用已存在的层。

对同一个父镜像层的层而言，如果Dockerfile命令和涉及的文件没有更改，那么可以复用之前的层。如果不能复用，那么后续的层都不会复用。检查过程具体而言：

- **ADD / COPY**：计算对应文件hash用于判断。
- **RUN**：如果命令一致那么仍然使用cache，可以使用参数`--no-cache`确保获取最新的外部依赖。



**减少镜像大小的方法**

- **基础镜像**：使用`scratch`（空镜像）、`busybox`（包含一些常用的Linux工具）、`alpine`（宣称是最小的linux发行版）
- **合并`RUN`**：减少层数
- **多阶段构建**：在最后的镜像中只保留产出的二进制的层



### Q：Docker网络模型是什么？

> - https://wiki.archlinux.org/index.php/Iptables
> - https://www.ipspace.net/kb/DockerSvc/30-nat-iptables.html
> - https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html

- **host**：与宿主机在同一个网络命名空间中，使用宿主的网卡、路由、iptable和IP等。
- **bridge**：默认的网络配置，通过虚拟网卡与外界通信；
- **container**：与某个容器共用一个网络命名空间。
- **none**：不会给容器进行任何网络配置。也就是说，使用这种模式的容器没有IP地址（只有一个回环地址）；

**Bridge模式**

利用了宿主机内核的网桥功能`linux bridge`创建虚拟网桥，容器通过链接网桥链接到`docker0`网桥（自定义网络则会创建新的Bridge）可访问外网。创建方式如下：

1. **创建虚拟网卡**：在主机上创建一对虚拟网卡veth设备。veth设备总是成对出现的，它们组成了一个数据的通道，数据从一个设备进入，就会从另一个设备出来。因此，veth设备常用来连接两个网络设备。
2. **链接Docker网卡**：Docker将veth设备的一端放在新创建的容器中，并命名为eth0。另一端放在主机中，以veth65f9这样类似的名字命名，并将这个网络设备加入到docker0网桥中，可以通过brctl show命令查看。
3. **分配IP**：从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。



宿主机中的iptable nat表：

```
# 从外网和本地网卡的请求，转向DOCKER链
# 剩下的本地进程发出的数据，转向DOCKER链
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER

# 配置网桥 - 将IP在网桥的网段上，同时不是从网桥网卡上发出的数据，IP字段改为宿主机IP
# MASQUERADE: 获取当前IP地址做NAT
-A POSTROUTING -s 172.19.0.0/16 ! -o br-37fdd421936d -j MASQUERADE
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -s 172.27.0.0/16 ! -o br-83f2bde6ea91 -j MASQUERADE
-A POSTROUTING -s 192.168.192.0/20 ! -o br-05b6d5954698 -j MASQUERADE
-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 80 -j MASQUERADE

# 配置网桥 - 发出的数据通过默认网桥和自定义网桥，提早返回以免NAT
-A DOCKER -i docker0 -j RETURN
-A DOCKER -i br-37fdd421936d -j RETURN
-A DOCKER -i br-83f2bde6ea91 -j RETURN
-A DOCKER -i br-05b6d5954698 -j RETURN
# 配置网桥 - 接受的数据是目标地址，则进行NAT，目标地址将被重写为容器地址
-A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80
```



网桥模式的数据流动： 

```
data(container) -> eth0 -> veth092631c ---<host iptabls[PREROUTING]>---> docker0 ---(route table)---> enp3s0 ---<host iptabls[POSTROUTING]>---> (outside)
```

![docker-bridge-data-flow](/static/image/2022-02-27/docker-bridge-data-flow.png)



### Q：一些常用Docker命令

- `docker save / docker load`：保存和装载镜像。常用于GFW的场景。
- `docker export / docker import`：保存和装载容器。
- `docker stop / docker rm -f`：发送`SIGTERM`信号并等待10s。发送`SIGKILL`直接终止。
- `docker [image | container | network | volumn | system] prune`：删除无用对象。
- `docker stats`：实时获得容器的监控信息，类似`top`。还可直接从宿主机的cgroup文件（`/sys/fs/cgroup/memory/docker/{CONTAINER ID}/`）中获得。



### Q：一些常用Dockerfile命令和区别

> - https://zhuanlan.zhihu.com/p/376209058

- **CMD / ENTRYPONIT**：用于指定容器启动时候执行的命令，区别在于`docker run [COMMAND] [ARG...]`的command覆盖上。

  - **CMD**：可以被`docker run`指定的启动命令覆盖。当用户在命令行上不输入参数时，为容器提供默认的执行命令。

  - **ENTRYPONIT**：不会被docker run指定的启动命令覆盖。`[COMMAND] [ARG...]`相当于给`ENTRYPOINT`命令添加参数。
  - **EXEC模式 / SHELL模式**：`CMD / ENTRYPOINT`都能够提供这两个模式。
    - **exec模式**：特点是不会通过 shell 执行相关的命令，所以像`$HOME`这样的环境变量是取不到的
    - **shell模式**：会以`/bin/sh -c "<command>"` 的方式执行任务命令。也就是说<u>容器中的1号进程不是任务进程而是bash进程</u>。

- **ADD / COPY**：取目标文件复制到镜像当中。

  - 唯一差别在于`add`源文件可以支持url且可以对压缩文件进行解压操作。
  - 而copy针对的是当前构建的工作目录。

- **ONBUILD**：是Dockerfile其他命令的前缀，是指在本次构建的镜像中不执行，推迟到别的镜像引用它为基础镜像时起效。
  - 例子：`maven:3-jdk-9-onbuild`

```
FROM maven:3-jdk-9
RUN mkdir -p /usr/src/app
WORKDIR /usr/src/app

ONBUILD ADD . /usr/src/app
ONBUILD RUN mvn install
---
FROM maven:3-jdk-9-onbuild
# 此时会自动添加文件并运行mvn install
```





## Kubernetes

### Q：什么是Kubernetes？架构如何？

Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。通过Kubernetes能够进行应用的自动部署、扩缩容和负载均衡。

![kubernetes-architectrue](/static/image/2022-02-28/kubernetes-architectrue.png)

- **MasterNode**：作为控制节点，对集群进行调度管理
  - **kube-apiserver**：主要用来处理REST业务逻辑，状态将被保存在etcd中。
    - REST语义，监控，持久化和一致性保证，API 版本控制，放弃和生效
    - 内置准入控制语义，同步准入控制钩子，以及异步资源初始化
    - API注册和发现
  - **etcd**：分布式KV存储，支持副本和分片，主要被用来共享配置和服务发现。
  - **controller-manager**：处理集群任务，一种资源一种控制器。在集群的层级提供复制、发布以及健康检查的功能。监听对象状态改变，将对象状态协调至期望状态。
  - **scheduler**：根据调度策略将Pod部署到合适的Node中
    - **节点过滤**：遍历所有的Node，按照具体的预选策略筛选出符合要求的Node列表。如没有Node符合预选策略规则，该Pod就会被挂起。
    - **节点打分**：预选Node列表的基础上，按照优选策略为待选的Node进行打分和排序，从中获取最优Node。
- **WorkerNode**：工作节点，运行业务应用的容器；WorkerNode包含kubelet、kube-proxy和container runtime进程；
  - **kubelet**：使用cAdvisor进行资源监控，Kubelet才是Pod是否能够运行在特定Node上的最终裁决者，而不是scheduler或者DaemonSet
    - 负责node节点上pod的创建、修改、监控、删除等<u>Pod生命周期的管理</u>
    - 接收kube-apiserver下发的指令；通过kube-apiserver与etcd集群交互，读取配置信息，上报节点状态
  - **container runtime**：负责下载镜像和运行容器。
  - **kube-proxy**：管理网络规则，并实现服务到Pod的路由和转发，以及通过应用的负载均衡



### Q：常用工作负载有哪些？

- **ReplicaSet**：目的是维护一组在任何时候**都处于运行状态**的Pod副本集合。 它通常用来保证**给定数量**的、**完全相同**的 Pod 的可用性。
  - 建议使用Deployment，它管理 ReplicaSet，并向 Pod 提供声明式的更新以及许多其他有用的功能。
- **Deployment**：Deployment 控制器为 Pods 和 ReplicaSets 提供声明式的更新能力。
  - Deployment依赖ReplicaSet来组织Pods
  - **场景**：为无状态服务提供滚动更新的能力
- **StatefulSet**：用来管理有状态应用的工作负载对象。 用来管理某 Pod 集合的部署和扩缩， 并为这些 Pod **提供持久存储和持久ID**。
  - 和 Deployment 不同的是， StatefulSet 为它们的每个 Pod 维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个**永久不变的 ID**。
  - **场景**：为有状态服务提供唯一的IP、ID和存储，有序的缩放和滚动更新。
- **DaemonSet**：在每个节点上运行。
  - **场景**：针对节点的操作，如节点的日志收集，节点的的运行状态监控。
- **Job / CronJob**：多次或定时任务，支持并发，它保证能成功完成给定的执行次数。



### Q：Pod是什么？和container的区别？为什么要设计Pod？

- **Pod是什么？**
  - Pod是一个或以上的容器组成的，他们具有共享存储/网络/PID命名空间的能力，容器通过本地回环或共享内存等方式通信。在Kubernetes中，Pod是最小的可被调度的原子单位。
  - Pod的作用是将互相间紧密相关的进程组成一个实体，将进程组的概念映射到容器技术中。
- **为什么要设计Pod？**
  - 如果没有pod的概念，那么一组容器作为一个单元。假设其中一个容器死亡了，此时这个单元的状态应该由谁来定义？如何定义呢？由应用程序判断会加重逻辑负担，且此处的逻辑完全可以在基础架构层面复用。
  - 每个pod都有唯一的IP地址，pod里所有的业务容器共享pause容器的IP地址，以及pause容器mount的Volume，通过这种设计，业务容器之间可以直接通信，文件也能够直接彼此共享。



### Q：可以通过哪些方法访问Pod？各种Service如何选择？

> - https://mp.weixin.qq.com/s/dHaiX3H421jBhnzgCCsktg

- **端口转发**：`kubectl port-forward <pod-name> <exposed-port>:<target-port>`
  - **场景**：仅调试时使用
- **宿主机端口**：Pod配置中的`hostPort`可以将容器的端口与所调度的节点上的端口绑定，可以通过宿主机的IP访问
  - **场景**：别用。不是最佳实践除，除非绝对必要。
- **`ClusterIP`**：它在集群内部生成一个服务，供集群内的其他应用访问。外部无法通过它访问此Pod。
  - **场景**：仅集群内部使用，不需要将它暴露至公网。
- **`NodePort`**：在所有的节点上开放指定的端口，所有发送到这个端口的流量都会直接转发到服务。
  - 一个端口只能供一个服务使用，范围在30000–32767。
  - **场景**：最简单的暴露方式，可以用于演示项目。
- **`LoadBalancer`**：分配一个单独的IP地址，将所有流量转发到服务中，包括TCP、UDP等。
  - 会调用云服务商的 API 接口，不同的云服务商会实现不同的适配器来创建 LoadBalancer 类型的资源。
  - **场景**：发布服务到互联网的标准方式。云服务厂商提供，每个服务都会有一个独立的IP地址。
- **`Ingress`**：典型的场景是HTTP层面的转发，会根据Host等信息将HTTP请求转发到对应Service上。
  - **场景**：在同一个IP地址下发布多个服务，且需要在HTTP层面做复杂定制（Host转发、SSL认证等）



### Q：Kubernetes网络模型是什么？各层工作原理?

> - https://zhuanlan.zhihu.com/p/48782859
> - https://blog.csdn.net/weixin_41947378/article/details/110749380
> - https://draveness.me/kubernetes-service/
> - https://www.qikqiak.com/post/how-to-use-ipvs-in-kubernetes/

Kubernetes网络系统希望解决的四个主要问题。有很多种方式可以实现这种网络模型，其中Flannel是非常简单的一种默认实现：

- **容器间通信**：为Pod分配一个独立IP，其中的容器共享网络命名空间，这要求容器间需要通过本地回环通信。
  - **实现**：为Pod指派一个唯一的IP地址，然后通过`container`网络模式让这些容器共享同一个网络命名空间。
- **Pod间通信**：这里是Flannel等网络插件要解决的事情，即为Pod分配IP、修改路由表并封装数据做正确转发。
  - **实现**：每一个宿主机上运行名为`flanneld`代理，同过etcd维护节点间的路由表用于转发：
    - `flanneld`启动时从etcd中读取配置信息、请求获取子网的租约、并为每个Pod分配IP。
    - 创建虚拟网卡`flannel0`并链接`docker0`网桥
    - 当数据包到来，通过UDP封装转发给目的节点的网卡。对端数据到达后通过flannld解包，发送至`docker0`网桥再转发。
- **Pod和服务间通信**：Pod是不稳定的，所以Pod的IP也是不稳定的。K8s引入Service的概念，来做IP的重定向。Pod通过访问虚拟IP（指service的`ClusterIP`）来访问对应的服务（指Pod的实际IP）。维护`ClusterIP`到实际地址的任务由`kube-proxy`来承担。
  - `kube-proxy`具体实现有三种代理模式。他们都是根据Service配置中的`selector`，查找并根据对应Pod的对应Endpoint中的`IP`和`port`，来访问具体的`IP:port`网络服务。
  - **userspace代理模式**：每一个 Service 都会在当前的节点上开启一个端口，通过iptables转发至`kube-proxy`做软路由。
    - **缺点**：用户空间下转发效率低。
  - **iptables代理模式**：`kube-proxy`监听Service变化，使用 iptables 转发当前节点上的全部流量。数据不通过`kube-proxy`而是内核iptables。
    - **缺点**：当集群中的节点数量非常多时，每次匹配时都会遍历所有 Service ，每次增加新规则也会非常慢。（ Service 达到 5,000 个，每增加一条规则都需要耗时 11min，当集群中的 Service 达到 20,000 个时，每增加一条规则都需要消耗 5h）
  - **ipvs代理模式**：使用哈希表作为底层的数据结构并且工作在内核态。也使用了iptable作为依赖。在v1.11成为稳定版本。
    - ipvs 就是用于解决在大量 Service 时，iptables 规则同步变得不可用的性能问题。
    - ipvs 和 iptables 都是基于netfilter的，只不过有更多的负载均衡算法和更高的性能。
- **外部和服务间通信**：
  - **`NordPort`**：`kube-proxy`在节点上暴露一个监听端口`NodePort`，请求根据`kube-proxy`实现转发。
  - **`LoadBalanncer`**：云平台创建新的IP，再将请求映射到具体的`NodePort`上。
  - **`Ingress`**：不同云厂商有不同的实现，开源的`ingress-nginx`是封装了nginx，在集群中用`ClusterIP`的service来做转发。所以它跳过了kube-proxy的转发。

![kubernetes-flannel](/static/image/2022-02-28/kubernetes-flannel.png)



### Q：镜像的下载策略？

Kubernetes的镜像下载策略有三种：

- **Always**：总是从指定的仓库中获取镜像。
- **Never**：禁止从仓库中下载镜像，也就是说只能使用本地镜像。
- **IfNotPresent**：仅当本地没有对应镜像时，才从目标仓库中下载。

默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签不是latest，那么默认策略是IfNotPresent。



### Q：静态Pod是什么？

静态 Pod 直接由特定节点上的 kubelet 进程来管理，并且始终绑定在某⼀个kubelet运⾏在同⼀个节点上，不通过 master 节点上的 apiserver。⽆法与我们常⽤的控制器 Deployment 或者 DaemonSet 进⾏关联，kubelet 直接监控每个Pod，并在故障失效时进行重启自愈。

kubelet会为每个它管理的静态Pod，调用api-server在 Kubernetes 的 apiserver 上创建⼀个镜像 Pod（Mirror Pod）。因此我们可以在 apiserver 中查询到该 Pod，也能通过kubectl等方式进行访问，但是不能通过 apiserver 进⾏控制。

**作用**

因为使用静态Pod可以有效预防通过kubectl、或管理工具操作的误删除，可以利用它来部署一些核心组件应用，保障应用服务总是运行稳定数量和提供稳定服务。其主要用途是运行自托管的控制面。



### Q：Pod的生命周期和重启策略

**Pod生命周期**

- 起始于 `Pending` 阶段如果至少 其中有一个主要容器正常启动，则进入 `Running`，之后取决于 Pod 中是否有容器以 失败状态结束而进入 `Succeeded` 或者 `Failed` 阶段。
- Pod 在其生命周期中**只会被调度一次**。 一旦 Pod 被调度（分派）到某个节点，Pod 会一直在该节点运行，直到 Pod 停止或者 被[终止](https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination)。
- **Pod 自身不具有自愈能力。**如果 Pod 被调度到某[节点](https://kubernetes.io/zh/docs/concepts/architecture/nodes/) 而该节点之后失效，或者调度操作本身失效，Pod 会被删除；与此类似，Pod 无法在节点资源 耗尽或者节点维护期间继续存活。Kubernetes 使用一种高级抽象，称作 [控制器](https://kubernetes.io/zh/docs/concepts/architecture/controller/)，来管理这些相对而言 可随时丢弃的 Pod 实例。新 Pod 的名字可以不变，但是其 UID 会不同。
- 如果某物声称其生命期与某 Pod 相同，例如存储[卷](https://kubernetes.io/zh/docs/concepts/storage/volumes/)， 这就意味着如果 Pod 因为任何原因被删除，甚至某完全相同的替代 Pod 被创建时， 这个**相关的对象也会被删除并重建**。

| 取值        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| `Pending`   | Pod 已被 Kubernetes 系统接受，但有**一个或者多个容器尚未创建亦未运行**。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间， |
| `Running`   | Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。**至少有一个容器仍在运行**，或者正处于启动或重启状态。 |
| `Succeeded` | Pod 中的**所有容器都已成功终止**，并且不会再重启。           |
| `Failed`    | Pod 中的所有容器都已终止，并且**至少有一个容器是因为失败终止**。也就是说，容器以非 0 状态退出或者被系统终止。 |
| `Unknown`   | 因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。 |

**容器生命周期**

一旦将 Pod 调度给某个节点，`kubelet` 就通过 [容器运行时](https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes) 开始为 Pod 创建容器。

你可以使用[容器生命周期回调](https://kubernetes.io/zh/docs/concepts/containers/container-lifecycle-hooks/) 来在容器生命周期中的特定时间点触发事件。

| 取值         | 描述                                             |
| ------------ | ------------------------------------------------ |
| `Waiting`    | 仍在运行它完成启动所需要的操作                   |
| `Running`    | 表明容器正在执行状态并且没有问题发生。           |
| `Terminated` | 已经开始执行并且或者正常结束或者因为某些原因失败 |

**容器重启策略**

Pod 的 `spec` 中包含一个 `restartPolicy` 字段，其可能取值包括 Always、OnFailure 和 Never。默认值是 Always。

`restartPolicy` 适用于 Pod 中的所有容器。`restartPolicy` 仅针对同一节点上 `kubelet` 的容器重启动作。当 Pod 中的容器退出时，`kubelet` 会按**指数回退** 方式计算重启的延迟（10s、20s、40s、...），其最长延迟为 5 分钟。 一旦某容器执行了 10 分钟并且没有出现问题，`kubelet` 对该容器的重启回退计时器执行 重置操作。


- Always：当容器失效时，由kubelet自动重启该容器。
- OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器。
- Never：不论容器运行状态如何，kubelet都不会重启该容器。



### Q：如何检查Pod的健康状态？健康检查机制？

健康检查用于检测您的应用实例是否正常工作，是保障业务可用性的一种传统机制，一般用于负载均衡下的业务，如果实例的状态不符合预期，将会把该实例“摘除”，不承担业务流量。

- **存活探针**：很多情况下服务出现问题，进程却没有退出，如系统超载 5xx 错误，资源死锁等。
  - 若检查失败**则杀死Pod，重新启动一个并替换**。

- **就绪探针**：就绪探针旨在让Kubernetes知道你的应用**是否准备好为请求提供服务**。
  - 如果就绪探针检测失败，**服务将停止向该容器发送流量，直到它通过检测**。



### Q：失效 Pod 的垃圾收集？

对于已失败的 Pod 而言，对应的 API 对象仍然会保留在集群的 API 服务器上，直到用户或者控制器进程显式地将其删除。

控制面组件会在 Pod 个数超出所配置的阈值时，删除已终止的 Pod（Succeeded 或 Failed）。 这一行为会避免随着时间演进不断创建和终止 Pod 而引起的资源泄露问题。



### Q：Pod的调度机制？

亲和性和反亲和性是运行时调度策略，主要包括nodeAffinity（主机亲和性）、podAffinity（pod亲和性）、podAntiAffinity（pod反亲和性）三类。

- **nodeAffinity**：规定pod可以部署在哪个node或者不能部署在哪个节点上。定义Pod和主机间的关系。
- **podAffinity**：规定pod可以和哪些pod部署在同一拓扑结构下。定义Pod间的关系。
- **podAntiAffinity**：规定pod不可以和哪些pod部署在同一拓扑结构下。定义Pod间的关系。
  - 当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，以提高可用性。

三种Affinity使用时都有两种规则可以设定：

- **requiredDuringSchedulingIgnoredDuringExecution**：严格匹配规则调度，否则不调度在过滤阶段执行
  - 首次调度严格匹配。在Pod运行过程中忽略。
- **preferredDuringSchedulingIgnoredDuringExecution**：尽力执行，优先满足规则调度，在打分阶段执行
  - 首次调度偏好规则。在Pod运行过程中忽略。

**对称性**：多个Pod需要同时设定亲和性/反亲和性的情况

- 反亲和性具备对称性：如果没有设定反亲和的Pod，在设定反亲和的Pod之后被调度，那么它们也有可能调度到一个节点上。
- 硬亲和性不具备对称性：因为第一个调度的Pod时，没有可以亲和的Pod。



### Q：Pod创建和终止过程？

**Pod创建过程**

- 执行kubectl命令创建pod，根据kubeconfig的配置向kube-apiserver发送创建请求
- `kube-apiserver`存储Pod数据
  - 向Pod对象写入一些系统默认数据`defaulter`；检查Pod对象字段是否有效`validator`
  - 在 etcd 中持久化这个对象
- `kube-scheduler`监听未绑定的Pod，并开始调度尝试分配主机。
  - **监听机制**：由etcd的`watch + list`提供
  - **节点预选**：基于一系列过滤规则，将不符合的节点过滤掉
  - **节点优选**：为符合要求的主机计算权重。对预选出的节点进行优先级排序，以便选出最适合运行 pod 对象的节点。
  - 进行bind将Pod和Node绑定，结果存储到etcd中。
- `kubelet`监听绑定的Pod，尝试启动Pod。
  - **启动前配置**：为该Pod挂载外部卷、创建`pause`容器以配置后续Pod可加入的网络`container:pause`等
  - `docker run` & 监控并更新Pod状态

![pod-starting](/static/image/2022-02-28/pod-starting.png)

**Pod终止过程**

- 用户发出删除 pod 命令
- `kube-apiserver`在etcd创建优雅退出的信息，并将Pod标记为“Terminating”状态
- `kubectl`监听退出状态的Pod，尝试停止Pod
  - 通过容器运行时，向容器发出`SIGTERM`；若监听到的优雅退出时间过期，发送`SIGKILL`信号
  - 开始`preStop`回调
- 与上一步同时：`endpoint-controller`监听到Pod关闭，将对应Service匹配的Endpoint删除
- `kube-apiserver`受到删除成功响应后，删除etcd对应Pod信息。

![pod-stopping](/static/image/2022-02-28/pod-stopping.png)



### Q：Init和Sidecar容器是什么？

- **Init容器**：在Pod内的应用容器启动之前运行并退出，用于做某种配置操作。
  - 在 Pod 启动前，在网络和数据卷初始化之后，每个Init 容器会按顺序依次启动退出（同时只有一个Init容器存在）。
  - 注意：Init容器不支持探针和生命周期
- **Sidecar容器**：在应用容器运行的同时，利用Sidecar容器可以做到一些相同生命周期的长时间操作。

![init-and-sidecar](/static/image/2022-02-28/init-and-sidecar.gif)



### Q：Deployment升级过程？发布策略？

> - https://www.qikqiak.com/post/k8s-deployment-strategies/
> - https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247489100&idx=1&sn=eab291eb345c074114d946b732e037eb&source=41#wechat_redirect

Deployment会在`.spec.strategy.type==RollingUpdate`时，采取滚动更新的方式更新 Pods。可以指定 `maxUnavailable` 和 `maxSurge` 来控制滚动更新过程：

- `maxSurge`最大激增数, 指更新过程中, 最多可以比replicas预先设定值多出的pod数量，默认25%
- `maxUnavailable`最大无效数, 指更新过程中, 最多有几个pod处于无法服务状态, 整个更新过程中, 会有maxUnavailable个pod处于Terminating状态，默认25%。

下面是一些发布过程的Deployment实现方式：

- **金丝雀发布 / 灰度测试**：先发布一台或者一个小比例规模，以便做验证。
  - **实现**：发布Service时，选取正常版本和金丝雀版本。当使用金丝雀时，多发布一个金丝雀，并缩小一个正常版本即可。
- **滚动式发布**：依次将老版本流量从上摘除，再发布新版本。尽量保证用户体验不受影响。
  - **实现**：`maxSurge: 1`、`maxUnavailable: 0`
- **蓝绿发布**：V1 版本称为蓝组，V2 版本称为绿组，发布时通过 LB 一次性将流量从蓝组直接切换到绿组
  - **实现**：`maxSurge: 100%`、`maxUnavailable: 0`

**一些其他发布策略**

- **功能开关发布**：新功能（V2 new feature）和老功能（V1 old feature）住在同一套代码中，新功能隐藏在开关后面，如果开关没有打开，则走老代码逻辑，如果开关打开，则走新代码逻辑。
  - 需要一个配置中心或者开关中心这样的服务支持
- **A/B 测试**：为了验证 V2 的功能正确性，同时也为了避免 V2 有问题时影响所有用户，先通过 LB 将手机端的流量切换到 V2 版本，经过一段时间的 A/B 比对测试和观察（主要通过用户和监控反馈），确保 V2 正常，则通过 LB 将全部流量切换到 V2。
  - 功能开关和 A/B 测试有点相似，但功能开关一般是无状态和全量的
- **影子测试**：对于一些涉及核心业务的遗留系统的升级改造，为了确保万无一失，有一种称为影子测试的大招，采用比较复杂的**流量复制、回放和比对技术**实现。



### Q：HPA自动扩容机制？

Kubernetes使用Horizontal Pod Autoscaler（HPA）的控制器，基于CPU使用率进行自动Pod扩缩容。HPA控制器周期性地监测目标Pod的资源性能指标，并与HPA资源对象中的扩缩容条件进行对比，在满足条件时对Pod副本数量进行调整：

- Kubernetes中的某个Metrics Server（Heapster或自定义Metrics Server）持续采集所有Pod副本的指标数据。HPA控制器通过Metrics Server的API（Heapster的API或聚合API）获取这些数据，基于用户定义的扩缩容规则进行计算，得到目标Pod副本数量。
- 当目标Pod副本数量与当前副本数量不同时，HPA控制器就向Pod的副本控制器（Deployment、RC或ReplicaSet）发起scale操作，调整Pod的副本数量，完成扩缩容操作。



### Q：数据持久化的方式有哪些？

Kubernetes通过数据持久化来持久化保存重要数据，常见的方式有：

- **EmptyDir / 空目录**：不指定要挂载位置，直接映射到宿主机上。
  - 当pod节点删除时，volume的数据也会被删除。
  - **场景**：只需要临时将数据保存在磁盘上，比如在合并/排序算法中；
- **hostPath**：将宿主机上已存在的目录或文件挂载到容器内部。
  - **场景**：要访问宿主机上的内容，如需要访问宿主机容器运行时socket。
- **NFS**：**场景**：最简单的一种云存储方案
- **PersistentVolume**：维护一个存储池，可以在创建Pod时请求存储资源，同时屏蔽处理基础设施的细节
  - 如基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理。



### Q：CRD是什么？运作流程如何？

通过 CRD 我们可以向 Kubernetes API 中增加新资源类型，而不需要修改 Kubernetes 源码来创建自定义的 API server，该功能大大提高了 Kubernetes 的扩展能力。

- 编写CRD的配置时，我们需要确定GVK、配置规格`spec`和validator等信息。这只是为了让`kube-apiserver`有存储对象的能力。
- 我们还需要创建controller来监听并协调对象状态：一般用`controller-runtime`来做开发，它包含了各种Controller常用的模块，兼顾了灵活性和模块化。
  - **Controller**：控制器通过响应事件（对象创建，更新，删除）以协调在对象的规范中指定的状态可以匹配系统的状态。这个过程成为**Reconcile / 协调**。

# 数据结构与算法


## 基础

### Q：了解哪些排序算法，并比较一下，以及适用场景

> https://blog.csdn.net/mountain_hua/article/details/81107024

| 排序法     | 最差时间分析 | 平均时间复杂度 | 稳定度 | 空间复杂度      |
|------------|--------------|----------------|--------|-----------------|
| 冒泡排序   | O(n2)        | O(n2)          | 稳定   | O(1)            |
| 插入排序   | O(n2)        | O(n2)          | 稳定   | O(1)            |
| 选择排序   | O(n2)        | O(n2)          | 稳定   | O(1)            |
| 二叉树排序 | O(n2)        | O(n*log2n)     | 不一顶 | O(n)            |
| 快速排序   | O(n2)        | O(n*log2n)     | 不稳定 | O(log2n) ~ O(n) |
| 堆排序     | O(n*log2n)   | O(n*log2n)     | 不稳定 | O(1)            |
| 希尔排序   | O            | O              | 不稳定 | O(1)            |




### Q：快排的基本思路是什么？最差的时间复杂度是多少？如何优化？

> 优化：https://blog.csdn.net/sinat_28676875/article/details/69053449

```c++
int sort(vector<int>& nums, int l, int r) {
    if (l >= r) return;
    int ra = rand() % (r - l + 1) + l;
    swap(nums[ra], nums[l]);

    int i = l, j = r, x = nums[l];
    while (i < j) {
        while (i < j && nums[j] >= x) j--;
        if (i < j) nums[i++] = nums[j];

        while (i < j && nums[i] <= x) i++;
        if (i < j) nums[j--] = nums[i];
    }

    nums[i] = x;
    sort(nums, l, i, k);
    sort(nums, i+1, r, k);
}

```

优化方法：

1. 随机选择比较值
2. 元素少时用插入排序
3. 三向切分：大小关系分开后，将相等项排除递归


# 语言方面


## Rust



### Q：宏与过程宏

宏用于在编译时利用AST生成代码，它分为声明宏和过程宏。

声明宏利用`match`结构匹配AST，进行代码展开

过程宏直接处理词素流生成代码，它分为三种：

1. 导出宏：用于结构体自动实现，如`#[derive(Debug)]`
2. 类属性宏：用于自定义属性，如定义一个路由`#[route(GET, "/")]`
3. 类函数宏：将词素作为参数，比函数和声明宏更灵活。如定义SQL语句`let sql = sql!(SELECT * FROM posts WHERE id=1);`



### Q：Box

Box 首先是一个智能指针  

1. 智能指针是一类数据结构，他们的表现类似指针，但是也拥有额外的元数据和功能。

2. 在大部分情况下，相较于普通指针，智能指针拥有他们指向的数据。

3. 智能指针实现了 Deref 和 Drop trait。Deref trait 允许智能指针结构体实例表现的像引用一样，这样就可以编写既用于引用、又用于智能指针的代码。Drop trait 允许我们自定义当智能指针离开作用域时运行的代码。

4. 智能指针的实现采用内部可变性模式，指不可变类型能够暴露出改变其内部值的 API。

box 允许你将一个值放在堆上而不是栈上。它们多用于如下场景：

1. 当有一个在编译时未知大小的类型，而又想要在需要确切大小的上下文中使用这个类型值的时候

2. 当有大量数据并希望在确保数据不被拷贝的情况下转移所有权的时候

3. 当希望拥有一个值并只关心它的类型是否实现了特定 trait 而不是其具体类型的时候



### Q：Trait Object

trait 对象指向一个实现了我们指定 trait 的类型的实例，以及一个用于在运行时查找该类型的trait方法的表。此处涉及**动态大小类型和动态绑定原理**

1. trait 本身也是一种类型，但他的大小在编译期是无法确定的，所以必须要使用指针包裹。
2. trait 对象包括 **data 指针和 vtable 指针**。<br>data 指针指向**堆上**具体的类型数据； <br>vtable 指针指向**静态只读区上**实现 trait 的虚表，包括方法和类型大小等信息。
3. 使用条件：指定的 trait 中`Self`不可限定为`Sized`；trait 中所有方法类型安全（无泛型参数，返回值非`Self`）。



### Q：Trait Object 对象安全

trait 对象本身是动态分发的，编译器无法确定`Self`具体是哪个类型。

1. 指定的 trait 中`Self`不可限定为`Sized`

   无法确定`Self`具体是哪个类型，也就无法确定大小

2. 所有方法无泛型参数（一个方法有类似`fn foo<T>(&self, a: T)`的签名）

   rust的泛型是静态分发的，即单态化。<br>若一个方法带有泛型参数，则会在内存静态区的虚表中**单态化展开**所有对应的**具体类型**和对应的**泛型参数**。这是巨大的开销。

3. 所有方法仅第一个参数包含`Self`（如`self` `&self` `Box<self>`等）

   没有`Self`就是关联方法，只能用具体类型名调用（如`String::from`），使用不到 trait 对象。

4. 所有方法所有返回值非`Self`

   无法确定`Self`具体是哪个类型，所以无法返回。



### Q：动态分发和静态分发

**静态分发**

单态化是将通用代码转换为特定代码的过程。编译器使用泛型代码针对具体类型生成代码。我们可以使用泛型来编写不重复的代码，而 Rust 将会为每一个实例编译其特定类型的代码。这意味着在使用泛型时**没有运行时开销**，但同时容易出现**二进制文件膨胀**缺陷。

**动态分发**

使用一个运行时查找具体类型的trait方法的虚表，来实现Trait对象的方法。Trait 对象包含data指针和vtable指针，用于指向堆上的具体实例和静态区的对应虚表。当调用发生时，Trait 对象将根据虚表指针从虚表中查找正确的指针，然后动态调用对应方法。



### Q：Drop & Deref

实现 `Deref` trait 允许我们重载 **解引用运算符**。通过这种方式实现 `Deref` trait 的智能指针可以被当作常规引用来对待，可以编写操作引用的代码并用于智能指针

 `Drop`允许我们在值要离开作用域时执行一些代码。可以为任何类型提供 `Drop` trait 的实现，同时所指定的代码被用于释放类似于文件或网络连接的资源。



### Q：解引用强制多态

**解引用强制多态**是 Rust 在函数或方法传参上的一种便利。当引用作为实参传递和或调用方法时，解引用强制多态将自动发生。这时会有一系列的 `deref` 方法被调用，把我们提供的类型转换成了参数所需的类型。



## Java



### Q：异常与错误

> https://blog.csdn.net/qq_29229567/article/details/80773970

**Throwable**： 有两个重要的子类：Exception（异常）和 Error（错误）。异常能被程序本身可以处理，错误是无法处理。



**Error（错误）:**

- 是程序无法处理的错误，表示运行应用程序中较严重问题。大多数表示代码运行时 JVM 出现的问题。
- 无法捕获。

**Exception（异常）:**

- 是程序本身可以处理的异常。
- Exception 类有一个重要的子类  RuntimeException。RuntimeException 类及其子类表示“JVM  常用操作”引发的错误。例如，若试图使用空值对象引用、除数为零或数组越界，则分别引发运行时异常（NullPointerException、ArithmeticException）和 ArrayIndexOutOfBoundException。
- 而其他异常皆可捕获，即**可查异常**。



### Q：解释一下IoC和DI

IoC即控制反转，它最核心的地方在于，资源不由使用资源的双方管理，而由不使用资源的第三方管理，这可以带来很多好处：

- 资源集中管理，实现资源的可配置和易管理。
- 降低了使用资源双方的依赖程度，也就是我们说的耦合度。



DI即依赖注入，通过DI，对象的依赖关系将由系统中第三方组件在创建对象的时候进行设定，对象无需自行创建管理它们的依赖关系，依赖关系将被自动注入到需要它们的对象当中去。



## Java 并发

依次介绍 Java 容器、Java 锁、Java 线程相关内容。



### Q：HashMap 原理与不安全原理

>[HashMap 底层数据结构分析](https://snailclimb.gitee.io/javaguide/#/docs/java/collection/HashMap(JDK1.8)%E6%BA%90%E7%A0%81+%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90)
>
>[HashMap为什么线程不安全](https://juejin.cn/post/6917526751199526920)

**数据结构 - JDK8之前**

JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。

- 过程：HashMap 通过 key 的 hashCode 经过**扰动函数**处理过后得到 hash 值，然后通过 **`(n - 1) & hash`** 判断当前元素存放的位置。若冲突则用链地址法（拉链法）。
- 扰动函数：为了防止一些实现比较差的 hashCode() 方法，可以减少碰撞。



**数据结构 - JDK8之后**

JDK1.8 之后 HashMap 的组成多了红黑树，在满足下面两个条件之后（链表长度大于阈值（默认为 8）、HashMap 数组长度超过 64），会执行链表转红黑树操作，以此来加快搜索速度。若数组长度不大于64,则使用`resize()`进行扩容。

- 阈值：`threshold = capacity * loadFactor`，当容纳的元素数量大于等于阈值后，需要扩增数组。
- 加载因子：loadFactor 加载因子是控制数组存放数据的疏密程度，越趋近于 1，会让链表的长度增加；**loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。**
- 扩容：扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。



**线程不安全 - JDK8之前**

发生在多线程扩容时，在A线程扩容的过程中被挂起，同时B线程唤醒完成了扩容，等到A线程运行时会继续扩容，导致**链表死循环**和**数据丢失**。

```java
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while (null != e) {
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            e.next = newTable[i];
            // 此处挂起
            newTable[i] = e;
            e = next;
        }
    }
}
```



**线程不安全 - JDK8之后**

发生在`put`操作中，A线程在确定了hash索引并发现表中不存在链表时被挂起，此时B线程唤醒完成了`put`，此时A线程唤醒仍认为不存在链表，继续填入了新节点，导致**数据覆盖**。

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 此处挂起
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);

	...
}
```



### Q：ConcurrentHashMap 原理

**数据结构 - JDK1.8之前**

用分段数组+链表实现，将数组分为多个段，每个`Segment`段分配一个分段锁。当多线程访问不同的分段时，不存在锁竞争，提高并发度。

一个 `ConcurrentHashMap` 里包含一个 `Segment` 数组。`Segment` 是一种数组+链表结构，它包含一个 `HashEntry` 数组，每个 `HashEntry` 是一个链表结构的元素。

`Segment`继承了`ReentrantLock`，当对 `HashEntry` 数组的数据进行修改时，必须首先获得对应的 `Segment` 的锁。



**数据结构 - JDK1.8之后**

与1.8之后的 HashMap 一致，使用数组 + 链表/红黑树实现。并发控制则使用`synchronized`和CAS进行。

`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发。



### Q：HashTable 原理

数据结构与JDK1.8之前的 HashMap 一致（数组+链表），读写的并发控制全部使用全表锁（`synchronized`）进行，效率不高。



### Q：ThreadLocalMap 原理

这里讲容器顺便写一下`ThreadLocalMap`，需要注意的是 Hash 算法和它的内存泄漏原理与解决方法。



**数据结构**

每个`Thread`中保存有一个`threadLocalMap`，其中保存了单个`ThreadLocalMap.Entry`数组。其中`ThreadLocalMap.Entry`继承`WeakReference<ThreadLocal<?>>`，键为`ThreadLocal<?>`，值为`Object`。



**Hash 算法**

是开放地址法的线性探查方法，使用的 Hash 函数则是 fibonacci 函数。

斐波那契散列法是一种特殊的乘法散列，散列函数为h(k)=[m(kA mod 1)]。一般来说，m取值为2^p。关于A的取值，knuth为了得到更好的随即性， 认为A去黄金分割数是一个比较理想的值，因此A=0.6180339887。

所以你可以在`ThreadLocal`源码中发现一个`HASH_INCREMENT = 0x61c88647`。每当创建一个`ThreadLocal`对象，这个`ThreadLocal.nextHashCode` 这个值就会增长 `0x61c88647` 。



**内存泄漏原理**

注意到`Entry`继承了`WeakReference<ThreadLocal<?>>`，它的构造函数不难记：

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        this.value = v;
    }
}

// 获取键： e.get()
// 获取值： e.value
```

当内存中只存在键的弱引用时（即该线程中没有再引用`ThreadLocal`，这里注意即使键不引用，但值还是会在其他地方正常使用），下一次GC会清理掉`ThreadLocalMap`中的键，使得键变为`null`。但`value`则因为强引用而永远不会被清除，如果其他地方没有使用`value`的话，就会导致内存泄漏。

`ThreadLocalMap`的解决方法则是在`set() get() remove()`函数中进行线性探查的替换和消除键为`null`的`Entry`。

最好的方法还是在不需要引用`ThreadLocal`时，手动`remove`释放它。



### Q：原子类原理 CAS的思想

Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。要么失败要么成功。

四种原子类：

1. 基本类型：`AtomicInteger`，`AtomicLong`，`AtomicBoolean`
2. 引用类型：`AtomicReference`，`AtomicStampedReference`，`AtomicMarkableReference`
3. 数组类型：`AtomicIntegerArray`
4. 对象字段更新器：`AtomicIntegerFieldUpdater`



**原理**

AtomicInteger 类主要利用 CAS + volatile 的方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

底层依赖`Unsafe`类的CAS操作，降实例字段对应的offset进行修改的一种API方式。



**CAS的思想**

> http://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf

CAS将读写化作一个原子性操作，首先比较一个早已读出的值，如果相同则交换。

如果操作成功，说明读出值到CAS操作的这段时间中，没有其他线程能早于本线程完成（排除ABA问题，可以通过扩大状态空间解决）。这样能**保证竞争的正确进行**。

为什么能保证竞争的正确进行？让竞争有效的基础是，有能够验证本线程是首先完成的能力。详细展开它：

1. 我们首先需要知晓其他线程的状态，即能够知道他们其中是否存在已经完成的线程。
2. 其次本线程在获知自己是首先完成的情况下，如何让其他线程知晓本线程已经优先完成。
3. 必须将以上二者结合，否则会出现所有线程同时知晓自己优先完成的情况。

如果有其他线程先完成操作，那么本次读出值到CAS操作的代码必须应失去意义，因为这不被认为是竞争到的产物。



### Q：volatile 关键字

**Java 内存模型**

1. 介绍JMM：屏蔽硬件和操作系统的内存访问差异，达到一致性内存访问的效果，关注变量如何存储与内存和从内存读取的底层细节。
2. JMM的内存结构：规定线程存在独占的工作内存，其中存储了主存的数据副本；线程必须只能存工作内存中读写，工作内存和主存的交互有8种操作并且需要按照一定的规则（read load use assign store write lock unlock）「特例」
   1. assign 的数据不可丢弃
   2. lock 清除工作内存对应的值
   3. unlock 将工作内存的值写回主存
   4. load&read  store&write顺序而非连续。
3. 并发编程三个特性
   1. **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。`synchronized` 可以保证代码片段的原子性。
   2. **可见性** ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。
   3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化



**volatile 关键字**

1. volatile作用
   1. 保证可见性：对变量的写，保证其他线程能立即读到最新的值 
   2. 禁止重排序：一般在cpu处理汇编语句时考虑单线程表现为串行语义，而相互不依赖的两个语句会进行重新排序，进行并行执行。volatile会在某些场景下禁止重排序（读写写读）。
2. volatile实现原理
   1. 可见性: use&load&read assign&store&write  可认为连续执行，效果是读取前刷新工作内存、写入后刷新工作内存。 
   2. 有序性：
      1. 重排序在java编译器和cpu层面都有涉及，底层上通过内存屏障使cpu禁止重排序
      2. 使用lock汇编前缀可以提供缓存刷新的功能，同时也能将受到影响的cpu刷新内存
      3. 为什么lock前缀可以当作内存屏障？cpu重排序的过程是必须按照一定规则，不能使代码逻辑发生改变。当lock起效后，可以认为之前所有的代码执行完毕。



### Q：synchronized 原理与锁升级

**概念与历史**

`synchronized`关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

在JDK1.6前，它属于重量级锁。因为`synchronized`实现依赖于操作系统的锁，而操作系统的实现会直接将线程从用户态切换进入内核态，耗时较多效率低。

在JDK1.6之后，大量的优化提高了它的效率，优化手段有：**偏向锁**、**轻量级锁**（十次自旋锁、适应性自旋锁）、**锁粗化**（合并锁，降低锁请求）、**锁消除**（大量的`synchronized`实际上只在单线程中运行，开启逃逸分析后可以进行锁消除，当需要锁的对象不会逃逸出函数栈或线程则消除锁）。



**使用方法**

加在实例方法上；加在静态方法上；加在实例对象上

注意：

1. 静态方法上的锁，和`Xxx.class`的锁相同。
2. 实例方法上的锁，和实例对象的锁相同。
3. 实例对象和类对象的锁不互斥。
4. 构造方法不能修饰`synchronized`，因为它本身是线程安全的，不存在两个线程同时竞争构造一个对象。



**原理**

`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 对象监视器 `monitor` 的持有权（每个对象中都内置了一个 `ObjectMonitor`）。如果锁的计数器为 0 则表示锁可以被获取，或可释放。

另外，`wait/notify`等方法也依赖于`monitor`对象，这就是为什么只有在同步的块或者方法中才能调用`wait/notify`等方法，否则会抛出`java.lang.IllegalMonitorStateException`的异常的原因。



jvm 的`synchronized`方法使用了`ACC_SYNCHRONIZED` 标识指明该方法是一个同步方法。在调用和返回的指令中，隐式处理了调用同步方法时进入的监视器入口和返回时退出的监视器，就像使用了`monitorenter`和`monitorexit`一样。



**锁升级**

JDK1.6之后，`synchronized`锁的级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。

锁可以升级, 但不能降级. 即: 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁是单向的。锁的降级实际上是存在的，但是没有实用价值。这种策略是为了提高获得锁和释放锁的效率。

锁的状态被存储于 markword 中，001无锁、101偏向锁、00轻量级锁、10重量级锁。（11为GC存活标记）。

![synchronized](/static/image/2021-03-24/synchronized.png)



**偏向锁**

它的依据在于，大多数同步代码只会在同一个线程中被执行。

当线程获取锁时，jvm会在对象的 markword 中修改锁状态为101，并通过 CAS 将线程ID写入进去。

偏向锁不会解锁，只会撤销。当后续进入同步代码时，只需要判断线程ID是否相同即可。

当其他线程通过 **CAS 获取偏向锁失败**，并在safepoint时发现原线程**仍在同步代码**中时，它会升级成为轻量级锁。



**轻量级锁 - 自旋锁**

它的依据在于，大多数同步代码在同一个时间只会有一个线程进入。或者说对于同步代码，多个线程是交替进入的。

当线程获取锁时，会将当前栈中申请一个锁记录空间。将对象的 markword 记录于其中，并在 markword 中用 CAS 写入锁记录空间的地址，并改写锁状态00。（锁记录空间还会记录对象的地址。）如果 CAS 失败，表示存在锁的竞争，当前线程则开始自旋获得锁。

轻量级锁解锁时, 会使用原子的 CAS 操作将当前线程的锁记录替换回到对象头。

关于锁升级，JDK1.6下：如果在自旋一定次数后仍未获得锁，那么轻量级锁将会升级成重量级锁。JDK1.6 后：适应性自旋锁。



这里提一下自旋锁（一般用CAS）和互斥锁的优缺点：

1. 自旋锁在`while`循环中忙等，不会引发线程的阻塞就绪运行等耗时操作。当竞争程度不高并且同步代码快速时，适合使用。
2. 互斥锁在同步中，触发线程阻塞。当排队线程多并且代码慢速时适用。



**重量级锁**

直接调用操作系统底层的互斥量，会引发线程阻塞和就绪等耗时操作，但为长时间排队的线程提供了足够的并发量。



### Q：ReentrantLock 和 synchronized 区别与实现原理

可重入锁指的是自己可以再次获取自己的内部锁。如果是不可锁重入的话，就需要特殊处理否则会造成死锁。

1. 前者为API实现，后者由JVM实现。
2. 高级功能：
   - **等待中断**：`lockInterruptibly`线程在请求lock并被阻塞时，如果被interrupt，则“此线程会被唤醒并被要求处理InterruptedException”。
   - **公平锁**：先等待的线程先获得锁
   - **选择性通知**：`synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。



**线程的打扰机制**

每个线程都有一个 打扰 标志。这里分两种情况，

1. 线程在`sleep`、`wait`或`join`， 此时如果别的进程调用此进程的 `interrupt`方法，此线程会被唤醒并被要求处理InterruptedException；(thread在做IO操作时也可能有类似行为，见java thread api)
2. 此线程在运行中， 则不会收到提醒。但是 此线程的 “打扰标志”会被设置， 可以通过isInterrupted()查看并 作出处理。



**实现原理**

1. 可重入：使用计数器，进入时加一，释放时减一，当0时才进入或释放。
2. 公平锁：使用CLH队列锁，即虚拟队列中自旋等待前驱线程的锁释放。



### Q：AQS 原理

AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 `ReentrantLock`，`Semaphore`。



**原理**

1. 通过一个共享变量`volatile int state`表示共享资源，一个基于CLH的虚拟队列提供线程阻塞和唤醒机制。
2. 使用模板方法模式，具体的子类继承并覆写`tryAcquire - tryRelease`和`tryAcquireShared - tryReleaseShared`即可实现独占或共享资源的同步器。不用考虑调度等问题。



**经典CLH队列锁**

CLH队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。

CLH  锁是对自旋锁的一种改进，有效的解决两个缺点：不公平和多处理器频繁直接访问同一状态变量。

1. 首先它将线程组织成一个队列，保证先请求的线程先获得锁，避免了饥饿问题。
2. 其次锁状态去中心化，让每个线程在不同的状态变量中自旋，这样当一个线程释放它的锁时，只能使其后续线程的高速缓存失效，缩小了影响范围，从而减少了 CPU 的开销。

```java
class ClhLock {
    private final AtomicReference<Node> tail = new AtomicReference<>(new Node());
    private final ThreadLocal<Node> curNode = ThreadLocal.withInitial(Node::new);
    private final ThreadLocal<Node> preNode = ThreadLocal.withInitial(() -> null);

    public void lock() {
        Node node = curNode.get();
        node.locked = true;
        Node prev = tail.getAndSet(node);
        preNode.set(prev);
        while (prev.locked);
    }

    public void unlock() {
        Node node = curNode.get();
        node.locked = false;
        curNode.set(preNode.get());
    }

    static class Node {
        public volatile boolean locked;
    }
}
```



**AQS 对 CLH 队列锁的改造**

1. 将自旋锁改为阻塞线程。
2. 扩展更多功能，如支持超时中断等，显示的维护前后节点。



### Q：各种锁的使用场景

**Semaphore 信号量**

- 用于限制资源的个数，当信号量等于小于0时，再次获得锁将会阻塞。

```java
semaphore.acquire();
semaphore.release();   (InterruptedException)
```



**CountDownLatch 倒计时锁**

- 用于倒计时的功能，当多个线程处理计算后`countDown`，主线程等待`await`直到计时器到0时唤醒。

```java
latch.countDown();
latch.await();   (InterruptedException)
latch.await(timeout, timeUnit);   (InterruptedException)
```



**CyclicBarrier 回环栅栏**

- 用于多个线程间同步，当每个线程共享的`cyclicBarrier`被规定次数的`await`调用后，这些线程才继续执行（或还可运行规定的操作作为回调）。

```java
await() （InterruptedException, BrokenBarrierException
await(timeout, TimeUnit) (InterruptedException,BrokenBarrierException,TimeoutException)
```





### Q：手写自旋锁

> https://www.infoq.cn/article/BVPvyVxjKM8ZSTSpTi0L

1. 如何实现可重入？

   只需记录当前线程并计数。如果当前线程不是锁的所有者，则竞争锁或不释放锁；如果是锁的所有者，则计数器自增或计数器自减释放。

2. 如何实现公平？

   1. 获取锁前，获取一个`ticket`数字，当它与`serviceNumber`相同时，进入。释放锁则CAS`serviceNumber`自增。需要所有线程监听同一个变量，会导致cpu频繁访主存。
   2. CLH自旋锁，每次`my.lock`为真，获取虚拟队列中前一个节点的锁，等待`prev.lock==false`。释放则需要将`my.lock`改为假，并将自己的容器中的节点改为前一个节点。



**可重入自旋锁**

```java
class ReentrantSpinLock implements Lock {
    private final AtomicReference<Thread> owner = new AtomicReference<>(null);
    private int count = 0;

    public void lock() {
        Thread cur = Thread.currentThread();
        if (owner.get() != cur) {
            while (!owner.compareAndSet(null, cur));
        }
        count++;
    }

    public void unlock() {
        Thread cur = Thread.currentThread();
        if (owner.get() == cur && --count == 0)
            owner.set(null);
    }
}
```



**公平可重入自旋锁**

```java
class FairReentrantSpinLock implements Lock {
    private final AtomicInteger counter = new AtomicInteger(0);
    private volatile int serviceNumber = 0;
    private volatile Thread owner = null;
    private int count = 0;

    public void lock() {
        Thread cur = Thread.currentThread();
        if (cur != owner) {
            int ticket = counter.getAndIncrement();
            while (serviceNumber != ticket);
        }

        owner = cur;
        count++;
    }

    public void unlock() {
        Thread cur = Thread.currentThread();
        if (owner == cur && --count == 0) {
            owner = null;
            serviceNumber++;
        }
    }
}
```



**可重入CLH自旋锁**

CLH  锁是对自旋锁的一种改进，有效的解决了以上的两个缺点。

1. 首先它将线程组织成一个队列，保证先请求的线程先获得锁，避免了饥饿问题。
2. 其次锁状态去中心化，让每个线程在不同的状态变量中自旋，这样当一个线程释放它的锁时，只能使其后续线程的高速缓存失效，缩小了影响范围，从而减少了 CPU 的开销

```java
class ReentrantClhSpinLock implements Lock {
    private final AtomicReference<Thread> owner = new AtomicReference<>(null);
    private int count = 0;

    private AtomicReference<Node> tail =  new AtomicReference<Node>(new Node());
    private ThreadLocal<Node> pre = ThreadLocal.withInitial(() -> null);
    private ThreadLocal<Node> cur = ThreadLocal.withInitial(Node::new);

    public void lock() {
        Thread thread = Thread.currentThread();

        if (owner.get() != thread) {
            Node node = cur.get();
            node.locked = true;
            Node prev = tail.getAndSet(node);
            pre.set(prev);
            while (prev.locked);

            owner.set(thread);
        }
        count++;
    }

    public void unlock() {
        Thread thread = Thread.currentThread();
        if (owner.get() == thread && --count == 0) {
            Node node = cur.get();
            owner.set(null);
            node.locked = false;
            cur.set(pre.get());
        }
    }

    static class Node {
        public volatile boolean locked = false;
    }
}
```

它也有两个缺点：

1. 因为有自旋操作，当锁持有时间长时会带来较大的 CPU 开销。
2. 基本的 CLH 锁功能单一，不改造不能支持复杂的功能



### Q：手写单例模式

1. 懒汉式-线程安全

   ```java
   public static synchronized Singleton getUniqueInstance() {
       if (uniqueInstance == null) {
           uniqueInstance = new Singleton();
       }
       return uniqueInstance;
   }
   ```

   

2. 饿汉式-线程安全

   ```java
   private static Singleton uniqueInstance = new Singleton();
   ```

   

3. 懒汉式-线程安全-双重检验锁

   ```java
   public class Singleton {
   
       private volatile static Singleton uniqueInstance;
   
       private Singleton() {
       }
   
       public static Singleton getUniqueInstance() {
           if (uniqueInstance == null) {
               synchronized (Singleton.class) {
                   if (uniqueInstance == null) {
                       uniqueInstance = new Singleton();
                   }
               }
           }
           return uniqueInstance;
       }
   }
   ```

   1. 比单次检验有更好的效率
   2. 使用`volatile`的目的是禁止重排序。`x = new X()`的操作包含了三个原子的过程：申请内存空间、初始化对象、返回内存空间的引用。有时会重排2和3，但这样的话会导致线程A直接拿到引用而线程B通过第一次检验但对象却没有构建完毕。



### Q：ThreadLocal原理

实现每一个线程都有自己的专属本地变量。

每个`Thread`中保存有一个`threadLocalMap`，其中保存了单个`ThreadLocalMap.Entry`数组。其中`ThreadLocalMap.Entry`继承`WeakReference<ThreadLocal<?>>`，键为`ThreadLocal<?>`，值为`Object`。

当为`ThreadLocal`设置变量时，实际上是操作本线程对象的`threadLocalMap`添加或修改键值对。

更多详见上文`ThreadLocalMap`。



### Q：线程池

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。



![threadpool](/static/image/2021-03-25/threadpool.png)



**构造函数参数**

我们一般通过构造函数来创建线程池。

```java
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler
) { ... }
```

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- `keepAliveTime`:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
- `unit` : `keepAliveTime` 参数的时间单位。
- `threadFactory` :executor 创建新线程的时候会用到
- `handler` :饱和策略。



**饱和策略**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时， 根据策略来处理情况。下面是常见的策略:

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。



**execute vs. submit**

1. `execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；
2. `submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功。



## Golang

### Q：GPM模型

goroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多(M:N)的线程模型。

Go语言中支撑整个scheduler实现的主要有4个重要结构，分别是M、G、P、Sched。

- `M`指的是`Machine`，一个`M`直接关联了一个内核线程。由操作系统管理。
- `P`指的是`processor，代表了`M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接。
- `G`指的是`Goroutine`，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。

在程序启动时，创建N个线程执行schedule调度协程。调度首先从M个协程中寻找一个要执行的协程，运行该协程直到需要调度其它协程时才返回，保存协程状态回到调度第一步。具体而言：

- **对于线程**：在 Go 进程启动之后，干个物理线程进入调度函数，M从P取出（或工作窃取）可运行的协程执行，如果没有那么睡眠。

- **对于协程**：

  - **创建过程**：新创建的协程会先保存在本地队列或全局队列中。（本地满了去全局）等待被取出执行。
  - **网络调用 / 非阻塞调用**：当G执行之后，调度程序会将G保存上下文并切出M，M会继续循环寻找下一个。
    - 当 G 获得了想要的数据后，sysmon 线程会将 G 放入队列当中，等待着调度运行。
    - 注意：golang把socket的调用都封装成NONBLOCK，后面调用poll，runtime_pollWait

  - **系统调用**：当G发生了`syscall` 或阻塞操作。
    - 此时M物理线程大概率已经陷入内核，没有办法运行下一个G，这个系统调用只能占用一个物理线程。但是这个时候 M 实际上可能只是等待内核的 IO 数据，并不会占用 CPU。
    - 这时候，`sysmon`线程会检测到M已经阻塞，把这个线程M从P摘除，然后再创建一个新的线程尝试调度占用 CPU；
    - 当系统调用结束时候，这个 M 会尝试获取一个空闲的 P 执行。如果获取不到 P，那么这个线程 M 会 park 它自己(休眠)，加入到空闲线程中。



### Q：select原理

Go 语言会在运行时执行编译期间展开的 `selectgo` 函数，这个函数会按照以下的过程执行：

1. 随机生成一个遍历的轮询顺序 `pollOrder` ，和根据Channe 地址生成的固定锁定顺序 `lockOrder`（固定顺序用于防止死锁）；
2. 根据 `pollOrder` 遍历所有的 `case` 查看是否有可以立刻处理的 Channel 消息；
   - 如果有消息直接返回；
   - 如果没有消息就会创建 `sudog` 结构体，将当前 Goroutine 加入到所有相关 Channel 的 `sendq` 和 `recvq` 队列中并调用 `gopark` 触发调度器的调度；
3. 当调度器唤醒当前 Goroutine 时就会再次按照 `lockOrder` 遍历所有的 `case`，从中查找需要被处理的 `sudog` 结构并返回对应的索引；

然而并不是所有的 `select` 控制结构都会走到 `selectgo` 上，很多情况都会被直接优化掉，没有机会调用 `selectgo` 函数。

**一些关于select的语法知识**

1. 在Channel状态改变之前，`select` 会一直阻塞当前协程
2. 如果 `select` 控制结构中包含 `default` 语句，当存在可以收发的 Channel 时，直接处理该 Channel 对应的 `case`；否则执行 `default` 中的语句
3. `select case`中的表达式必须都是 Channel 的收发操作
4. `x, ok := <-c` 的语法是用来替代 `closed(c)` 语法判断 Channel 的关闭状态
5. `select` 在遇到多个 `<-ch` 同时满足可读或者可写条件时会**随机选择**一个 `case` 执行其中的代码，随机的引入就是为了**避免饥饿问题**的发生。



### Q：Context使用场景

1.  `context.Context` 的主要作用是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用
2.  除了构造新的Context的`Background`和`TODO`函数外，还有4个创建子上下文的函数：`WithTimeout`、`WithDeadline`、`WithCancel`和`WithValue`
3.  其中传值的`WithValue`的常见使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。



### Q：make和new

- make 的作用是初始化内置的数据结构，也就是我们在前面提到的切片、哈希表和 Channel；
- new 的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针
  - 注意：`new`没有递归地创建空间。

```go
type Test struct {
	Params map[string]string
}

func NewTest() *Test {
	return &Test{Params: make(map[string]string)}
}

func main() {
	t := new(Test)
	fmt.Println(t.Params == nil)		// true

	t = NewTest()
	fmt.Println(t.Params != nil)		// true
}
```

