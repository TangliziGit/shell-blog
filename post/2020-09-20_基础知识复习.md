
# 计算机网络




## 基础




### Q：五层协议的体系结构分别是什么？每一层都有哪些协议？

> https://blog.csdn.net/cainv89/article/details/46885197

- **应用层**：应用层不仅要提供应用进程所需要的信息交换和远地操作，还要作为互相作用的应用进程的用户代理；
  - HTTP协议，FTP，SMTP协议，DNS协议

- **运输层**：任务是负责主机中两个进程间的通信；
  - TCP，UDP协议

- **网络层**：网络层负责的是分组选择合适的路由；
  - IP协议，RIP，OSPF路由协议

- **数据链路层**：将在网络层交下来的数据报组装成帧（frame)，两个相邻结点间的链路实现帧的传输；
  - ARP和RARP协议

- **物理层**：透明地传输比特流。
  - 以太网协议CSMA/CD




### Q：为何有MAC地址还要IP地址？

> https://www.zhihu.com/question/21546408/answer/149670503

核心思路是 IP 提供了子网划分的能力。

1. 简化路由计算：随着网络中的设备逐渐增多，人们发现路由变得越来越困难了。于是人们想了一个办法，就是把网络划分成很多个子网。这样，在路由的时候，路由器可以把其他子网看成一个整体来进行计算。对于目的地在其他子网的数据包，路由器只需要让数据包到达那个子网即可，而剩下的工作就由子网内部解决了。
2. 降低存储空间：如果我们只用 MAC 地址的话，我们会发现路由器需要记住每个 MAC 地址所在的子网是哪一个。而MAC地址一共有48位，每个路由器是不可能存储这些MAC地址到端口的映射的。



### Q：为何有IP地址还要MAC地址？

> https://www.zhihu.com/question/21546408/answer/149670503

IP地址是需要分配的，而MAC地址是硬件固有的。在分配 IP 地址的过程中，为链路层提供访问的能力，我们还需要用 MAC 地址来区分不同的设备。




## TCP



### Q：TCP特性？如何实现？

- TCP 提供一种**面向连接的、可靠的**字节流服务
- **可靠传输**：TCP 使用校验和，ACK确认和重传机制来保证
- **乱序冗余**：TCP 使用累积确认保证数据的顺序不变和非重复
- **流控机制**：TCP 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制



### Q：TCP和UDP的区别？

> https://blog.csdn.net/xiaobangkuaipao/article/details/76793702

> https://www.cnblogs.com/jingliming/p/4477264.html

**TCP**：面向连接，可靠，字节流，传输效率慢，所需资源多，应用于通信数据可靠的场景（文件传输，邮件传输，远程登录），首部20-60个字节。

**UDP**：无连接，不可靠，用户数据报，传输效率低，所需资源少，通信速度要求高的场景（域名转换，视频流），首部8个字节。



1、TCP面向连接；UDP是无连接的，即发送数据之前不需要建立连接

2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP尽最大努力交付，即不保证可靠交付

Tcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。

3、UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。

4.每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

5、TCP对系统资源要求较多，UDP对系统资源要求较少。




### Q：拥塞控制和流量控制都是什么，两者的区别？

> https://blog.csdn.net/ailunlee/article/details/53716367

**流量控制**

- 控制发送者的发送速度，避免发送过快，接收者来不及接收，导致分组丢失。
- 滑动窗口协议实现，动态的调整窗口大小，控制发送者发送速度。



**拥塞控制**

- 作用于网络，防止过多的数据注入到网络中，避免出现网络负载过大的情况。（TCP被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量）
- 慢启动、拥塞避免、拥塞发生和快速恢复调整拥塞窗口`cwnd`





### Q：谈谈TCP为什么要三次握手？为什么要四次挥手？

> https://blog.csdn.net/zhaobudaofangxia/article/details/55260259

> https://zhuanlan.zhihu.com/p/53374516

> https://draveness.me/whys-the-design-tcp-three-way-handshake/

三次握手：(验证双方的收发能力正常)

    第一次。A跟B说，我要建立连接了			SYN 		(new SEQ)
    第二次。B跟A说，OK那我也建立连接			SYN + ACK 	(new SEQ)
    第三次。A跟B说，嗯，我知道了。			ACK

**第三次握手解决历史链接问题**：

为了阻止历史的重复连接初始化造成的混乱问题，防止使用 TCP 协议通信的双方建立了错误的连接；

接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。

使用三次握手和 `RST` 控制消息将是否建立连接的最终控制权交给了发送方。



四次挥手：（二四验证收到断开链接请求）

    第一次。A跟B说，我要断开连接了						FIN
    第二次。B跟A说，好的我不再接收你的信息了				ACK
    第三次。B跟A说，我传给你的信息传完了,你可以关闭连接了	FIN
    第四次。A跟B说，好的我关闭连接了						ACK



### Q：播放视频用TCP还是UDP？为什么？

TCP 和 UDP 是质量和实时性的权衡。
拿视频网站来说，你完全可以缓冲 20s 再播放，不会带来什么影响，但如果画面有马赛克之类的东西出现肯定是不好的，所以用 TCP。
而对于视频聊天，如果缓冲 5s，相信整个聊天已经没法愉快的进行了，而这时出现一些画面质量的损失也可以被接受，所以用 UDP。





### Q：TCP KeepAlive

TCP KeepAlive 的基本原理是，隔一段时间**给连接对端**发送一个**探测包**，如果收到对方回应的 **ACK**，则认为连接还是存活的，在超过一定重试次数之后还是没有收到对方的回应，则丢弃该 TCP 连接。

局限：

1. TCP KeepAlive 监测的方式是发送一个 probe 包，会给网络带来额外的流量
2. 只能在内核层级监测连接的存活与否，而连接的存活不一定代表服务的可用。



### Q：TIME_WAIT状态是什么？为什么需要2MSL来等待关闭？MSL、RTT和TTL的区别？

> - https://draveness.me/whys-the-design-tcp-time-wait/

TCP 协议中包含 11 种不同的状态，TCP 连接会根据发送或者接收到的消息转换状态。

使用 TCP 协议通信的双方会在关闭连接时触发 `TIME_WAIT` 状态，关闭连接的操作其实是告诉通信的另一方**自己没有需要发送的数据**，但是它仍然**保持了接收对方数据的能力**，一个常见的关闭连接过程如下：

1. 当客户端没有待发送的数据时，它会向服务端发送 `FIN` 消息，发送消息后会进入 `FIN_WAIT_1` 状态；
2. 服务端接收到客户端的 `FIN` 消息后，会进入 `CLOSE_WAIT` 状态并向客户端发送 `ACK` 消息，客户端接收到 `ACK` 消息时会进入 `FIN_WAIT_2` 状态；
3. 当服务端没有待发送的数据时，服务端会向客户端发送 `FIN` 消息；
4. 客户端接收到 `FIN` 消息后，会进入 `TIME_WAIT` 状态并向服务端发送 `ACK` 消息，服务端收到后会进入 `CLOSED` 状态；
5. 客户端等待**两个最大数据段生命周期**（Maximum segment lifetime，MSL）的时间后也会进入 `CLOSED` 状态；

从上述过程中，我们会发现 `TIME_WAIT` 仅在主动断开连接的一方出现，被动断开连接的一方会直接进入 `CLOSED` 状态，进入 `TIME_WAIT` 的客户端需要等待 2 MSL 才可以真正关闭连接。TCP 协议需要 `TIME_WAIT` 状态的原因和客户端需要等待两个 MSL 不能直接进入 `CLOSED` 状态的原因是一样的：

- **阻止延迟数据段**：防止对端关闭前发送的数据段，被被其他使用相同源地址、源端口、目的地址以及目的端口的 TCP 连接延迟接受；
  - 至于为什么是两倍，RFC文档中没有解释。一般认为这个报文段可能是自己发出的，然后对端接受并恢复，一共两倍。
- **保证连接关闭**：保证 TCP 连接的远程被正确关闭，即对端收到 `FIN` 对应的 `ACK` 消息；
  - 当服务端还没有收到 ACK 消息时，客户端的新链接发送 SYN 消息请求握手时会收到服务端的 RST 消息，连接建立的过程就会被终止。
  - 如果客户端等待 2 MSL 的时间，那么无论服务端有没有受到`ACK`（如果没受到重发`FIN`），客户端都可以关闭或响应。

**MSL、RTT和TTL的区别**

- **MSL**：Maximum Segment Lifetime，任何TCP报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
  - RFC793不严谨地定义它为两分钟长，早期Linux就定义它为60秒。
- **TTL**：Time To Live，存储了一个ip数据报可以经过的最大路由数。
- **RTT**：Round-Trip Time，TCP数据段往返时间，一些算法可以动态估计它。



### Q：ACK攻击是什么

当主机在接收到ACK标志位的数据包的时候，需要检查该数据包所表示的**连接四元组**是否存在，检查该数据包所表示的**状态是否合法**，然后再向对应进程传递该数据包。当发包速率很大的时候，主机操作系统将耗费大量的精力接收报文、判断状态，同时要**主动回应RST报文**，正常的数据包就可能无法得到及时的处理。




## HTTP




### Q：HTTP报文格式？

> https://blog.csdn.net/holmofy/article/details/68492045

Requst: Method + URL + Version

Response: Version + Status + Description




### Q：了解哪些响应状态码？

> https://blog.csdn.net/oops_qu/article/details/75675702

> 1xx（临时响应）：表示临时响应并需要请求者继续执行操作的状态代码。

> 2xx （成功）：表示成功处理了请求的状态代码。

> 3xx （重定向）：表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。

> 4xx（请求错误）：这些状态代码表示请求可能出错，妨碍了服务器的处理。

> 5xx（服务器错误）：这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。



301: 永久移动

302: 临时移动

401: 身份验证未授权

403: 禁止

405: 方法禁用




### Q：GET和POST的区别？

> https://www.cnblogs.com/huaxingtianxia/p/5895236.html

GET在浏览器回退时是无害的，而POST会再次提交请求。
GET请求会被浏览器主动cache，而POST不会，除非手动设置。
GET请求只能进行url编码，而POST支持多种编码方式。
GET请求在URL中传送的参数是有长度限制的，而POST么有。
GET参数通过URL传递，POST放在body中。



注意`100 continue`在GET和POST上都可以存在，并没有限制HTTP方法。

100 Continue的目的是对，HTTP客户端希望在发送之前查看一下服务器是否会接受这个实体，这种情况进行优化。

如果客户端在向服务器发送一个实体，并愿意在发送实体之前等待100 Continue响应，那么客户端就要发送一个携带了值为100  Continue的Expect请求首部。如果客户端没有发送实体，就不应该发送100 Continue  Expect首部，因为这样会使服务器误以为客户端要发送一个实体。



### Q：HTTP1.0和1.1的区别？

> https://blog.csdn.net/linsongbin1/article/details/54980801/

> https://www.jianshu.com/p/7bfec28236c3

**长连接**

- HTTP1.1 支持长连接和流水线处理。但长连接中每个请求都是**串行**的，会产生队头阻塞问题。



**节约带宽**

- `range`头信息，可以向服务器请求数据的一部分。
- `content-encoding`提供双方的编码方式，以便压缩信息。
- `100 Continue`状态码：客户端在每个请求时首先发送header，服务器检查有效性，返回`100`或`4xx`状态码。



**HOST域**

- IP地址绑定一个HOST域名，每个IP可能绑定不同域名。



**缓存策略**

- 除了HTTP1.0 提供的`If-Modified-Since`和`Last-Modified`，HTTP1.1 又提供了`If-Unmodified-Since`。
- `If-Modified-Since`: （若修改再下载）客户端尝试下载最新版本的文件，若修改则200，若未修改则304。
- `If-Unmodified-Since`:（若未修改再下载） 断点续传(一般会指定Range参数)，若未修改则200，若修改则412。



错误通知

- 更多的错误码





### Q：HTTP1.1和2.0的区别？

> https://segmentfault.com/a/1190000016975064

**二进制分帧**

- 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码
- 通信都在一个TCP连接上完成，这个连接可以承载任意数量的双向数据流
- 



**多路复用**

- 相比较与HTTP1.1的piplining，多路复用对请求提供了**并发**的能力，消除了队头阻塞问题。



**头部数据压缩**

- HTTP1.1对消息体进行gzip压缩，或本身就是压缩过的内容；对请求头和请求行明文传输。
- HTTP2.0在基础上使用HPACK算法对头进行压缩。



**服务器推送**

- HTTP1.1对每个资源都做请求；HTTP2.0 引入服务器推送，允许服务器推送请求之外的内容。






### Q：HTTP和HTTPS的区别?

多一层TLS，以防中间人，保证安全。




### Q：在地址栏打入http://www.baidu.com会发生什么？

> https://github.com/skyline75489/what-happens-when-zh_CN

- **检查 HSTS 列表**

  - 浏览器检查自带的“预加载 HSTS（HTTP严格传输安全）”列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站

  - 其次在服务器返回的响应中，有一个特殊的头部，指示浏览器对于此网站，强制使用 HTTPS 进行访问<br>`Strict-Transport-Security: max-age=31536000; includeSubdomains; preload`<br>注意SSL剥离攻击


- **DNS 查询**

  - 浏览器检查域名是否在缓存当中；有则返回

  - 检查域名是否在本地 Hosts；有则返回

  - 进行ARP查询DNS(DNS在子网)或网关(DNS不在子网)的MAC，向 DNS 服务器发送一条 DNS 查询请求


- **ARP 过程**

  - 查询 ARP 缓存；有则返回

  - 查看路由表，选择接口发送ARP请求；如果下一个设备是：
    - 目标 / 路由器：返回ARP应答
    - 交换机：查MAC表，如果有结果则向端口发送；若无则向其他端口广播
    - 集线器：向其他端口广播


- **TCP 握手**
- **TLS 握手**
- **HTTP 协议**



### Q：DNS解析过程如何？

以下是迭代式：注意还有递归式

```
浏览器DNS缓存 -> 操作系统DNS缓存 -> 本地host文件 -> 本地DNS服务器
本地DNS服务器 -> 根DNS服务器
             -> 顶级DNS服务器
```



### Q：1.0短链接、1.1长连接、2.0多路复用？

> https://www.cnblogs.com/gotodsp/p/6366163.html

> https://www.cnblogs.com/Paul-watermelon/p/10467662.html

**短链接**：HTTP/1.0使用短连接。客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。客户端浏览器每遇到一个Web资源，浏览器就会重新建立一个HTTP会话(TCP连接)。



**长连接**：HTTP/1.1默认使用长连接。`Connection:keep-alive`。当一个网页打开完成后，TCP连接不会关闭，客户端会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件中设定这个时间。**在下一个请求发出之前，必须响应TCP连接上的每个HTTP请求。**

**流水线**：HTTP/1.1 Pipeline解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；**可以立即进行TCP链接上的每个HTTP请求，而无需等待先前请求的响应返回，回复将以相同顺序返回。**



**多路复用**：HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；**可以立即进行TCP链接上的每个HTTP请求，而无需等待先前请求的响应返回，回复将以任意顺序返回。**




### Q：HTTPS原理及认证过程

> https://hit-alibaba.github.io/interview/basic/network/HTTPS.html



**对称加密**

- 双方使用同一个密钥去加密和解密数据。
- 特点是速度快，适合于对大数据量进行加密。<br>缺点是密钥安全管理困难
- 常见的对称加密算法有DES、3DES、TDEA、Blowfish、RC5和IDEA。
- **明文 + 加密算法 + 私钥 => 密文**<br>**密文 + 解密算法 + 私钥 => 明文**



**非对称加密**

- 用公钥或私钥中的任何一个进行加密，用另一个进行解密。
- 私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。
- 花费时间长、速度慢。
- 在非对称加密中使用的主要算法有：RSA、Elgamal、Rabin、D-H、ECC等。
- **明文 + 加密算法 + 公钥 => 密文， 密文 + 解密算法 + 私钥 => 明文**<br>**明文 + 加密算法 + 私钥 => 密文， 密文 + 解密算法 + 公钥 => 明文**



**HTTP + TLS1.2 通信过程**

1. 客户端发送`Client Hello`：（协议版本、加密算法、压缩算法）、**客户端随机数**

2. 服务器返回`Server Hello`：（协议版本、加密算法、压缩算法）、证书公钥、证书链、**服务端随机数**等

3. 客户端进行证书验证，若验证失败则放弃后续访问。<br>验证成功则再次生成一个**随机字符串（premaster）**。<br>随机串经过非对称加密的公钥后，发送`Change Cipher Spec`给服务器，**通知服务器**之后的消息用对称密钥加密。<br>客户端根据三个随机数生成对话密钥。

   （现在客户端可以直接发送数据）

4. 服务器接受数据用非对称加密的密钥进行解密。<br>拿到随机串后，根据三个随机数生成对话密钥，`Change Cipher Spec`**通知客户端**之后的消息用对称密钥加密，完成TLS1.2握手。



**CA认证**

> CA机构（Certificate Authority）即颁发数字证书的机构。是电子交易、网络数据交流中权威的受信任的第三方机构，承担公钥体系中公钥的合法性检验的责任。

- 服务器的证书首先在CA机构中通过申请；客户端验证证书方法是向权威CA机构校验
- 证书验证的过程依赖于证书信任链，即一个证书要依靠上一级证书来证明自己是可信的，最顶层的证书被称为根证书，拥有根证书的机构被称为根 CA。根证书一般是操作系统自带的



### Q：QUIC是什么

> https://network.51cto.com/art/202009/625999.htm

> https://zhuanlan.zhihu.com/p/32553477

Quic即“快速 UDP 互联网连接”，是由 google 提出的使用 udp 进行多路并发传输的协议。

Quic 相比现在广泛应用的 http2+tcp+tls 协议有如下优势：

- **连接建立延时低** : 0RTT建立链接(曾有过链接) vs 4.5RTT链接 

- **改进的拥塞控制**

- **多路复用**：在一条 QUIC 连接上可以并发发送多个请求，互相之间没有依赖（类似HTTP2，但解决了它在TCP层面的队头阻塞）

- **加密认证的报文**

相当于QUIC包含了HTTP2.0多路复用、TLS安全加密、TCP拥塞控制。




### Q：HTTP3.0是什么

> https://network.51cto.com/art/202009/625999.htm

HTTP3.0，也称作HTTP over QUIC，而QUIC是基于传输层UDP上的协议。即HTTP3.0 + QUIC + UDP

相当于QUIC包含了HTTP2.0多路复用、TLS安全加密、TCP拥塞控制。




### Q：为什么 HTTPS 需要 7 次握手以及 9 倍时延

> https://draveness.me/whys-the-design-https-latency/

(HTTPS 使用安全套接字层SSL保证数据传输的安全，随着传输层安全协议TLS的发展，目前我们已经使用 TLS 取代了废弃的 SSL 协议)

- TCP 协议 — 通信双方通过三次握手建立 TCP 连接；1.5 RTT；
- TLS 协议 — 通信双方通过四次握手建立 TLS 连接；2 RTT；
- HTTP 协议 — 客户端向服务端发送请求，服务端发回响应；1 RTT；

**TLS**

TLS 的作用是构建安全的传输通道（本身不提供可靠性保障）。在通信双方建立可靠的 TCP 连接之后，我们就需要通过 TLS 握手交换双方的密钥了。

TLS 握手的关键在于利用通信**双方生成的随机字符串**和**服务端的公钥**生成一个双方经过协商后的密钥，通信的双方可以使用这个**对称的密钥加密**消息防止**中间人**的监听和攻击，保证通信的安全。




### Q：50x错误各代表什么意义

500: 程序内部错误

(501: 服务器不具备完成请求的功能)

502: 错误网关 (web容器收到了无法理解的响应)

503: 服务不可用 (停机维护)

504: 网关超时 (超过了web容器的超时时间，不等待程序的返回结果)

505: HTTP版本不支持




### Q：Cookie / Session / Token 

> https://zhuanlan.zhihu.com/p/129227994

HTTP 协议是一种`无状态协议`，即每次服务端接收到客户端的请求时，都是一个全新的请求，服务器并不知道客户端的历史请求记录；Session 和 Cookie 的主要目的就是为了弥补 HTTP 的无状态特性。



**Cookie**

- 服务器发送到浏览器的 Cookie，浏览器会进行存储，并与下一个请求一起发送到服务器。
- 响应头`Set-Cookie`，请求头`Cookie`工作原理。
- 过期时间，域，HttpOnly



**Session**

- 客户端请求服务端，服务端会为这次请求开辟一块`内存空间`，存储客户端在同一个会话期间的一些记录。
- 服务器第一次返回响应时，带有`Set-Cookie：SESSIONID=XXXXXXX`；<br>客户端在本机客户端设置此Cookie，该 Cookie 的过期时间为浏览器会话结束；<br>客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息；<br>服务器每次读取请求头中的 Cookie 信息，获取SessionId，获得状态。
- 负载均衡后，需要Session数据库提供一致性能力。



**Token**

- 服务器生成加密令牌，客户端请求带上Token，服务器校验。一般放在cookie里。
- **无状态**：减轻服务器的压力，减少频繁的查询数据库
- JWT格式: header.payload.sign



### Q：如何实现跨域？

- 图片ping & jsonp
- WebSocket
- CORS
- 其他



### Q：跨域资源共享 CORS 原理

> http://www.ruanyifeng.com/blog/2016/04/cors.html

浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。

实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。

浏览器将CORS请求分成两类：简单请求和非简单请求。



**基本流程**

1. 自动在头信息之中，添加一个`Origin`字段。说明请求来自哪个源（协议 + 域名 + 端口）。

   - 若为简单请求，则直接请求
   - 若为非简单请求，则发送`OPTION`方法，对`Access-Control-Allow-*`系列头部进行预检查，而后进行正常通信。检查方法同下文。

2. 服务器返回一个正常的HTTP回应。客户端检查是否存在`Access-Control-Allow-*`字段。

   - 若不存在，则浏览器的xml请求调用onerror回调

   - 若存在且与`Origin`相同，则正常返回


一些访问控制头：

- **Access-Control-Allow-Origin**：允许对应的Origin
- **Access-Control-Allow-Methods**：允许对应的Methods
- **Access-Control-Allow-Credentials**：是否允许带有Cookies
- **Access-Control-Expose-Headers**：允许包含的Header

# 操作系统




## 基础



### Q：什么是协程？与线程有什么区别？举一些例子？

> - https://github.com/LeoYang90/Golang-Internal-Notes/blob/master/Go%20%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96.md

协程是**一种程序运行的方式**，允许执行被挂起与被恢复。可以与它相比较的概念是子例程（即函数）：

- 协程可以通过让步`yield`，来调用或切换到其它协程上，当该协程再次被调用时将从`yield`处继续执行。
- 协程间是互相平等的关系。
- 多个协程之间的执行权，是由协程根据代码（调用或让步）自主分配，从而切换不同协程持有的函数栈。

协程的要点在于**执行权的唯一性和函数栈的自主切换**，它强调的是并发而非并行：

- 典型的协程是语言层级的构造，可看作一种形式的控制流；而线程是系统层级的构造，由操作系统和CPU来支撑并行。
- 所以，在协程之间的切换不应该涉及任何系统调用。

**JavaScript中的协程**

ES6 提供了一种半协程的实现，即Generator。协程有能力控制在它让位之后哪个协程立即接续它来执行，而生成器不能，它只能把控制权转交给调用生成器的调用者。如果是完全执行的协程，任何函数都可以让暂停的协程继续执行。

**Golang中的协程**

goroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多(M:N)的线程模型。

Go语言中支撑整个scheduler实现的主要有4个重要结构，分别是M、G、P、Sched。

- `M`指的是`Machine`，一个`M`直接关联了一个内核线程。由操作系统管理。
- `P`指的是`processor，代表了`M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接。
- `G`指的是`Goroutine`，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。

在程序启动时，创建N个线程执行schedule调度协程。调度首先从M个协程中寻找一个要执行的协程，运行该协程直到需要调度其它协程时才返回，保存协程状态回到调度第一步。具体而言：

- **对于线程**：在 Go 进程启动之后，干个物理线程进入调度函数，M从P取出（或工作窃取）可运行的协程执行，如果没有那么睡眠。

- **对于协程**：

  - **创建过程**：新创建的协程会先保存在本地队列或全局队列中。（本地满了去全局）等待被取出执行。
  - **网络调用 / 非阻塞调用**：当G执行之后，调度程序会将G保存上下文并切出M，M会继续循环寻找下一个。
    - 当 G 获得了想要的数据后，sysmon 线程会将 G 放入队列当中，等待着调度运行。
    - 注意：golang把socket的调用都封装成NONBLOCK，后面调用poll，runtime_pollWait

  - **系统调用**：当G发生了`syscall` 或阻塞操作。
    - 此时M物理线程大概率已经陷入内核，没有办法运行下一个G，这个系统调用只能占用一个物理线程。但是这个时候 M 实际上可能只是等待内核的 IO 数据，并不会占用 CPU。
    - 这时候，`sysmon`线程会检测到M已经阻塞，把这个线程M从P摘除，然后再创建一个新的线程尝试调度占用 CPU；
    - 当系统调用结束时候，这个 M 会尝试获取一个空闲的 P 执行。如果获取不到 P，那么这个线程 M 会 park 它自己(休眠)，加入到空闲线程中。



### Q：进程和线程的区别？

> - https://stackoverflow.com/questions/200469/what-is-the-difference-between-a-process-and-a-thread

最典型的差异是：线程是在共享存储空间中运行的，而进程在单独的存储空间中运行。

下面是一些OS原理上的区别：

- 进程是资源分配的最小单位，线程是CPU调度的最小单位。
- **拥有资源**：进程有独立的地址空间，进程间相互隔离。线程间则使用相同的地址空间，共享大部分堆数据，虽然有自己的函数栈。
- **调度**：线程是独立调度的基本单位。
- **系统开销**：
  - **创建或撤销**进程时，系统要为之分配或回收资源，如内存空间、I/O 设备等。
  - 在进行**进程切换**时，主要开销在与虚拟内存的切换（TLB之类的东西）；而同一进程中线程切换时，只需保存和设置少量寄存器内容。
- **通信**：线程间可以通过直接读写同一进程中的数据进行通信。但进程间相互独立，需要使用譬如管道，信号，消息队列，共享内存，套接字等通信机制。





### Q：进程如何管理？调度算法？

> - https://segmentfault.com/a/1190000037765907

**进程控制块PCB**

PCB是进程存在的唯一标识，这意味一个进程一定会有对应的PCB：

- **进程管理信息**
  - 进程ID、父进程ID、进程组、优先级、开始时间、使用CPU时间等
- **存储管理**
  - TEXT段指针、数据段指针、堆栈段指针
- **文件管理**
  - 文件描述符等

**PCB如何组织**

一般有三种：

- 线性表
- 链表：包含执行指针、就绪指针、阻塞指针
  - Linux使用双向链表组织PCB，且每个进程的PCB都存在内核空间。
- 索引：包含执行指针、就绪指针、阻塞指针，每个指针指向一个索引表



**七状态模型**

- **`就绪 -> 运行`**：当操作系统内存在着调度程序，当需要运行一个新进程时，调度程序选择一个就绪态的进程，让其进入运行态。
- **`运行 -> 就绪`**：运行态的进程，会占有CPU（参照一开始的饼状图）。每个进程会被分配一定的执行时间，当时间结束后，重新回到就绪态。
- **`运行 -> 阻塞`**：进程请求调用系统的某些服务，但是操作系统没法立即给它（比如这种服务可能要耗时初始化，比如I/O资源需要等待），那么它就会进入阻塞态。
- **`阻塞 -> 就绪`**：当等待结束了，就由阻塞态进入就绪态。
- **`运行 -> 终止`**：当进程表示自己已经完成了，它会被操作系统终止。
- **就绪挂起**：为了解决内存占用问题，可以将一部分内存中的进程交换到磁盘中，这些被交换到磁盘的进程，会进入挂起状态。
- **阻塞挂起**

该切换过程一般涉及以下步骤：

1. 保存处理器上下文环境：将CPU程序计数器和寄存器的值保存到当前进程的私有堆栈里
2. 更新当前进程的PCB（包括状态更变）
3. 将当前进程移到就绪队列或者阻塞队列
4. 根据调度算法，选择就绪队列中一个合适的新进程，将其更改为运行态
5. 更新内存管理的数据结构
6. 新进程内对堆栈所保存的上下文信息载入到CPU的寄存器和程序计数器，占有CPU



**进程调度算法**

- **先来先服务**
- **短作业优先**：按照最短长度排队。
- **时间片轮转**：每一个进程会被分配一个时间片。时间片结束，会被抢占式到就绪队列。CPU切换至其他进程。
- **优先权调度算法**：按优先级排队，如果多个进程优先级相同，则按照先来先服务的方式依次执行。
  - Linux调度程序跟踪进程，动态周期性计算出优先级，依照优先级排队调度。
- **多级反馈队列**：基于时间片轮转和优先级调度。多个就绪队列，赋予每个就绪队列优先级，优先级越高的队列进程的时间片越短
  - 如果进程在一级队列取出并在时间盘中没有结束运行，那么进入下一个就绪队列。
  - 仅当第i级队列为空时，才调度第i+1级队列的进程
  - 当有一个更高优先级的进程进入，则会停下第i级的进程，让它回到第i级队列尾部，CPU转而执行更高优先级的进程



### Q：进程间通信？ 

> - https://segmentfault.com/a/1190000037765907

以 Unix/Linux 为例，介绍几种重要的进程间通信方式：

- **共享内存**：多个进程可以读写同一块内存区域
- **管道**：多个生产者，生产一些数据，将其放置到共享缓冲区中，由消费者从缓冲区中取走数据。
  - 缓冲区同一时间内只允许生产者或者消费者一方访问。
  - 当缓冲区满了，生产者添加数据阻塞；当缓冲区空了，消费者读取数据阻塞。
- **消息通信**
  - **直接通信**：sender直接发消息发给receiver，把消息挂在接收进程的消息队列中，接收进程从消息队列中获取消息
  - **间接通信**：消息不直接发送给接收者，而是发送到一个共享数据结构。该结构是一种消息队列，也称为信箱。通过进程ID收发消息。
- **信号量**：信号量本质是一个计数器，当多进程共享内存时，用于保护共享内存仅由N个进程使用。
- **信号**：是一种异步通信，进程需要为信号设置相应的监听处理。常用于一些异常情况下的进程间通信。



### Q：Linux怎么创建一个进程？

1. 分配PID，申请空白的PCB，若PCB申请失败，创建失败。
2. 为进程分配资源：为新进程的程序和数据及用户栈分配必要的内存空间。
3. 初始化PCB，包括进程标识符，处理机状态（寄存器状态），进程调度信息（状态，优先级），进程控制信息（程序和数据的地址）。
4. 如果就绪队列能够容纳新进程，则新进程插入就绪队列，等待调度执行。




### Q：死锁的产生和避免? 

> https://www.cnblogs.com/fangrong/p/5271724.html

- **原因**：系统资源竞争、程序推进顺序非法

- 死锁产生的四个必要条件：

  - **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，必须等待直到该资源被释放为止。

  - **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。

  - **非抢占：**资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。

  - **循环等待：**有一组等待进程{P0，P1，P2，...，Pn}，P0等待的资源被P1占有，P1等待的资源被P2占有，Pn等待的资源被P0占有。

- 死锁解决方案：
  - **死锁预防**：设置某些限制条件，破坏产生死锁的四个必要条件中的一个或几个。
  - **避免死锁**：在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。
    - 安全状态：能找到一个分配资源的序列能让所有进程都顺序完成。
    - 银行家算法：采用预分配策略检测分配完成时系统是否处在安全状态。
  - **死锁监测**：无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取措施解除死锁。
    - 死锁监测：化简资源分配图
    - 死锁解除：资源剥夺，撤销进程，进程回退




### Q：基本分页 & 请求分页

**基本分页**

固定分区会产生内碎片，动态分区会产生外碎片；为了尽量避免内存碎片，提出基本分页存储。

它将主存空间分为固定相等的小块，作为主存的单元。进程在申请内存时，以页为单位进行请求。（进程中为页，内存中为页框，外存中为块。无外碎片，平均半个页的内碎片。）

- **页面大小取舍**
  - 太小：页表过大（浪费内存），地址转换频繁（浪费时间）
  - 太大：内碎片过大（浪费内存）
- **页表**：
  - 便于寻找页面对应的物理块，系统在内存中为每个进程维护一张页表。
  - 实际上是物理块号的数组，其索引为页号。
- **基本地址变换机构**：
  - 逻辑地址结构： `| 页号 | 页内偏移量 |`
  - 页表寄存器：`| 页表起始地址 | 页表长度 |`
  - 检查逻辑地址页号长度小于页表长度，计算页表中对应页号地址，取出块号拼接偏移量。
- **快表**
  - 具有并行查找能力的高速缓冲器，用于提升地址变换速度（减少一次查页表的访存）。
  - 实际上为`| 页号 | 块号 |`的数组
  - 在原有变换流程基础上，首先查找快表，取出块号拼接偏移量。
- **两级页表**
  - 为了压缩页表大小，不去存储无用的页表项，系统在内存中为每个进程维护一张二级页表。
  - 逻辑地址结构： `| 一级页号 | 二级页号 | 页内偏移量 |`



**请求分页** 

虚拟内存的一种实现方式。虚存基于时空局部性，当内存暂时不使用时换出至外存。系统为用户提供了一个比物理空间大得多的虚拟空间，故称虚存。

只需一部分页面装入内存，程序即可运行。当需要访问不在内存中的页面时，通过**请求调页**功能调入，同时置换不用的页面至外存。

- **页表**：为了发现和处理请求页面时，页面是否存在和调出等问题，加入另外一些字段。（如访问位，修改位等）
- **地址变换机构**：首先查找快表，（若不存在）再查找页表；查看页表是否已调入，（若缺页）产生缺页中断，请求调页。
- **缺页中断机构**：CPU遇到缺页中断后，阻塞缺页进程；若内存中无空闲页框，则按**页面置换算法**淘汰某页，再调入目标页面。
- **页面置换算法**：LRU实现使用哈希表+双向链表，读写移动至表头，替换时删除表尾。



### Q：页面置换算法？

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断请求调页。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法的主要目标是使页面置换频率最低：

- **最佳（OPT）**：所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

- **最近最久未使用（LRU）**：虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。
  - 当使用某个页时，将它放置在队头。当驱逐某个页时，排出队尾元素。

- **时钟算法（CLOCK）**：维护环形链。每个元素都有一个计数位。
  - 当使用一个页时，计数位设置为1。
  - 当驱逐某个页时，如果页面的位设置为1，设置为零；如果不是，则驱逐它。



### Q：什么是中断？什么是系统调用 ？

**中断（interrupt）**是指在计算机运行过程中，当发生某个事件后，CPU 会停止当前程序流，转而去处理该事件，并在处理完毕后继续执行原程序流。

- **外中断**：由外部设备（如：磁盘，网卡，键盘，时钟）产生，用来通知操作系统外设状态变化。
  1. **外设** 将中断请求发送给中断控制器；
  2. **中断控制器** 根据中断优先级，有序地将中断传递给 CPU；
  3. **CPU** 进行中断处理：
     - **关中断**
     - **保存断点**：将原来的程序的断点（即程序计数器PC）保存起来
     - **中断服务程序寻址**：取出中断服务程序的入口地址送入程序计数器PC
     - **保存现场**：程序状态字寄存器PSWR和某些通用寄存器的内容
     - **执行中断服务程序**：如何执行？切换进程PCB还是什么？
     - **恢复现场**
     - **开中断**
- **内中断**：源自CPU执行指令内部的事件，如程序的非法操作码、地址越界、算术溢出、虚存系统缺页及陷入指令等引起的事件。



### Q：CPU Cache的结构？写入方式？ CPU间缓存一致性？

> - [10 张图打开 CPU 缓存一致性的大门](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247486479&idx=1&sn=433a551c37a445d068ffbf8ac85f0346&chksm=f98e48a5cef9c1b3fadb691fee5ebe99eb29d83fd448595239ac8a2f755fa75cacaf8e4e8576&scene=21#wechat_redirect)

**CPU Cache的结构**

CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。

CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成。CacheLineSize被大多数操作系统和CPU定义为64B，从主存中加载数据到缓存一次加载一个缓存行。

**写入方式**

那在什么时机才把 Cache 中的数据写回到内存呢？

- **写直达（Write Through）**：写缓存的同时，写入主存。缓存没有脏数据。
- **写回（Write Back）**：当缓存行被驱逐时，写入主存。缓存有脏数据并能做脏标记，掉电数据丢失。
  - 常见的淘汰策略主要有LRU和Random两种。



### Q：CPU Cache如何解决缓存一致性问题？ 

> - [MESI - Intel 奔腾系列 CPU的缓存一致性协议](https://blog.csdn.net/vcj1009784814/article/details/106544494)

由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的缓存一致性的问题。如CPU0写入数据x后，CPU1读出发现数据没变。这是因为更新在缓存中，要解决这一问题，需要同步两个不同核心里面的缓存数据：

- **写传播**：某个 CPU 核心里的 Cache 数据更新时，必须要把写入事件传播到其他核心的 Cache。
  - 注意是写入事件，而不是CPU核心去读主存。这样就不会有下面串行化的问题了。
- **串行化**：某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的。
  - 防止CPU2和CPU3对CPU1和CPU0对同一个数据的操作顺序感知反了，导致2和3中cache数据不同。
  - 解决它需要某种并发控制保证顺序：如锁或乐观控制等。

针对以上问题，Intel奔腾系列使用了**总线嗅探（Bus Snooping）+MESI协议**，AMD使用了相似的协议。

- **总线嗅探**：当核心修改了L1 Cache变量，那么通过总线把写入事件广播给其他所有的核心，然后每个核心监听总线上的广播事件，把该数据更新到自己的L1 Cache。
  - **总线负载**：不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这会加重总线负载。
  - **不保证串行化**
- **MESI协议**：用状态机机制降低了总线带宽压力，同时做到缓存一致性。
  - 数据状态将根据事件做转换，这个过程中可能触发其他总线事件、同时缓存读入或写出到主存。
  - 该协议将事件约定为两种：本地CPU读写`PrRd / PrWr`，嗅探到的总线读写`BusRd / BusRdX`、总线写但本地包含这个数据`BusUpgr`、总线Flush`Flush / FlushOpt`。
  - 该协议对L1Cache约定了四种状态（以下省略了更新状态的步骤）：
    - **Modified已修改**：脏标记。
      - 本地自由读。远端读写时写入主存。
    - **Exclusive独占**：只有该CPU持有该数据。
      - 本地自由读写。与主存无交互。总线写会置`Invalidated`。
    - **Shared共享**：有多个CPU持有该数据。
      - 本地自由读。与主存无交互。总线写会置`Invalidated`。
    - **Invalidated已失效**：禁止使用，需要重新读主存。
      - 本地不可读。本地读写是需要读主存。



### Q：程序的装入和链接是什么？动态链接库与静态的区别？

> - https://blog.csdn.net/hguisu/article/details/5713099

将用户程序变为在内存中执行的进程，通常都要经过以下几个步骤：

- **编译**：编译器将代码编译成CPU可执行的目标代码，产生了若干个目标模块.o（机器码程序段）。
  - 目标代码中以0为基址顺序进行编址，在这里每条指令和操作数的地址统称为逻辑地址 。
- **链接**：链接器将目标模块（程序段），以及它们所需要的库函数链接在一起，形成装入模块.out。
  - 将模块链接起来，需要修改**模块程序段相对地址**，让总体在一个0~N的地址空间；将**调用逻辑变成跳转地址**。
  - **静态链接**：一次性链接所有模块，形成一个完整的可运行程序。其中模块线性排列。
    - **优缺点**：与环境无关，移植方便；浪费空间。
    - 静态链接库在此时起效。
  - **装入时动态链接**：在装入内存时边装入边链接。外部模块调用事件引起装入程序寻找并装入外部目标模块。
    - **优点 - 依赖更新**：若依赖库更新，那么用户只需要更新动态库即可增量更新。
    - 动态链接库在此起效。
  - **运行时动态链接**：在运行时需要模块时，才进行链接。
    - **优点 - 节省内存**：不仅可加快程序的装入过程，而且可节省大量的内存空间。如错误处理的模块，如果程序不出现错误则不会装入内存。
    - 动态链接库在此起效。
- **装入**：装入程序将装入模块装入物理内存。确定装入内存的实际物理地址，并修改程序中与逻辑地址，即**地址重定位**。
  - **绝对装入**：按照物理内存的位置，给逻辑地址赋予实际的物理地址。不支持虚存。
  - **静态地址重定位**
  - **动态地址重地位**





## Linux

### Q：Linux如何管理内核空间和用户空间？

> - https://blog.51cto.com/wushank/1406480

**物理地址空间布局**

- **`ZONE_DMA`**：专门供I/O设备的DMA使用。因为DMA使用物理地址访问内存，不经过MMU，并且需要连续的缓冲区。
- **`ZONE_NORMAL`**：内核能够直接使用的区域。
- **`ZONE_HIGHMEM`**：高端内存，内核不能直接使用。

![linux-physical-memory-layout](/static/image/2022-02-25/linux-physical-memory-layout.jpeg)



**虚拟地址空间布局**

- **内核空间**：
  - `ZONE_ HIGHMEM`：用户数据、页表(PT)等不常用数据放在ZONE_ HIGHMEM里，只在要访问这些数据时才建立映射关系(kmap())。
  - `ZONE_NORMAL`：与内核线性空间存在直接映射关系，所以内核会将频繁使用的数据如kernel代码、GDT、IDT、PGD、mem_map数组等放在ZONE_NORMAL里。
  - `ZONE_DMA`

- **用户空间**：
  - 参数、全局环境变量
  - 栈区
  - 堆区
  - 未初始化数据区
  - 数据区
  - 代码区

![linux-virtual-memory-kernel-layout](/static/image/2022-02-25/linux-virtual-memory-kernel-layout.jpeg)

![linux-virtual-memory-user-layout](/static/image/2022-02-25/linux-virtual-memory-user-layout.jpeg)



**虚拟地址与物理地址的映射**

32位Linux将4G的线性地址空间分为2部分，0~3G为user space，3G~4G为kernel space。

- 物理空间中的`ZONE_DMA`和`ZONE_NORMAL`被线性映射到虚拟内核空间低地址区域，共896M。
- 其余空间都映射到`ZONE_HIGHMEM`中。

![linux-virtual-physical-mapping](/static/image/2022-02-25/linux-virtual-physical-mapping.jpeg)



### Q：fork操作干了什么事？

`fork`会对父进程程序段、数据段、堆段以及栈段创建拷贝，以此创建新进程映像。大部分现代 UNIX 实现(包括 Linux)采用两种技术来避免拷贝：

- **代码段**：内核将每一进程的代码段标记为只读，那么父子进程可共享同一代码段。
  - 在为子进程创建代码段时，进程页表项均指向与父进程相同的物理内存页帧。
- **数据段、堆和栈**：写时复制。
- **文件**：子进程会获得父进程所有文件描述符的副本，对应的描述符均指向相同的打开文件句柄。



### Q：Linux IO模式 
> https://segmentfault.com/a/1190000003063859

**用户空间与内核空间**

操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。

对32位Linux而言，它的寻址空间（虚拟存储空间）为4G。Linux 将最高的1G字节，供内核使用，称为内核空间，而将较低的3G字节，供各个进程使用，称为用户空间。

在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据先被拷贝在文件系统的页缓存，然后才会拷贝到应用程序的地址空间。所以，对于一次IO访问：

1. 等待数据准备： 数据会先被拷贝到**操作系统内核的缓冲区**中
2. 拷贝到进程中：从操作系统内核的缓冲区拷贝到**应用程序的地址空间**。

正因这两个阶段，linux系统产生了下面五种网络模式的方案。

- **阻塞 IO**

  - 当用户进程调用 `recvfrom / read / write` 系统调用后，内核准备数据并拷贝至内核空间，直到内核将数据拷贝到用户空间，用户进程才退出阻塞状态。

  - 在两个过程中，用户进程是一直阻塞的。
  - 在linux中，默认socket都是BLOCKING。

- **非阻塞 IO**：可以让我们周期性地检查（轮询，poll）某个文件描述符上是否可执行从内核空间拷贝数据到用户空间。

  - 当用户进程调用 `recvfrom / read / write` 系统调用后，内核立即返回到用户进程，并后台准备数据拷贝至内核空间； 当内核在数据缓冲区中准备好数据时，用户进程再次调用`recvfrom`并阻塞，等待内核拷贝数据。
  - 用户第一个过程可不断调用IO，kernel不断返回error，直至第一个过程结束。  用户第二个过程调用后进程阻塞。
  - **注意**：本质是跳过内核准备数据阶段，它可以在`connect/accept/send/recv`中使用，返回的FD可以在`select / poll`做搭配。

  - 在linux中，socket可以设置为`O_NONBLOCK`

- **IO 多路复用**

  - 当用户进程调用 `select / poll` 系统调用后，对每个文件描述符：内核准备数据并拷贝至内核空间。当其中一个文件在内核空间准备就绪后，用户进程解除阻塞，选择文件描述符调用`read`让内核拷贝至用户空间。
  - 用户第一个过程阻塞，直至kernel结束第一过程，解除阻塞。用户第二个过程调用IO后阻塞。
  - **注意**：使用`O_NONBLOCK`，用户进程可以在第一步不阻塞，干别的事情。

  - **优点**：单进程可以同时处理多个网络连接IO。如果处理的连接数不是很高的话，使用多路复用IO不一定比使用多线程+阻塞IO性能更好。


- **异步 IO**
  - 当用户进程调用 aio_read 系统调用后，内核立即返回。并后台准备数据拷贝至内核空间和用户空间，完毕后向用户进程发送信号。
  - 两个过程皆不阻塞。

- **信号驱动IO**
  - 进程为通知信号绑定Handler函数，并设置监听的文件描述符属主。当 I/O 操作就绪时，内核为进程发送一个信号，然后调用信号处理函数。

由于非阻塞式I/O和多进线程都有各自的局限性，下列备选方案往往更可取：

- **I/O 多路复用**：允许进程同时检查多个文件描述符以找出它们中的任何一个是否可执行I/O 操作。
- **信号驱动 I/O**：是指当有输入或者数据可以写到指定的文件描述符上时，内核向请求数据的进程发送一个信号。进程可以处理其他的任务，当 I/O 操作可执行时通过接收信号来获得通知。当同时检查大量的文件描述符时，相比 select()和 poll()有显著的性能提升。
- **epoll**：允许进程同时检查多个文件描述符。当同时检查大量文件描述符时，能提供更好的性能。



### Q：select / poll / epoll？
> https://zhuanlan.zhihu.com/p/93609693

**select / poll**

在 Linux 内核层面，select和pol都使用了相同的内核poll函数。select的返回值等行为完全可以通过一些语言层面的转换成poll。

以下是系统调用select和poll之间的一些区别：

- **上限限制**：select的参数和返回值`fd_set`对于被检查的文件描述符数量有一个上限限制，poll没有限制。
- **重新初始化参数**：select的参数`fd_set`同时也保存返回值，如果重复调用的话，必须重新初始化它。而poll通过独立的两个字段来处理。
- **超时精度**：select()提供的超时精度（微秒）比 poll()提供的超时精度（毫秒）高。
- **FD关闭可感知**：如果被检查的文件描述符关闭了，poll()会准确告诉我们是哪一个文件描述符关闭了。与之相反，select()只会返回−1，并设错误码为EBADF。用户需要自行在描述符上I/O调用来检查错误码。



**epoll**

Linux 的 epoll（event poll）主要优点如下：

- 当检查大量的文件描述符时，epoll 的性能扩展性性比 select()和 poll()高很多。
- epoll API 既支持水平触发也支持边缘触发。与之相反，select()和 poll()只支持水平触发，而信号驱动 I/O 只支持边缘触发。

epoll的实现如下：

- 首先`epoll_create`创建一个epoll文件描述符，底层同时创建一个红黑树，和一个就绪链表。
  - 红黑树存储所监控的文件描述符的节点数据，就绪链表存储就绪的文件描述符的节点数据；
- `epoll_ctl`将会添加新的描述符，通过**红黑树判断文件描述符是否存在**。如果有，则立即返回。
  - 如果没有，在树上插入新的节点，并且**通过`waitqueue`告知内核注册回调函数**。
  - 每次 socket 状态变化，内核就可以**快速从红黑树查询**进程是否关心这个 socket，将该节点插入到就绪链表里面。
  - 再根据触发条件（LT和ET）判断是否出参。
- `epoll_wait`将会接收到消息，并且将数据拷贝到用户空间，清空链表。



**性能差异**

![select-poll-epoll-perf](/static/image/2022-02-24/select-poll-epoll-perf.png)

其实在Linux内核中，三者都使用了相同的内核poll函数。那么为什么 epoll 的性能表现会更好？当检查大量的文件描述符时，select和poll都会遇到一些问题：

- **每次调用内核O(n)检查**：
  - 每次调用select或poll，内核都**必须检查所有**被指定的文件描述符，看它们是否处于就绪态。
  - 通过`epoll_ctl`添加的FD，会注册在回调中。当调用`epoll_wait`后，通过`waitqueue`唤醒进程，直接返回就绪链表。
- **每次调用拷贝FD**：
  - 每次调用select或poll时，程序都必须传递所有需要FD数据结构到内核。
  - `epoll_wait`不携带FD参数，通过`waitqueue`唤醒进程，直接返回就绪链表。
- **每次调用用户O(n)检查**：
  - select()或 poll()调用完成后，程序必须**检查返回的数据结构中的每个元素**，以此查明哪个文件描述符处于就绪态了。
  - `epoll_wait`直接返回就绪链表。
  - （这里所花费的时间与上面两个相比微不足道）

二者糟糕的性能扩展性源自这些 API 的局限性：内核不会在每次调用后就记录下等待FD，而且没有回调机制。

epoll相比于select并不是在所有情况下都要高效：

- 有少于1024个文件描述符监听，且大多数socket都是活跃态。select要比epoll更为高效，因为epoll会有更多次的系统调用，用户态和内核态会有更加频繁的切换。
- epoll的应用场景在于需要监视大量的文件描述符，但大部分处于空闲状态，只有少数文件描述符处于就绪态。

|            |                       select                       |                       poll                       |                            epoll                             |
| :--------- | :------------------------------------------------: | :----------------------------------------------: | :----------------------------------------------------------: |
| 操作方式   |                        遍历                        |                       遍历                       |                       `waitqueue`回调                        |
| 底层实现   |                        数组                        |                       链表                       |                        红黑树 + 链表                         |
| IO效率     |      每次调用都进行线性遍历，时间复杂度为O(n)      |     每次调用都进行线性遍历，时间复杂度为O(n)     | 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到readyList里面，时间复杂度O(1) |
| 最大连接数 |              1024（x86）或2048（x64）              |                      无上限                      |                            无上限                            |
| fd拷贝     | 每次调用select，都需要把fd集合从用户态拷贝到内核态 | 每次调用poll，都需要把fd集合从用户态拷贝到内核态 |  调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝   |



### Q：边缘触发ET & 水平触发LT？epoll为什么在ET模式下搭配非阻塞IO？

> - https://juejin.cn/post/6844903878685622285

这是两种文件描述符准备就绪的通知模式：

- **水平触发LT**：如果文件描述符上可以非阻塞地执行 I/O 系统调用，此时认为它已经就绪。
  - 其实内核缓冲区有数据，就可以触发可读信号。
  - 所以当LT触发时，可以先读一半数据，水平触发会再次有效，亦然可以继续读没有读完的数据。
- **边缘触发ET**：如果文件描述符自上次状态检查以来有了新的 I/O 活动（比如新的输入），此时需要触发通知。
  - 当内核缓冲区从无到有，或从满到不满，可以触发可读信号。
  - 当ET触发时，先读一半数据而剩一半的话，边缘触发不会再进行通知。所以，ET模式需要一直读，直到`EAGAIN`表示缓冲区已空。

**epoll为什么在ET模式下搭配非阻塞IO？**

提供一个场景：

- A与B通过套接字在文件描述符rfd上建立了一个连接。
- A在epoll上注册一个文件描述符rfd。
- B向这个文件描述符写2kB的数据。
- epoll_wait告诉A：B发了数据过来，你可以读了。
- A粗心大意**只读取了1kB数据**，还有1kB的数据忘记读了，就以为自己读完了。
- 这时候epoll_wait调用完成。

这里注意阻塞IO是不要求用户一直读到缓冲区为空的，所以这容易让用户忘记缓冲区仍有数据。而非阻塞IO是要做到读`EAGAIN`才行的。

> An  application  that  employs the EPOLLET flag **should** use nonblocking file descriptors to avoid having a blocking read or write starve



### Q：有哪些方法可以监控内核Metrics？

> - https://manjusaka.itscoder.com/posts/2022/01/31/a-simple-introduction-about-network-monitoring-in-linux-kernel/
> - https://www.cnblogs.com/xinghuo123/p/13782009.html
> - https://arthurchiao.art/blog/trace-packet-with-tracepoint-perf-ebpf-zh/
> - https://www.iserica.com/posts/brief-intro-to-ebpf/

**The Proc Filesystem**

PROC文件系统是UNIX的操作系统中的一个特殊文件系统，它在层次文件的结构中呈现有关进程和其他系统信息的信息，提供更方便和标准化的方法，用于动态访问在内核数据而不是直接访问内核内存。PROC文件系统提供内核空间和用户空间之间的通信方法。例如，显示进程信息`pc`和网络信息的`netstat`都使用PROC文件系统获取其数据，而无需使用任何专门的系统调用。

具体举例：

- **进程信息**：`/proc/<PID>/`
  - **`/proc/<PID>/cmdline`**：启动该进程的命令行
  - **`/proc/<PID>/environ`**：环境变量的名字和值
  - **`/proc/<PID>/status`**：进程的基本信息，包括运行状态、内存使用。如`Pid / PPid`、线程个数`Threads`，驻留集大小`VmRSS`。
  - **`/proc/<PID>/task`**：包含子任务的目录硬链接
- **网络信息**
  - **`/proc/net/tcp`**：连接状态、本地地址端口、远程地址端口、慢启动阈值等
  - **`/proc/net/nf_conntrack`**：存在的网络连接
- **设备信息**
  - **`/proc/cpuinfo`**：各种CPU信息，如架构、Cache大学、核数等

**netlink + sock_diag**

但`procfs`通信方式都是同步的，只由用户态主动发起向内核态的通信，内核无法主动发起通信。

而Netlink是一种**异步全双工的通信方式**，它支持由内核态主动发起通信，内核为Netlink通信提供了一组特殊的API接口，用户态则基于socket  API，内核发送的数据会保存在接收进程socket 的接收缓存中，由接收进程处理。

一些语言的社区会对netlink做包装：

```go
package main

import (
	"fmt"
   	
    "github.com/vishvananda/netlink"
	"syscall"
)

func main() {
	results, _ := netlink.SocketDiagTCPInfo(syscall.AF_INET)
	
	for _, item := range results {
		if item.TCPInfo != nil {
			fmt.Printf("Source:%s, Dest:%s, RTT:%d\n", item.InetDiagMsg.ID.Source.String(), item.InetDiagMsg.ID.Destination.String(), item.TCPInfo.Rtt)
		}
	}
}
```



**eBPF + tracepoint / kprobe**

eBPF用于提供一种安全、友好的Linux内核态程序执行环境。eBPF程序是基于内核事件驱动的，在内核中特定事件发生时，用户编写的eBPF程序会被内核中的eBPF虚拟机执行。内核提供了eBPF即时编译功能，可以加速eBPF程序的运行。人们可以很方便地在Linux运行时动态扩展和丰富内核的能力。

eBPF的核心思想与BPF一脉相承，BPF用户在内核中处理和分析网络数据包，并过滤无关数据包。避免将大量数据包发送到用户态，节省了数据搬运的开销：

- **构建**：eBPF程序的目标文件是可以被eBPF虚拟机解释执行的eBPF字节码。
  - 除了用纯C写，还可以调一些三方库比如python的`bcc`
- **验证**：内核会先用eBPF Verifier验证程序的合法性：检查权限、程序是否导致内核崩溃、是否出现死循环。
- **注册与执行**：eBPF程序在完成构建后，需要“挂载”到内核上的对应事件上，当事件产生时，触发内核调用对应的eBPF程序。

```python
from bcc import BPF

bpf_text = """
BPF_RINGBUF_OUTPUT(tcp_event, 65536);

enum tcp_event_type {
    retrans_event,
    recv_rst_event,
};

struct event_data_t {
    enum tcp_event_type type;
    u16 sport;
    u16 dport;
    u8 saddr[4];
    u8 daddr[4];
    u32 pid;
};

TRACEPOINT_PROBE(tcp, tcp_retransmit_skb)
{
    struct event_data_t event_data={};
    event_data.type = retrans_event;
    event_data.sport = args->sport;
    event_data.dport = args->dport;
    event_data.pid=bpf_get_current_pid_tgid()>>32;
    bpf_probe_read_kernel(&event_data.saddr,sizeof(event_data.saddr), args->saddr);
    bpf_probe_read_kernel(&event_data.daddr,sizeof(event_data.daddr), args->daddr);
    tcp_event.ringbuf_output(&event_data, sizeof(struct event_data_t), 0);
    return 0;
}

TRACEPOINT_PROBE(tcp, tcp_receive_reset)
{
    struct event_data_t event_data={};
    event_data.type = recv_rst_event;
    event_data.sport = args->sport;
    event_data.dport = args->dport;
    event_data.pid=bpf_get_current_pid_tgid()>>32;
    bpf_probe_read_kernel(&event_data.saddr,sizeof(event_data.saddr), args->saddr);
    bpf_probe_read_kernel(&event_data.daddr,sizeof(event_data.daddr), args->daddr);
    tcp_event.ringbuf_output(&event_data, sizeof(struct event_data_t), 0);
    return 0;
}

"""

bpf = BPF(text=bpf_text)


def process_event_data(cpu, data, size):
    event = bpf["tcp_event"].event(data)
    event_type = "retransmit" if event.type == 0 else "recv_rst"
    print(
        "%s %d %d %s %s %d"
        % (
            event_type,
            event.sport,
            event.dport,
            ".".join([str(i) for i in event.saddr]),
            ".".join([str(i) for i in event.daddr]),
            event.pid,
        )
    )


bpf["tcp_event"].open_ring_buffer(process_event_data)


while True:
    bpf.ring_buffer_consume()
```



# 数据库




## 数据库系统原理

> - <https://blog.tanglizi.one/post.sh?name=2022-02-19_[CMU15-445]_数据库原理知识点总结.md>




### Q：如何理解数据库的范式？

> https://blog.csdn.net/zymx14/article/details/69789326

- **第一范式**：确保每一列的原子性

- **第二范式**：非键字段必须依赖于键字段
  - 如果一个关系满足1NF，并且除了主键以外的其它列，都依赖与该主键，则满足二范式(2NF)，第二范式要求每个表只描述一件事。

- **第三范式**：在1NF基础上，除了主键以外的其它列都不传递依赖于主键列，或者说： 任何非主属性不依赖于其它非主属性
  - 在2NF基础上消除传递依赖

- **BCNF**：主键不**部分**依赖与码



## MySQL

### Q：简单介绍索引

> - [数据库两个神器索引和锁(修订版) ](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484721&idx=1&sn=410dea1863ba823bec802769e1e6fe8a&chksm=ebd74430dca0cd265a9a91dcb2059e368f43a25f3de578c9dbb105e1fba0947e1fd0b9c2f4ef&token=1676899695&lang=zh_CN#rd)
> - [MySQL 的覆盖索引与回表](https://zhuanlan.zhihu.com/p/107125866)

**B+树索引**

- Mysql的基本存储结构是**页**；数据页之间组成一个**双向链表**；而**每个数据页中的记录**又可以组成一个**单向**链表
- 每个数据页都生成一个**页目录**：在通过**主键**搜索时，在页目录中**二分**到对应目录；在**非主键**搜索时，只能从最小记录开始**遍历单链表**。
- InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，**一个节点就是一个页**
-  B+ 树索引只能找到数据行对应的页，然后数据库把整个页读入到内存中，并在内存中查找具体的数据行。
- B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度
- **要维持平衡树，就必须做额外的工作**。正因为这些额外的工作**开销**，导致索引会降低增删改的速度



**哈希索引**

- 哈希索引没法利用索引完成**排序**
- 不支持**最左匹配原则**
- 在有大量重复键值情况下，哈希索引的效率也是极低的：**哈希碰撞**问题。
- **不支持范围查询**



**最左匹配原则**

- 从最左边的索引匹配开始，同时遇到范围查询(>、<、between、like)就会停止匹配。
- 原因：
  - B+树维护多个索引(a, b)时，叶节点首先按照a进行排序，其次按照b。最终按照二分查询。
  - 当查询(a>0, b=1)时，无法确定a的准确值，就无法索引b。



### Q：MySQL 多版本并发控制

> https://www.zhihu.com/question/263820564/answer/289269082

通过一定机制生成一个数据请求**时间点的一致性数据快照（Snapshot)**，并用这个快照来提供一定级别（**语句级或事务级**）的**一致性读取**。**MVCC读写是不阻塞**。



**Undo记录 版本链**  
MySQL InnoDB实现了多版本并发控制（MVCC），在多版本存储上，MySQL采用从新到旧（Newest To Oldest）的版本链。  
B+Tree叶结点上，始终存储的是**最新的数据（可能是还未提交的数据）**。  
而旧版本数据，通过UNDO记录（做DELTA）存储在回滚段（Rollback Segment）里。  
**每一条记录都会维护一个ROW HEADER元信息，存储有创建这条记录的`事务ID`，一个指向UNDO记录的`指针`。**  
通过最新记录和UNDO信息，可以还原出旧版本的记录。  



**ReadView 快照**      

ReadView描述某一个时间点，是事务执行状态的一个快照，可以用来判断事务的可见性。ReadView的基本结构如下：

```text
ReadView {
    creator_trx_id	// 创建这个ReadView的事务ID
    low_limit_id	// (未创建) 所有事务ID大于或等于low_limit_id对当前事务都不可见
    up_limit_id		// (已提交) 所有事务ID严格小于up_limit_id的事务对当前事务可见
    ids				// (执行中) 未提交的事务ID列表
    ...
}
```




**可见性的判断**

事务通过用当前事务（或语句，取决于隔离级别）的 ReadView 来判断一个事务id的操作是否对当前事务可见。判断可见性的伪代码如下：

```python
IsVisible(trx_id)
    if (trx_id == creator_trx_id)     	// 当前事务
        return true;
    else if (trx_id < up_limit_id)    	// ReadView创建时, 事务已提交
        return true;
    else if (trx_id >= low_limit_id)  	// ReadView创建时，事务还未被创建
        return false;
    else if (trx_id is in m_ids)  		// ReadView创建时，事务正在执行，但未提交
        return false
    else                          		// ReadView创建时, 事务已提交
        return true;
```

|  -> up_limit_id    |  ids    |  low_limit_id ->    |
| :--: | :--: | :--: |
|   已提交 可见   | 执行中 不可见 | 未创建 不可见 |




### Q：MySQL中的表级锁和行级锁 TODO

> [数据库两个神器索引和锁(修订版)](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484721&idx=1&sn=410dea1863ba823bec802769e1e6fe8a&chksm=ebd74430dca0cd265a9a91dcb2059e368f43a25f3de578c9dbb105e1fba0947e1fd0b9c2f4ef&token=1676899695&lang=zh_CN###rd)

InnoDB只有通过**索引条件**检索数据**才使用行级锁**，**InnoDB的行锁是基于索引的**。

**表锁**

- 加锁快；不会死锁；并发度低
- 表读锁 & 表写锁 阻塞的表现为读写锁

**行锁**

- 加锁慢；会死锁；并发度高
- 共享锁 & 排他锁 阻塞的表现为读写锁

**可重复读情况下的丢失更新**：

- 悲观锁：`select ... for update`（主键和unique行级锁；普通字段表级锁）
- 乐观锁：添加一个版本字段来实现`update A set Name=lisi, version=version+1 where ID=#{id} and version=#{version}`，当version不一致时，会出现失败情况。

**间隙锁 GAP**

-  `Repeatable read`隔离级别，**用范围条件检索数据**，并请求共享或排他锁情况。<br>`select * from  emp where empid > 100 for update`
- **可防止幻读**



### Q：MySQL隔离级别实现方法

**读未提交**：不加读锁，没有进行隔离

**读已提交**：（MV-2PL：语句级别快照隔离）**每次读**时生成快照ReadView

**可重复读**：（MV-2PL：事务级别快照隔离）**首次读**时生成快照ReadView

**读未提交**：S2PL



## Redis

> - https://zhuanlan.zhihu.com/p/91539644

### Q：Redis的特点和优势？

- **操作原子性**：Redis有着更为复杂的数据结构并且提供对他们的原子性操作。
- **数据类型**：string、hash、list、set、zset
- 支持事务
- 支持过期时间



### Q：Redis的数据类型和使用场景

> - https://www.cnblogs.com/lizhenghn/p/5322887.html
> - https://zhuanlan.zhihu.com/p/91539644
> - https://xie.infoq.cn/article/98c984f6462aec99ffc0c3b42

- **String**：
  - **内部存储**：默认是简单字符串SDS，遇到数字操作时会转成数值型进行计算
  - **场景**：缓存、计数器、Session。
- **Hash**：存储一系列kv对，逻辑上是单层Map。
  - **内部存储**：一位数组ZipList，当数量足够转换为HashTable。
  - **场景**：比较有限，可以做类似Key的聚合
- **List**：字符串列表。
  - **内部存储**：双向链表QuickList
  - **场景**：轻量消息队列、利用`lrange`做分页功能。

- **Set**：
  - **内部存储**：数组intset或值为nil的HashTable。
  - **场景**：分布式去重、集合命令做交并差。

-  **ZSet**：命令中多了一个权重参数score，集合中的元素能够按score进行排列。
  - **内部存储**：数组ZipList或者跳表SkipList
  - **场景**：排行榜、取TopN。



### Q：Redis为什么能做到操作原子性？事务原子性和隔离性？

> - https://stackoverflow.com/questions/43259635/is-redis-set-command-an-atomic-operation

**操作原子性**

因为Redis是单线程的，所有的命令都需要一个一个的执行。但是事务不同，事务间的命令可能cross，所以有额外的保护机制。

**事务原子性**

> - https://segmentfault.com/a/1190000023951592

| 命令    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| MULTI   | 标记一个事务块的开始                                         |
| EXEC    | 执行所有事务块内的命令                                       |
| DISCARD | 取消事务，放弃执行事务块内的所有命令                         |
| WATCH   | 监视一个（或多个）key，如果在事务执行之前这个（或多个）key被其他命令所改动，那么事务将被打断 |
| UNWATCH | 取消 WATCH 命令对所有 keys 的监视                            |

**原子性**不被保证。当事务中的一条语句执行出错（Hash命令用在String上），那么这个事务不会回退，而是跳过它继续执行（如果语法有误，那么在入队和`EXEC`时会报错）。

为什么不支持原子性或者回退呢？官方回答是这样可以保证Redis内部简单快速。真是大道至简呢。

**事务隔离性**

单机事务并发控制非常简单：当`EXEC`发生时把事务当作操作执行，所以单机下造成串行调度。但是注意这里的**隔离性**是指从`MULTI`开始时刻到`EXEC`执行时刻间没有冲突，这需要配合`WATCH`实现乐观并发控制：

- 在`MULTI`之前紧挨着`WATCH`，可以设置监视键；当 `EXEC` 被调用时，对所有键的监视都会被取消。
- 当事务执行过程中监视键改变，那么整个事务将被打断，不再执行， 直接返回失败。

> - 分布式事务：https://segmentfault.com/a/1190000040321750

那么分布式事务Redis支持么?我们讲分布式事务一般是指在多个分片上保证事务ACID，如原子性提交、分布式Join等。

那么关于原子性提交，我认为Redis使用`WATCH`应该就能做乐观并发控制，不过要对`watched_keys`做共识副本，如Raft等共识策略。



### Q：Redis集群是什么？Sharding和replicating如何做？

> - https://redis.io/topics/cluster-spec

**[Replicating] Master-Replica with Sentinel 哨兵模式**

> - https://redis.io/topics/sentinel
> - https://pdai.tech/md/db/nosql-redis/db-redis-x-sentinel.html

讨论Replica时我们讲哪些话题？主备同步模型、同步/异步复制、是否读写分离（主从一致性）、故障恢复（故障发现（单节点故障处理 / 多节点共识机制） + 主备切换/选举主节点 + 脑裂）

- **主备同步模型**：从节点首次复制使用RDB全量更新，往后使用AOF增量**异步复制**。（State Transfer + Replica State Machine）
  - 注意这里似乎可以从从复制。
  - 多个从节点宕机后，不要一起重启。这可能导致主节点IO剧增而宕机。
- **读写分离 / 主从一致性**：是读写分离 + 最终一致性。因为主从是异步复制的，没有多余的一致性保证。
- **故障恢复**：
  - **故障发现**：Sentinel哨兵模式，利用一种形式Gossip共识机制，用于心跳监控主从的独立进程。通常N个哨兵互相监控，同时监控所有主从。
  - **选举主节点 / 主备切换 / 处理脑裂**：
    - **Subjectively Down (SDown) / 主观下线**：单个哨兵检测网络不通
    - **Objectively Down (ODown) / 客观下线**：半数以上哨兵检测网络不通
    - **#1 Qourum**：首先某个哨兵发现master宕机，那么标记状态为SDown，请求其他节点投票：是否转变为ODown + 我是否成为发起ODown的主哨兵
    - **#2 Elect**：主哨兵筛选并排序出适合变为主的从节点。
    - **#3 通知**：主哨兵针对不同角色发不同消息：新Master解除从节点、其他节点认新Master、客户端通过Pub/Sub获知新主节点。



**[Sharding] - Cluster 集群模式**

讨论Sharding时我们讲哪些？分片策略（扩缩容）、分布式事务（原子提交协议）、重定向策略。

- **分片策略**：哈希槽。
  - 集群中有16384个哈希槽，每个key通过效验取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。
  - **扩缩容**：

- **重定向策略**：是由工作节点查询分片对应的节点，客户端受到重定向响应再去对应节点查询。
  - **MOVED**：MOVED重定向说明键对应的槽已经明确指定到新的节点，因此需要更新slots缓存。
  - **ASK**：ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是临时性的重定向，客户端不会更新slots缓存。

- **故障恢复**：集群中每个分片都有一个slave节点做故障恢复。
  - **故障检测**：节点间心跳监控每个其他节点。当节点间发现主观下线PFail，利用Gossip通知各个节点，Qourum到达后广播Fail状态。
  - **主备切换 / 故障转移**：各个主节点选择从节点，通过Qourum做共识，最后替换。



### Q：Redis分布式锁是什么？如何实现？

> - https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce

- **使用`setnx`+`expire`**
  - **问题**：这两个命令并不是原子性的，如果在执行`expire`服务器宕机，那么重启后这个key将会一直存在。

- **使用`set`扩展命令**：`set k v ex 5 nx`，超时5s不存在才写入
  - **问题**：锁被提前释放 & 锁被误删。
  - **解决方案**：不用长任务、用value来做CAS（用Lua脚本做`set + del`原子性）
- **Redisson**：通过不断询问任务结束来增加超时时间，处理提前释放问题。
- **Redlock**：Sentinel集群（异步复制）下的分布式锁，使用经典Qourum思想。
  - 客户端向N个节点请求锁，仅当N/2+1个节点同意，则申请成功。
  - 当客户端申请失败或使用结束后，向N个节点发送释放锁。
  - **等待申请锁**：客户端计时超时时间，避免服务器端 Redis 已经挂掉的情况下，死等响应结果。
  - **锁的可用时间**：客户端计算真正的锁可用时间：失效时间 = 当前时间 - 获取时时间
  - **故障恢复**：节点宕机的情况下，不要立即重启，而是等待锁的有效时间过了后重启。



### Q：单线程的redis为什么这么快

- 纯内存操作

- 单线程操作，避免了频繁的上下文切换

- 采用I/O多路复用



### Q：Redis持久化机制

Redis 提供了 RDB 和 AOF 两种持久化方式：

- **RDB**：fork子进程，把内存中的数据以快照形式压缩写入磁盘，保存在单一文件中
  - 快照保存完成之前如果宕机，这段时间的数据将会丢失。
  - 保存快照时可能导致服务短时间不可用。
- **AOF**：以追加文本日志的形式，记录每一个写操作
  - 支持每秒同步、每次修改同步和不同步。



### Q：Redis过期删除策略 & 驱逐策略

**过期删除策略**

- **定时删除**：Redis不用它。用一个定时器来负责监视key，过期则自动删除。
  - 虽然内存释放及时，但十分消耗CPU资源。

- **定期删除**：每隔100ms随机抽查key删除
  - redis默认每隔100ms检查，是否有过期的key，有过期的key则删除。
  - 将所有的key检查一次，而是先随机抽取进行检查，如果只采用定期删除策略，会导致很多key到时间没有删除。
- **惰性删除**：在获取某个key的时候，redis会检查是否过期，如果过期那么删除。

**淘汰策略**

当内存占用达到`maxmemory`的时候，根据不同的驱逐策略淘汰kv：

- **no-enviction**：禁止删除数据，新写入操作会报错
- **volatile-lru**：默认值。从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
- **volatile-ttl**：从已设置过期时间的数据集中挑选最少TTL的数据淘汰
- **volatile-random**：从已设置过期时间的数据集中任意选择数据淘汰
- **allkeys-lru**：从数据集中挑选最近最少使用的数据淘汰
- **allkeys-random**：从数据集中任意选择数据淘汰
- 还有**volatile-lfu**、**allkeys-lfu**：先根据使用频率淘汰最少的，如果有多个那么选择LRU。



### Q：缓存场景问题：缓存雪崩、缓存穿透是什么？缓存预热和更新的方法？

**缓存场景下的问题**

- **缓存雪崩**
  - 原有缓存失效，新缓存未到期间（在同一时刻出现大面积的缓存过期），原本应该访问缓存的请求都去查询数据库了，对数据库CPU和内存造成巨大压力。
  - **解决方法**：用锁或者队列的方式保证不会有大量的线程对数据库一次性进行读写，避免失效时大量的并发请求落到底层存储系统上。将缓存失效时间分散开。

- **缓存穿透**
  - 用户查询数据，在数据库中没有，自然在缓存中也不会有。这样就导致用户查询的时候在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）
  - **解决方法**：内存存储布隆过滤器。

**缓存预热和更新的方法**

- **缓存预热**
  - 缓存预热系统上线后，将相关的缓存数据直接加载到缓存系统。这样可以避免用户请求的时候，先查询数据库，再将数据缓存的问题。

- **缓存更新**
  - 定期清理过期的缓存
  - 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。



### Q：Redis中查询大量Key需要注意什么？

- **使用`keys`**：如果使用Keys指令，那么会导致线上服务阻塞。
- **使用`scan`**：可以无阻塞的提取出指定游标的一些Key。
  - 它返回一个新游标，客户端需要在下次scan时用它 来延续之前的迭代过程。
  - 有一定的重复概率，需要客户端做一次去重。



### Q：缓存与数据库不一致怎么处理？

> - https://zhuanlan.zhihu.com/p/59167071

关于缓存的使用，一般来说有三种模式：（与OS的两种cache不同在于多了cache-aside）

- **Cache-Aside / 旁路缓存**：由应用程序处理未命中
  - **读流程**：读缓存，如果未命中。则读数据库并更新缓存。
  - **写流程**：更新数据库，删除旧缓存。
- **Write Through / 写穿透**：由缓存（或中间件）来处理未命中
  - **读流程**：读缓存，如果未命中，由缓存读数据库、做响应并更新缓存。
  - **写流程**：缓存（中间件）更新数据库，再更新缓存。
- **Write Back / 写回**
  - **读流程**：读缓存。
  - **写流程**：写缓存，缓存满后或者脏数据过多，批量写回。
  - <u>无一致性保证，所以需要故障回复机制。</u>

**在Cache-Aside模式里，如何处理写不一致问题？**

- **先更新缓存，再更新数据库**：不使用
  - 数据库可能宕机或提交失败，造成缓存数据比数据库更新的情况。（因为数据库事务才是决定数据是否以写入的唯一标准）
- **先更新数据库，再更新缓存**：不使用
  - **更新丢失** ：`A_DB, B_DB, B_CACHE, A_CACHE`，这会造成B的更新丢失，或者说缓存不保证最新。我认为这是没有办法解决的，除非通过一些保证读写顺序的方法（S锁读取+X锁写入删除缓存，或者读写消息队列）。
  - **写多读少 / 写入成本高**：这种场景下，删除缓存懒加载的方式更好。

- **先删除缓存，再更新数据库**：解决了写多读少

- **先更新数据库，再删除缓存**：解决了写多读少

这里想讨论一下**延时双删**的策略：`DelCache, WriteDB, Sleep, DelCache`

- 它想解决在step1～2之间，其他客户端读到旧数据存入缓存的问题。
- **为什么不用超时时间**：可以在写入缓存时加超时时间，做到相似作用。不过缓存的效率就变低了。
- **最终一致性**：仍然是最终一致性，只不过不一致的时长更小（step2~step3之间）而已。
- **后台删除**：后台维护一个清除缓存线程，工作线程可以把step3~4交给它然后直接响应。
- Sleep的时长如何确定：稍大于`ReadDB + WriteCache`的时长

结论：上述方法都不能解决最终一致性问题，不过可以在降低不一致时间、降低写入成本上很有效。

**如果想做到强一致呢？**

那么必须调整读写顺序，让读请求（DB+Cache）发生在写请求（DB）之前：

- **DB的保证**：如果直接读数据库，不希望读到旧数据，那么使用**读已提交**隔离等级。
- **Cache的保证**：需要保证`ReadCache, WriteDB`之间的顺序
  - **消息队列**：读写请求入队即可保证一次只做一个请求，把未命中读数据库并更新缓存的操作原子化。
  - **加锁**：在更新缓存前，S锁读取数据库。同时在写入数据库时，用X锁并删除缓存。

# 数据结构与算法




## 基础



### Q：了解哪些排序算法，并比较一下，以及适用场景

> https://blog.csdn.net/mountain_hua/article/details/81107024

| 排序法     | 最差时间分析 | 平均时间复杂度 | 稳定度 | 空间复杂度      |
|------------|--------------|----------------|--------|-----------------|
| 冒泡排序   | O(n2)        | O(n2)          | 稳定   | O(1)            |
| 插入排序   | O(n2)        | O(n2)          | 稳定   | O(1)            |
| 选择排序   | O(n2)        | O(n2)          | 稳定   | O(1)            |
| 二叉树排序 | O(n2)        | O(n*log2n)     | 不一顶 | O(n)            |
| 快速排序   | O(n2)        | O(n*log2n)     | 不稳定 | O(log2n) ~ O(n) |
| 堆排序     | O(n*log2n)   | O(n*log2n)     | 不稳定 | O(1)            |
| 希尔排序   | O            | O              | 不稳定 | O(1)            |




### Q：快排的基本思路是什么？最差的时间复杂度是多少？如何优化？

> 优化：https://blog.csdn.net/sinat_28676875/article/details/69053449

```c++
int sort(vector<int>& nums, int l, int r) {
    if (l >= r) return;
    int ra = rand() % (r - l + 1) + l;
    swap(nums[ra], nums[l]);

    int i = l, j = r, x = nums[l];
    while (i < j) {
        while (i < j && nums[j] >= x) j--;
        if (i < j) nums[i++] = nums[j];

        while (i < j && nums[i] <= x) i++;
        if (i < j) nums[j--] = nums[i];
    }

    nums[i] = x;
    sort(nums, l, i, k);
    sort(nums, i+1, r, k);
}

```

优化方法：

1. 随机选择比较值
2. 元素少时用插入排序
3. 三向切分：大小关系分开后，将相等项排除递归





### Q：AVL树插入或删除一个节点的过程是怎样的？

> https://blog.csdn.net/Ivan_zgj/article/details/51495926

> https://blog.csdn.net/friendbkf/article/details/50160141




# 语言方面


## Rust



### Q：宏与过程宏

宏用于在编译时利用AST生成代码，它分为声明宏和过程宏。

声明宏利用`match`结构匹配AST，进行代码展开

过程宏直接处理词素流生成代码，它分为三种：

1. 导出宏：用于结构体自动实现，如`#[derive(Debug)]`
2. 类属性宏：用于自定义属性，如定义一个路由`#[route(GET, "/")]`
3. 类函数宏：将词素作为参数，比函数和声明宏更灵活。如定义SQL语句`let sql = sql!(SELECT * FROM posts WHERE id=1);`



### Q：Box

Box 首先是一个智能指针  

1. 智能指针是一类数据结构，他们的表现类似指针，但是也拥有额外的元数据和功能。

2. 在大部分情况下，相较于普通指针，智能指针拥有他们指向的数据。

3. 智能指针实现了 Deref 和 Drop trait。Deref trait 允许智能指针结构体实例表现的像引用一样，这样就可以编写既用于引用、又用于智能指针的代码。Drop trait 允许我们自定义当智能指针离开作用域时运行的代码。

4. 智能指针的实现采用内部可变性模式，指不可变类型能够暴露出改变其内部值的 API。

box 允许你将一个值放在堆上而不是栈上。它们多用于如下场景：

1. 当有一个在编译时未知大小的类型，而又想要在需要确切大小的上下文中使用这个类型值的时候

2. 当有大量数据并希望在确保数据不被拷贝的情况下转移所有权的时候

3. 当希望拥有一个值并只关心它的类型是否实现了特定 trait 而不是其具体类型的时候



### Q：Trait Object

trait 对象指向一个实现了我们指定 trait 的类型的实例，以及一个用于在运行时查找该类型的trait方法的表。此处涉及**动态大小类型和动态绑定原理**

1. trait 本身也是一种类型，但他的大小在编译期是无法确定的，所以必须要使用指针包裹。
2. trait 对象包括 **data 指针和 vtable 指针**。<br>data 指针指向**堆上**具体的类型数据； <br>vtable 指针指向**静态只读区上**实现 trait 的虚表，包括方法和类型大小等信息。
3. 使用条件：指定的 trait 中`Self`不可限定为`Sized`；trait 中所有方法类型安全（无泛型参数，返回值非`Self`）。



### Q：Trait Object 对象安全

trait 对象本身是动态分发的，编译器无法确定`Self`具体是哪个类型。

1. 指定的 trait 中`Self`不可限定为`Sized`

   无法确定`Self`具体是哪个类型，也就无法确定大小

2. 所有方法无泛型参数（一个方法有类似`fn foo<T>(&self, a: T)`的签名）

   rust的泛型是静态分发的，即单态化。<br>若一个方法带有泛型参数，则会在内存静态区的虚表中**单态化展开**所有对应的**具体类型**和对应的**泛型参数**。这是巨大的开销。

3. 所有方法仅第一个参数包含`Self`（如`self` `&self` `Box<self>`等）

   没有`Self`就是关联方法，只能用具体类型名调用（如`String::from`），使用不到 trait 对象。

4. 所有方法所有返回值非`Self`

   无法确定`Self`具体是哪个类型，所以无法返回。





### Q：动态分发和静态分发

**静态分发**

单态化是将通用代码转换为特定代码的过程。编译器使用泛型代码针对具体类型生成代码。我们可以使用泛型来编写不重复的代码，而 Rust 将会为每一个实例编译其特定类型的代码。这意味着在使用泛型时**没有运行时开销**，但同时容易出现**二进制文件膨胀**缺陷。



**动态分发**

使用一个运行时查找具体类型的trait方法的虚表，来实现Trait对象的方法。Trait 对象包含data指针和vtable指针，用于指向堆上的具体实例和静态区的对应虚表。当调用发生时，Trait 对象将根据虚表指针从虚表中查找正确的指针，然后动态调用对应方法。



### Q：Drop & Deref

实现 `Deref` trait 允许我们重载 **解引用运算符**。通过这种方式实现 `Deref` trait 的智能指针可以被当作常规引用来对待，可以编写操作引用的代码并用于智能指针

 `Drop`允许我们在值要离开作用域时执行一些代码。可以为任何类型提供 `Drop` trait 的实现，同时所指定的代码被用于释放类似于文件或网络连接的资源。



### Q：解引用强制多态

**解引用强制多态**是 Rust 在函数或方法传参上的一种便利。当引用作为实参传递和或调用方法时，解引用强制多态将自动发生。这时会有一系列的 `deref` 方法被调用，把我们提供的类型转换成了参数所需的类型。



## Java



### Q：异常与错误

> https://blog.csdn.net/qq_29229567/article/details/80773970

**Throwable**： 有两个重要的子类：Exception（异常）和 Error（错误）。异常能被程序本身可以处理，错误是无法处理。



**Error（错误）:**

- 是程序无法处理的错误，表示运行应用程序中较严重问题。大多数表示代码运行时 JVM 出现的问题。
- 无法捕获。

**Exception（异常）:**

- 是程序本身可以处理的异常。
- Exception 类有一个重要的子类  RuntimeException。RuntimeException 类及其子类表示“JVM  常用操作”引发的错误。例如，若试图使用空值对象引用、除数为零或数组越界，则分别引发运行时异常（NullPointerException、ArithmeticException）和 ArrayIndexOutOfBoundException。
- 而其他异常皆可捕获，即**可查异常**。



### Q：解释一下IoC和DI

IoC即控制反转，它最核心的地方在于，资源不由使用资源的双方管理，而由不使用资源的第三方管理，这可以带来很多好处：

- 资源集中管理，实现资源的可配置和易管理。
- 降低了使用资源双方的依赖程度，也就是我们说的耦合度。



DI即依赖注入，通过DI，对象的依赖关系将由系统中第三方组件在创建对象的时候进行设定，对象无需自行创建管理它们的依赖关系，依赖关系将被自动注入到需要它们的对象当中去。



## Java 并发

依次介绍 Java 容器、Java 锁、Java 线程相关内容。



### Q：HashMap 原理与不安全原理

>[HashMap 底层数据结构分析](https://snailclimb.gitee.io/javaguide/#/docs/java/collection/HashMap(JDK1.8)%E6%BA%90%E7%A0%81+%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90)
>
>[HashMap为什么线程不安全](https://juejin.cn/post/6917526751199526920)

**数据结构 - JDK8之前**

JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。

- 过程：HashMap 通过 key 的 hashCode 经过**扰动函数**处理过后得到 hash 值，然后通过 **`(n - 1) & hash`** 判断当前元素存放的位置。若冲突则用链地址法（拉链法）。
- 扰动函数：为了防止一些实现比较差的 hashCode() 方法，可以减少碰撞。



**数据结构 - JDK8之后**

JDK1.8 之后 HashMap 的组成多了红黑树，在满足下面两个条件之后（链表长度大于阈值（默认为 8）、HashMap 数组长度超过 64），会执行链表转红黑树操作，以此来加快搜索速度。若数组长度不大于64,则使用`resize()`进行扩容。

- 阈值：`threshold = capacity * loadFactor`，当容纳的元素数量大于等于阈值后，需要扩增数组。
- 加载因子：loadFactor 加载因子是控制数组存放数据的疏密程度，越趋近于 1，会让链表的长度增加；**loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。**
- 扩容：扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。



**线程不安全 - JDK8之前**

发生在多线程扩容时，在A线程扩容的过程中被挂起，同时B线程唤醒完成了扩容，等到A线程运行时会继续扩容，导致**链表死循环**和**数据丢失**。

```java
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while (null != e) {
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            e.next = newTable[i];
            // 此处挂起
            newTable[i] = e;
            e = next;
        }
    }
}
```



**线程不安全 - JDK8之后**

发生在`put`操作中，A线程在确定了hash索引并发现表中不存在链表时被挂起，此时B线程唤醒完成了`put`，此时A线程唤醒仍认为不存在链表，继续填入了新节点，导致**数据覆盖**。

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 此处挂起
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);

	...
}
```



### Q：ConcurrentHashMap 原理

**数据结构 - JDK1.8之前**

用分段数组+链表实现，将数组分为多个段，每个`Segment`段分配一个分段锁。当多线程访问不同的分段时，不存在锁竞争，提高并发度。

一个 `ConcurrentHashMap` 里包含一个 `Segment` 数组。`Segment` 是一种数组+链表结构，它包含一个 `HashEntry` 数组，每个 `HashEntry` 是一个链表结构的元素。

`Segment`继承了`ReentrantLock`，当对 `HashEntry` 数组的数据进行修改时，必须首先获得对应的 `Segment` 的锁。



**数据结构 - JDK1.8之后**

与1.8之后的 HashMap 一致，使用数组 + 链表/红黑树实现。并发控制则使用`synchronized`和CAS进行。

`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发。



### Q：HashTable 原理

数据结构与JDK1.8之前的 HashMap 一致（数组+链表），读写的并发控制全部使用全表锁（`synchronized`）进行，效率不高。



### Q：ThreadLocalMap 原理

这里讲容器顺便写一下`ThreadLocalMap`，需要注意的是 Hash 算法和它的内存泄漏原理与解决方法。



**数据结构**

每个`Thread`中保存有一个`threadLocalMap`，其中保存了单个`ThreadLocalMap.Entry`数组。其中`ThreadLocalMap.Entry`继承`WeakReference<ThreadLocal<?>>`，键为`ThreadLocal<?>`，值为`Object`。



**Hash 算法**

是开放地址法的线性探查方法，使用的 Hash 函数则是 fibonacci 函数。

斐波那契散列法是一种特殊的乘法散列，散列函数为h(k)=[m(kA mod 1)]。一般来说，m取值为2^p。关于A的取值，knuth为了得到更好的随即性， 认为A去黄金分割数是一个比较理想的值，因此A=0.6180339887。

所以你可以在`ThreadLocal`源码中发现一个`HASH_INCREMENT = 0x61c88647`。每当创建一个`ThreadLocal`对象，这个`ThreadLocal.nextHashCode` 这个值就会增长 `0x61c88647` 。



**内存泄漏原理**

注意到`Entry`继承了`WeakReference<ThreadLocal<?>>`，它的构造函数不难记：

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        this.value = v;
    }
}

// 获取键： e.get()
// 获取值： e.value
```

当内存中只存在键的弱引用时（即该线程中没有再引用`ThreadLocal`，这里注意即使键不引用，但值还是会在其他地方正常使用），下一次GC会清理掉`ThreadLocalMap`中的键，使得键变为`null`。但`value`则因为强引用而永远不会被清除，如果其他地方没有使用`value`的话，就会导致内存泄漏。

`ThreadLocalMap`的解决方法则是在`set() get() remove()`函数中进行线性探查的替换和消除键为`null`的`Entry`。

最好的方法还是在不需要引用`ThreadLocal`时，手动`remove`释放它。



### Q：原子类原理 CAS的思想

Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。要么失败要么成功。

四种原子类：

1. 基本类型：`AtomicInteger`，`AtomicLong`，`AtomicBoolean`
2. 引用类型：`AtomicReference`，`AtomicStampedReference`，`AtomicMarkableReference`
3. 数组类型：`AtomicIntegerArray`
4. 对象字段更新器：`AtomicIntegerFieldUpdater`



**原理**

AtomicInteger 类主要利用 CAS + volatile 的方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

底层依赖`Unsafe`类的CAS操作，降实例字段对应的offset进行修改的一种API方式。



**CAS的思想**

> http://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf

CAS将读写化作一个原子性操作，首先比较一个早已读出的值，如果相同则交换。

如果操作成功，说明读出值到CAS操作的这段时间中，没有其他线程能早于本线程完成（排除ABA问题，可以通过扩大状态空间解决）。这样能**保证竞争的正确进行**。

为什么能保证竞争的正确进行？让竞争有效的基础是，有能够验证本线程是首先完成的能力。详细展开它：

1. 我们首先需要知晓其他线程的状态，即能够知道他们其中是否存在已经完成的线程。
2. 其次本线程在获知自己是首先完成的情况下，如何让其他线程知晓本线程已经优先完成。
3. 必须将以上二者结合，否则会出现所有线程同时知晓自己优先完成的情况。

如果有其他线程先完成操作，那么本次读出值到CAS操作的代码必须应失去意义，因为这不被认为是竞争到的产物。



### Q：volatile 关键字

**Java 内存模型**

1. 介绍JMM：屏蔽硬件和操作系统的内存访问差异，达到一致性内存访问的效果，关注变量如何存储与内存和从内存读取的底层细节。
2. JMM的内存结构：规定线程存在独占的工作内存，其中存储了主存的数据副本；线程必须只能存工作内存中读写，工作内存和主存的交互有8种操作并且需要按照一定的规则（read load use assign store write lock unlock）「特例」
   1. assign 的数据不可丢弃
   2. lock 清除工作内存对应的值
   3. unlock 将工作内存的值写回主存
   4. load&read  store&write顺序而非连续。
3. 并发编程三个特性
   1. **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。`synchronized` 可以保证代码片段的原子性。
   2. **可见性** ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。
   3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化



**volatile 关键字**

1. volatile作用
   1. 保证可见性：对变量的写，保证其他线程能立即读到最新的值 
   2. 禁止重排序：一般在cpu处理汇编语句时考虑单线程表现为串行语义，而相互不依赖的两个语句会进行重新排序，进行并行执行。volatile会在某些场景下禁止重排序（读写写读）。
2. volatile实现原理
   1. 可见性: use&load&read assign&store&write  可认为连续执行，效果是读取前刷新工作内存、写入后刷新工作内存。 
   2. 有序性：
      1. 重排序在java编译器和cpu层面都有涉及，底层上通过内存屏障使cpu禁止重排序
      2. 使用lock汇编前缀可以提供缓存刷新的功能，同时也能将受到影响的cpu刷新内存
      3. 为什么lock前缀可以当作内存屏障？cpu重排序的过程是必须按照一定规则，不能使代码逻辑发生改变。当lock起效后，可以认为之前所有的代码执行完毕。



### Q：synchronized 原理与锁升级

**概念与历史**

`synchronized`关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

在JDK1.6前，它属于重量级锁。因为`synchronized`实现依赖于操作系统的锁，而操作系统的实现会直接将线程从用户态切换进入内核态，耗时较多效率低。

在JDK1.6之后，大量的优化提高了它的效率，优化手段有：**偏向锁**、**轻量级锁**（十次自旋锁、适应性自旋锁）、**锁粗化**（合并锁，降低锁请求）、**锁消除**（大量的`synchronized`实际上只在单线程中运行，开启逃逸分析后可以进行锁消除，当需要锁的对象不会逃逸出函数栈或线程则消除锁）。



**使用方法**

加在实例方法上；加在静态方法上；加在实例对象上

注意：

1. 静态方法上的锁，和`Xxx.class`的锁相同。
2. 实例方法上的锁，和实例对象的锁相同。
3. 实例对象和类对象的锁不互斥。
4. 构造方法不能修饰`synchronized`，因为它本身是线程安全的，不存在两个线程同时竞争构造一个对象。



**原理**

`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 对象监视器 `monitor` 的持有权（每个对象中都内置了一个 `ObjectMonitor`）。如果锁的计数器为 0 则表示锁可以被获取，或可释放。

另外，`wait/notify`等方法也依赖于`monitor`对象，这就是为什么只有在同步的块或者方法中才能调用`wait/notify`等方法，否则会抛出`java.lang.IllegalMonitorStateException`的异常的原因。



jvm 的`synchronized`方法使用了`ACC_SYNCHRONIZED` 标识指明该方法是一个同步方法。在调用和返回的指令中，隐式处理了调用同步方法时进入的监视器入口和返回时退出的监视器，就像使用了`monitorenter`和`monitorexit`一样。



**锁升级**

JDK1.6之后，`synchronized`锁的级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。

锁可以升级, 但不能降级. 即: 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁是单向的。锁的降级实际上是存在的，但是没有实用价值。这种策略是为了提高获得锁和释放锁的效率。

锁的状态被存储于 markword 中，001无锁、101偏向锁、00轻量级锁、10重量级锁。（11为GC存活标记）。

![synchronized](/static/image/2021-03-24/synchronized.png)



**偏向锁**

它的依据在于，大多数同步代码只会在同一个线程中被执行。

当线程获取锁时，jvm会在对象的 markword 中修改锁状态为101，并通过 CAS 将线程ID写入进去。

偏向锁不会解锁，只会撤销。当后续进入同步代码时，只需要判断线程ID是否相同即可。

当其他线程通过 **CAS 获取偏向锁失败**，并在safepoint时发现原线程**仍在同步代码**中时，它会升级成为轻量级锁。



**轻量级锁 - 自旋锁**

它的依据在于，大多数同步代码在同一个时间只会有一个线程进入。或者说对于同步代码，多个线程是交替进入的。

当线程获取锁时，会将当前栈中申请一个锁记录空间。将对象的 markword 记录于其中，并在 markword 中用 CAS 写入锁记录空间的地址，并改写锁状态00。（锁记录空间还会记录对象的地址。）如果 CAS 失败，表示存在锁的竞争，当前线程则开始自旋获得锁。

轻量级锁解锁时, 会使用原子的 CAS 操作将当前线程的锁记录替换回到对象头。

关于锁升级，JDK1.6下：如果在自旋一定次数后仍未获得锁，那么轻量级锁将会升级成重量级锁。JDK1.6 后：适应性自旋锁。



这里提一下自旋锁（一般用CAS）和互斥锁的优缺点：

1. 自旋锁在`while`循环中忙等，不会引发线程的阻塞就绪运行等耗时操作。当竞争程度不高并且同步代码快速时，适合使用。
2. 互斥锁在同步中，触发线程阻塞。当排队线程多并且代码慢速时适用。



**重量级锁**

直接调用操作系统底层的互斥量，会引发线程阻塞和就绪等耗时操作，但为长时间排队的线程提供了足够的并发量。



### Q：ReentrantLock 和 synchronized 区别与实现原理

可重入锁指的是自己可以再次获取自己的内部锁。如果是不可锁重入的话，就需要特殊处理否则会造成死锁。

1. 前者为API实现，后者由JVM实现。
2. 高级功能：
   - **等待中断**：`lockInterruptibly`线程在请求lock并被阻塞时，如果被interrupt，则“此线程会被唤醒并被要求处理InterruptedException”。
   - **公平锁**：先等待的线程先获得锁
   - **选择性通知**：`synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。



**线程的打扰机制**

每个线程都有一个 打扰 标志。这里分两种情况，

1. 线程在`sleep`、`wait`或`join`， 此时如果别的进程调用此进程的 `interrupt`方法，此线程会被唤醒并被要求处理InterruptedException；(thread在做IO操作时也可能有类似行为，见java thread api)
2. 此线程在运行中， 则不会收到提醒。但是 此线程的 “打扰标志”会被设置， 可以通过isInterrupted()查看并 作出处理。



**实现原理**

1. 可重入：使用计数器，进入时加一，释放时减一，当0时才进入或释放。
2. 公平锁：使用CLH队列锁，即虚拟队列中自旋等待前驱线程的锁释放。



### Q：AQS 原理

AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 `ReentrantLock`，`Semaphore`。



**原理**

1. 通过一个共享变量`volatile int state`表示共享资源，一个基于CLH的虚拟队列提供线程阻塞和唤醒机制。
2. 使用模板方法模式，具体的子类继承并覆写`tryAcquire - tryRelease`和`tryAcquireShared - tryReleaseShared`即可实现独占或共享资源的同步器。不用考虑调度等问题。



**经典CLH队列锁**

CLH队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。

CLH  锁是对自旋锁的一种改进，有效的解决两个缺点：不公平和多处理器频繁直接访问同一状态变量。

1. 首先它将线程组织成一个队列，保证先请求的线程先获得锁，避免了饥饿问题。
2. 其次锁状态去中心化，让每个线程在不同的状态变量中自旋，这样当一个线程释放它的锁时，只能使其后续线程的高速缓存失效，缩小了影响范围，从而减少了 CPU 的开销。

```java
class ClhLock {
    private final AtomicReference<Node> tail = new AtomicReference<>(new Node());
    private final ThreadLocal<Node> curNode = ThreadLocal.withInitial(Node::new);
    private final ThreadLocal<Node> preNode = ThreadLocal.withInitial(() -> null);

    public void lock() {
        Node node = curNode.get();
        node.locked = true;
        Node prev = tail.getAndSet(node);
        preNode.set(prev);
        while (prev.locked);
    }

    public void unlock() {
        Node node = curNode.get();
        node.locked = false;
        curNode.set(preNode.get());
    }

    static class Node {
        public volatile boolean locked;
    }
}
```



**AQS 对 CLH 队列锁的改造**

1. 将自旋锁改为阻塞线程。
2. 扩展更多功能，如支持超时中断等，显示的维护前后节点。



### Q：各种锁的使用场景

**Semaphore 信号量**

- 用于限制资源的个数，当信号量等于小于0时，再次获得锁将会阻塞。

```java
semaphore.acquire();
semaphore.release();   (InterruptedException)
```



**CountDownLatch 倒计时锁**

- 用于倒计时的功能，当多个线程处理计算后`countDown`，主线程等待`await`直到计时器到0时唤醒。

```java
latch.countDown();
latch.await();   (InterruptedException)
latch.await(timeout, timeUnit);   (InterruptedException)
```



**CyclicBarrier 回环栅栏**

- 用于多个线程间同步，当每个线程共享的`cyclicBarrier`被规定次数的`await`调用后，这些线程才继续执行（或还可运行规定的操作作为回调）。

```java
await() （InterruptedException, BrokenBarrierException
await(timeout, TimeUnit) (InterruptedException,BrokenBarrierException,TimeoutException)
```





### Q：手写自旋锁

> https://www.infoq.cn/article/BVPvyVxjKM8ZSTSpTi0L

1. 如何实现可重入？

   只需记录当前线程并计数。如果当前线程不是锁的所有者，则竞争锁或不释放锁；如果是锁的所有者，则计数器自增或计数器自减释放。

2. 如何实现公平？

   1. 获取锁前，获取一个`ticket`数字，当它与`serviceNumber`相同时，进入。释放锁则CAS`serviceNumber`自增。需要所有线程监听同一个变量，会导致cpu频繁访主存。
   2. CLH自旋锁，每次`my.lock`为真，获取虚拟队列中前一个节点的锁，等待`prev.lock==false`。释放则需要将`my.lock`改为假，并将自己的容器中的节点改为前一个节点。



**可重入自旋锁**

```java
class ReentrantSpinLock implements Lock {
    private final AtomicReference<Thread> owner = new AtomicReference<>(null);
    private int count = 0;

    public void lock() {
        Thread cur = Thread.currentThread();
        if (owner.get() != cur) {
            while (!owner.compareAndSet(null, cur));
        }
        count++;
    }

    public void unlock() {
        Thread cur = Thread.currentThread();
        if (owner.get() == cur && --count == 0)
            owner.set(null);
    }
}
```



**公平可重入自旋锁**

```java
class FairReentrantSpinLock implements Lock {
    private final AtomicInteger counter = new AtomicInteger(0);
    private volatile int serviceNumber = 0;
    private volatile Thread owner = null;
    private int count = 0;

    public void lock() {
        Thread cur = Thread.currentThread();
        if (cur != owner) {
            int ticket = counter.getAndIncrement();
            while (serviceNumber != ticket);
        }

        owner = cur;
        count++;
    }

    public void unlock() {
        Thread cur = Thread.currentThread();
        if (owner == cur && --count == 0) {
            owner = null;
            serviceNumber++;
        }
    }
}
```



**可重入CLH自旋锁**

CLH  锁是对自旋锁的一种改进，有效的解决了以上的两个缺点。

1. 首先它将线程组织成一个队列，保证先请求的线程先获得锁，避免了饥饿问题。
2. 其次锁状态去中心化，让每个线程在不同的状态变量中自旋，这样当一个线程释放它的锁时，只能使其后续线程的高速缓存失效，缩小了影响范围，从而减少了 CPU 的开销

```java
class ReentrantClhSpinLock implements Lock {
    private final AtomicReference<Thread> owner = new AtomicReference<>(null);
    private int count = 0;

    private AtomicReference<Node> tail =  new AtomicReference<Node>(new Node());
    private ThreadLocal<Node> pre = ThreadLocal.withInitial(() -> null);
    private ThreadLocal<Node> cur = ThreadLocal.withInitial(Node::new);

    public void lock() {
        Thread thread = Thread.currentThread();

        if (owner.get() != thread) {
            Node node = cur.get();
            node.locked = true;
            Node prev = tail.getAndSet(node);
            pre.set(prev);
            while (prev.locked);

            owner.set(thread);
        }
        count++;
    }

    public void unlock() {
        Thread thread = Thread.currentThread();
        if (owner.get() == thread && --count == 0) {
            Node node = cur.get();
            owner.set(null);
            node.locked = false;
            cur.set(pre.get());
        }
    }

    static class Node {
        public volatile boolean locked = false;
    }
}
```

它也有两个缺点：

1. 因为有自旋操作，当锁持有时间长时会带来较大的 CPU 开销。
2. 基本的 CLH 锁功能单一，不改造不能支持复杂的功能



### Q：手写单例模式

1. 懒汉式-线程安全

   ```java
   public static synchronized Singleton getUniqueInstance() {
       if (uniqueInstance == null) {
           uniqueInstance = new Singleton();
       }
       return uniqueInstance;
   }
   ```

   

2. 饿汉式-线程安全

   ```java
   private static Singleton uniqueInstance = new Singleton();
   ```

   

3. 懒汉式-线程安全-双重检验锁

   ```java
   public class Singleton {
   
       private volatile static Singleton uniqueInstance;
   
       private Singleton() {
       }
   
       public static Singleton getUniqueInstance() {
           if (uniqueInstance == null) {
               synchronized (Singleton.class) {
                   if (uniqueInstance == null) {
                       uniqueInstance = new Singleton();
                   }
               }
           }
           return uniqueInstance;
       }
   }
   ```

   1. 比单次检验有更好的效率
   2. 使用`volatile`的目的是禁止重排序。`x = new X()`的操作包含了三个原子的过程：申请内存空间、初始化对象、返回内存空间的引用。有时会重排2和3，但这样的话会导致线程A直接拿到引用而线程B通过第一次检验但对象却没有构建完毕。



### Q：ThreadLocal原理

实现每一个线程都有自己的专属本地变量。

每个`Thread`中保存有一个`threadLocalMap`，其中保存了单个`ThreadLocalMap.Entry`数组。其中`ThreadLocalMap.Entry`继承`WeakReference<ThreadLocal<?>>`，键为`ThreadLocal<?>`，值为`Object`。

当为`ThreadLocal`设置变量时，实际上是操作本线程对象的`threadLocalMap`添加或修改键值对。

更多详见上文`ThreadLocalMap`。



### Q：线程池

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。



![threadpool](/static/image/2021-03-25/threadpool.png)



**构造函数参数**

我们一般通过构造函数来创建线程池。

```java
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler
) { ... }
```

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- `keepAliveTime`:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
- `unit` : `keepAliveTime` 参数的时间单位。
- `threadFactory` :executor 创建新线程的时候会用到
- `handler` :饱和策略。



**饱和策略**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时， 根据策略来处理情况。下面是常见的策略:

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。



**execute vs. submit**

1. `execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；
2. `submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功。



## Golang

### Q：GPM模型

goroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多(M:N)的线程模型。

Go语言中支撑整个scheduler实现的主要有4个重要结构，分别是M、G、P、Sched。

- `M`指的是`Machine`，一个`M`直接关联了一个内核线程。由操作系统管理。
- `P`指的是`processor，代表了`M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接。
- `G`指的是`Goroutine`，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。

在程序启动时，创建N个线程执行schedule调度协程。调度首先从M个协程中寻找一个要执行的协程，运行该协程直到需要调度其它协程时才返回，保存协程状态回到调度第一步。具体而言：

- **对于线程**：在 Go 进程启动之后，干个物理线程进入调度函数，M从P取出（或工作窃取）可运行的协程执行，如果没有那么睡眠。

- **对于协程**：

  - **创建过程**：新创建的协程会先保存在本地队列或全局队列中。（本地满了去全局）等待被取出执行。
  - **网络调用 / 非阻塞调用**：当G执行之后，调度程序会将G保存上下文并切出M，M会继续循环寻找下一个。
    - 当 G 获得了想要的数据后，sysmon 线程会将 G 放入队列当中，等待着调度运行。
    - 注意：golang把socket的调用都封装成NONBLOCK，后面调用poll，runtime_pollWait

  - **系统调用**：当G发生了`syscall` 或阻塞操作。
    - 此时M物理线程大概率已经陷入内核，没有办法运行下一个G，这个系统调用只能占用一个物理线程。但是这个时候 M 实际上可能只是等待内核的 IO 数据，并不会占用 CPU。
    - 这时候，`sysmon`线程会检测到M已经阻塞，把这个线程M从P摘除，然后再创建一个新的线程尝试调度占用 CPU；
    - 当系统调用结束时候，这个 M 会尝试获取一个空闲的 P 执行。如果获取不到 P，那么这个线程 M 会 park 它自己(休眠)，加入到空闲线程中。



### Q：select原理

Go 语言会在运行时执行编译期间展开的 `selectgo` 函数，这个函数会按照以下的过程执行：

1. 随机生成一个遍历的轮询顺序 `pollOrder` ，和根据Channe 地址生成的固定锁定顺序 `lockOrder`（固定顺序用于防止死锁）；
2. 根据 `pollOrder` 遍历所有的 `case` 查看是否有可以立刻处理的 Channel 消息；
   - 如果有消息直接返回；
   - 如果没有消息就会创建 `sudog` 结构体，将当前 Goroutine 加入到所有相关 Channel 的 `sendq` 和 `recvq` 队列中并调用 `gopark` 触发调度器的调度；
3. 当调度器唤醒当前 Goroutine 时就会再次按照 `lockOrder` 遍历所有的 `case`，从中查找需要被处理的 `sudog` 结构并返回对应的索引；

然而并不是所有的 `select` 控制结构都会走到 `selectgo` 上，很多情况都会被直接优化掉，没有机会调用 `selectgo` 函数。

**一些关于select的语法知识**

1. 在Channel状态改变之前，`select` 会一直阻塞当前协程
2. 如果 `select` 控制结构中包含 `default` 语句，当存在可以收发的 Channel 时，直接处理该 Channel 对应的 `case`；否则执行 `default` 中的语句
3. `select case`中的表达式必须都是 Channel 的收发操作
4. `x, ok := <-c` 的语法是用来替代 `closed(c)` 语法判断 Channel 的关闭状态
5. `select` 在遇到多个 `<-ch` 同时满足可读或者可写条件时会**随机选择**一个 `case` 执行其中的代码，随机的引入就是为了**避免饥饿问题**的发生。



### Q：Context使用场景

1.  `context.Context` 的主要作用是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用
2.  除了构造新的Context的`Background`和`TODO`函数外，还有4个创建子上下文的函数：`WithTimeout`、`WithDeadline`、`WithCancel`和`WithValue`
3.  其中传值的`WithValue`的常见使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。



### Q：make和new

- make 的作用是初始化内置的数据结构，也就是我们在前面提到的切片、哈希表和 Channel；
- new 的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针
  - 注意：`new`没有递归地创建空间。

```go
type Test struct {
	Params map[string]string
}

func NewTest() *Test {
	return &Test{Params: make(map[string]string)}
}

func main() {
	t := new(Test)
	fmt.Println(t.Params == nil)		// true

	t = NewTest()
	fmt.Println(t.Params != nil)		// true
}
```

