# [CMU15-445] 数据库原理知识点总结

> - https://15445.courses.cs.cmu.edu/fall2021/schedule.html

这里将从lecture的顺序来做总结。下面是在并发控制中展示的图，它说明了整个数据库系统的大致组成部分：

![dbms-structure](/static/image/2022-02-19/dbms-structure.png)

# Storage / 存储

## Q：常见介质读写速度

![access-speed](/static/image/2022-02-19/access-speed.png)



## Q：数据库中讨论的Page是指什么？

![database-pages](/static/image/2022-02-19/database-pages.png)



## Q：DBMS如何存储各个Page？

一般而言有两种存储方式：

**Heap File**

堆文件是一个无序的页面集合，其中Tuple按随机顺序存储。而Heap File则通过使用页面链表或页面目录实现，用于给定页面id的时定位磁盘上的页面：

- Linked List：维护一个Header Page，里面存储free page和data page的位置；同时每个page带有双向链表的指针。
- Page Directory：维护一个目录页，存储每个page的位置。

![linked-list](/static/image/2022-02-19/linked-list.png)

![page-directory](/static/image/2022-02-19/page-directory.png)

**存储于索引**

B+Tree：Cluster Index聚簇索引，在叶节点上直接包含对应的数据页。

HashTable：哈希表也可以存储`<key, location>`，也可以存储`<key, tuple>`。相当于减少一次访存。



## Q：数据页的布局是什么样的？

**Slotted Pages**

这时当今dbms中最常用的方法。

- Page中的布局依次是头、空闲空间和Tuples数组。
- 其中Header记录了使用的槽数，最后一个使用的槽的起始位置，以及记录每个元组起始位置的槽数组。
- 对于Tuples数组部分，Tuples将从末尾到开始增长，响应的槽数组将从开始到结束增长。当槽数组和Tuple数据满足时，该页被认为是满的。

![slotted-pages](/static/image/2022-02-19/slotted-pages.png)

```
 table_page.h
 *  Slotted page format:
 *  ---------------------------------------------------------
 *  | HEADER | ... FREE SPACE ... | ... INSERTED TUPLES ... |
 *  ---------------------------------------------------------
 *                                ^
 *                                free space pointer
 *
 *  Header format (size in bytes):
 *  ----------------------------------------------------------------------------
 *  | PageId (4)| LSN (4)| PrevPageId (4)| NextPageId (4)| FreeSpacePointer(4) |
 *  ----------------------------------------------------------------------------
 *  ----------------------------------------------------------------------------
 *  | TupleCount (4) | Tuple_1 offset (4) | Tuple_1 size (4) | ...             |
 *  ----------------------------------------------------------------------------
```



**Log Structured**

一般DBMS只使用这种方法在存储日志记录。

- 为了读取记录，DBMS会扫描日志文件来重建日志。
- 适用于仅追加存储，因为DBMS不能返回和更新数据。所以写得快，读得慢。
- 为了避免长时间的读取，DBMS可以有索引，允许它跳转到日志中的特定位置。
- 可以周期性地压缩日志。但压缩的问题是DBMS最终会产生**写放大**。(Write Amplification，重复写相同的数据。)

![log-structured-file](/static/image/2022-02-19/log-structured-file.png)

![log-structured-snapshot](/static/image/2022-02-19/log-structured-snapshot.png)

## Q：什么是写放大？

> - [存储系统中的各种“写放大”](http://blog.jcix.top/2018-06-05/write_amplification/)



## Q：Tuple的内部结构是什么样的？

Tuple会存储两部分数据：

- Header：记录Tuple的大小、每个值是否为Null值的BitMap、并发控制的可见性信息等
- Payload：就是数据本身
  - 大部分数据库不支持Payload超过一个页
  - 可以将数据存储在一个特殊的“溢出”页面上，并让元组包含对该页面的引用的对象。这些溢出页可以包含指向其他溢出页的指针，直到可以存储所有数据为止。
  - 或者可以将数据存放在外部存储中，但这样就不能享受到DBMS提供的持久化和事务保证。

![overflow-page](/static/image/2022-02-19/overflow-page.png)

![external-file](/static/image/2022-02-19/external-file.png)

注意:

- 每个Tuple都有一个全局可访问的ID，一般而言是`page_id + offset`
- 如果两个表是相关的，那么**预连接**可能会有效：这两个表的数据最终会出现在同一个Tuple上。这使得读取速度更快，但更新成本更高



## Q：OLTP和OLAP工作负载区别？

OLTP：负载特征是快速且短暂的操作，典型的OLTP是写比读多的。

OLAP：负载特征是长时间且复杂的查询，定期会将数据从OLTP做ETL（提取转换加载）。

HTAP：二者混合。可直接在HTAP上做数据分析，也可以将数据转移在OLAP上。

![workloads](/static/image/2022-02-19/workloads.png)

## Q：数据页中Tuple的存储模型

这里的存储模型与数据页分布没有冲突，如Slotted Pages可以采用列式存储。不过列式存储的典型做法这里并没有介绍到，可以参考DDIA。

**N-Ary Storage Model (NSM） / 行存储**

DBMS将单个元组的所有属性连续存储在单个页面中。

这种方法对于OLTP工作负载非常理想：请求需要大量插入，且事务往往只操作单个实体。因为它只需要一次就能够获得单个Tuple的所有属性。

- **优势**：
  - 快速插入、更新、删除
  - 对查询Tuple所有属性的操作友好

- **缺点**：不适合做全表扫描、不适合做单独某些属性的查询（因为会查询到不需要的数据）

![nsm](/static/image/2022-02-19/nsm.png)

**Decomposition Storage Model (DSM) / 列存储**

DBMS将所有Tuple的列连续地存储在一个数据页中。

这个模型非常适合OLAP工作负载：大多数是只读查询，且常常做全表扫描 & 查询属性子集

- **优势**：
  - 减少了查询执行过程中浪费的工作量
  - 支持更好的压缩，因为相同属性的所有值都是连续存储的
- **缺点**：点查询、插入、更新和删除速度慢（因为需要多次随机查询，拼接出完整的Tuple）

![dsm](/static/image/2022-02-19/dsm.png)

拼接完整Tuple的方法有两种：

- **定长偏移量**：这是最常见的方法
  - 属性都是固定长度的，DBMS可以为每个元组计算属性的偏移量
  - 当拼接Tuple时，知道如何从offest跳转到文件中的该位置
  - 对于变长字段：维护`<offset, location>`的字典以便跳转；或者填充字段
- **内嵌ID**
  - 对于列中的每个属性，DBMS存储一个元组id。然后系统还会存储一个映射，告诉它如何跳转到每个具有该id的属性。
  - 这个方法有很大的存储开销，因为它需要为每个属性条目存储一个tuple id。

![dsm-history](/static/image/2022-02-19/dsm-history.png)

# Buffer Pool / 缓存

## Q：Buffer Pool是什么？为什么需要它？为什么不用OS的缓存？

Buffer Pool是从磁盘读取页面的内存缓存。它本质上是在数据库内部分配的一个大内存区域，用于存储从磁盘获取的页面。Buffer Pool的中的数据页被成为frame。

Buffer Pool维护的也不仅仅是Tuple和Index，更多的还有：sorting & joining缓存、查询缓存、日志缓存等。

**意义**

- DBMS面临的一个障碍是如何最大限度地减少移动数据的耗时。理想情况下，数据理应全部在内存中。
- DBMS比OS更加了解磁盘操作执行顺序和时机。比如：数据页淘汰策略、预取、脏页写回、WAL和checkpoint等。
- DBMS更清楚数据的时空局部性：在磁盘上经常使用的页面在物理上尽可能靠近、尽量减少从磁盘读取数据的档位数量。

大多数DBMS不使用OS缓存（O_DIRECT可绕过缓存）。不过，Postgres是一个使用操作系统页面缓存的数据库系统的例子。



## Q：锁与闩的区别？

![lock-vs-latch](/static/image/2022-02-19/lock-vs-latch.png)

## Q：闩的实现

**OS Mutex**

Linux提供了futex(快速用户空间互斥锁)，它由**用户空间中的自旋锁存器**和**操作系统级的互斥锁存器**组成。尽管它包含两个内部锁存器，但它看起来就像DBMS的一个锁存器。一些编程语言中包装了它，如C++`std::mutex`。

如果DBMS可以获得用户空间锁存器，那么就设置锁存器。如果DBMS没有获得用户空间锁存器，那么它就会进入内核，试图获得更重的互斥锁。如果DBMS没有获得第二个互斥锁，那么线程通知操作系统它被阻塞在这个互斥锁上，然后它被重新调度。

- 优势：简单易用；常用于处理等待进程多的场景，释放进程资源占用

- 缺点：开销太大，且不可扩展

**Spin Latch**

一般是指原子性的CAS。

- 优势：上锁/解锁很快
- 缺点：不可扩展，只能用在等待进程少的场景，否则占用进程资源；缓存不友好，因为它会出现导致缓存一致性问题，因为线程在轮询其他CPU上的缓存。

**RW Latch**

读写锁跟踪有多少线程持有它并等待获得锁。它在本质上使用前面两种锁存器实现中的一种作为原语，同时额外维护读写者队列，并记录读写者个数。

- 优势：读读可并发
- 缺点：可能导致饥饿问题（如果持续有reader占用锁，那么writer将饿死）。一个解决方法是当writer到来时，停止接受reader。

![rw-latch](/static/image/2022-02-19/rw-latch.png)

## Q：Buffer Pool的运作方式

当DBMS请求一个页面时，一个精确的副本被放置到缓冲池的一个帧中。然后，当请求页面时，数据库系统可以首先搜索缓冲池。如果没有找到该页，则系统从磁盘中获取该页的副本。

![buffer-pool](/static/image/2022-02-19/buffer-pool.png)

**metadata / 元数据**

- **页表**：内存中的哈希表，用于将页面id映射到缓冲池中的帧位置。
  - 页表还需要维护每页的额外元数据：**脏标记**和 **pin / reference counter**。
- **脏标志**：是由线程在修改页面时设置的。这指示存储管理器后续必须将该页写回磁盘。
- **pin / reference counter**：跟踪当前访问该页面的线程数。
  - 线程在访问该页之前必须增加计数器。如果一个页的计数大于零，那么存储管理器就不允许从内存中删除该页。



## Q：Buffer Pool的优化

**Multiple Buffer Pool**

支持的数据库：MySQL、Oracle、SQL Server、DB2

为不同的目的维护多个Buffer Pool。每个Buffer Pool可以采用针对存储在其中的数据定制的本地策略。该方法有助于减少锁存争用并改善局部性。

**预取**

根据查询计划预取页面。这是在连续访问多个页面时常用的方法。

**Scan Sharing / 共享游标**

支持的数据库：Oracle、SQL Server、PostgreSQL、DB2

查询游标可以重用扫描中检索到的数据：如果存在一个查询开始扫全表，那么DBMS就可以连接这个scan到第二个查询上。

**Buffer Pool 绕过**

支持的数据库：Oracle、SQL Server、PostgreSQL、Informix

顺序扫描操作符不会将获取的页面存储在缓冲池中，以避免开销。

因为某些数据大概率只会读取一次，比如读取连续大量页面时、临时数据查询时(排序，连接)。

后续会讨论到sequential flooding的情况，也可以用这种方法解决。



## Q：Buffer Pool的换页策略

**Least Recently Used (LRU) / 至少最近使用 / 最久未使用**

维护page队列。

- 当使用某个页时，将它放置在队头。
- 当驱逐某个页时，排出队尾元素。

**CLOCK**

维护环形链。每个元素都有一个计数位。

- 当使用一个页时，计数位设置为1。
- 当驱逐某个页时，如果页面的位设置为1，设置为零；如果不是，则驱逐它。

**Sequential Flooding / 顺序泛洪**

LRU和CLOCK容易受到顺序泛洪的影响：缓冲池的内容会因为顺序扫描，而不断被驱逐。

因为顺序扫描读取的每个页面，实际上是最不需要的页面，因为未来的一系列访问都不会再访问扫描过的页。

解决方法如下：

- 更大的工作集。
- 更好的换页策略：如LRU-K，它将最后K个引用的历史作为时间戳跟踪，用于预测页面下次被访问的时间。
- 查询的本地化：DBMS在每个事务/查询的基础上选择退出哪些页面。
- 优先级提示：允许事务根据查询执行期间每个页面的上下文告诉缓冲池页面是否重要。

**关于脏页**

这里的脏页会在后续的WAL中的checkpoint处理，如果使用简单checkpoint会直接写入磁盘，但是fuzzy checkpoint将在后台空闲执行.

# Access Methods / 访问方法

## Q：Hash Table的设计应该注意什么？

**Hash Function**：如何将一个较大的键空间映射到一个较小的域

- 需要考虑**执行速度**和**冲突率（均匀分布）**之间的权衡。
- DBMS不需要使用加密安全的哈希函数，不需要担心保护键的内容。
- 目前最先进的哈希函数是Facebook XXHash3。

![hash-function-benchmark](/static/image/2022-02-19/hash-function-benchmark.png)

**Hash Scheme**：如何处理哈希后的键冲突

- 需要考虑在分配一个大哈希表以减少冲突，还是在冲突发生时必须执行额外指令之间的权衡。



## Q：什么是 Static Hash Scheme / 静态哈希？

Static Hash Scheme，即哈希表的大小是固定的。如果哈希表中的存储空间用光了，那么必须重建更大的哈希表（通常两倍），这是非常昂贵的。

**Linear Probe Hashing / 线性探查**

是最基本的哈希方案，通常也是**最快的**。

数据结构上，它使用循环数组：

- 当冲突发生时，线性搜索相邻的插槽，直到找到一个开放的插槽，然后插入
- 对于查找，我们可以检查键散列所指向的槽，并线性搜索，直到找到所需的条目(或者一个空槽，在这种情况下键不在表中)
- 删除操作比较困难。为了不打破查询规则，一般有两种解决方案：
  - 墓碑位：为删除的数据打上墓碑位。查询时可以跳过，插入时可以直接插入。
  - 移动数据：直接将最末尾的数据移动到空位上。

关于**非唯一键**，有两种解决方案：

- 拉链法：每个槽将存储一个链表，相同hash的key存储在一起。
- 冗余键：直接存储即可，这是最常见的方案。

**Cuckoo Hashing / 布谷鸟哈希**

维护多个具有不同哈希函数的表。这里的哈希函数是相同的算法，但使用不同的种子。

- 当插入时，需要检查每个表，并选择一个有空闲槽的表
  - 如果没有表有空闲槽，我们随机选择一个表，并驱逐旧的条目。然后将旧条目重新散列到另一个表中。
  - 在极少数情况下，我们可能会陷入一个循环。这时需要重建所有哈希表，或者使用更大的表(更常见)重建哈希表。
- 这种Hashing保证了`O(1)`的查找和删除，但插入成本更高。

![cuckoo-hashing](/static/image/2022-02-19/cuckoo-hashing.png)

## Q：什么是 Dynamic Hash Scheme / 动态哈希？

动态哈希方案能够根据需要调整哈希表的大小，而不需要重建整个哈希表。

**Chained Hashing / 链式哈希**

这是最常见的动态哈希方案。DBMS为哈希表中的每个槽维护一个桶的链表，散列到相同槽位的键被简单地插入到该槽位的链表中。

注意：
1. 这里的链表是block（或者说page，它可以内涵多个元素）的链表，而非元素链表。
2. buckets扩容仍然需要rehash

![cuckoo-hashing](/static/image/2022-02-19/cuckoo-hashing.png)

**Extendible Hashing / 可扩展哈希**

GFS和ZFS等大多数文件系统使用这种方式来做Hash索引。

这种方法允许哈希表中的多个槽位置指向同一个bucket。其核心思想是在拆分时移动桶项，并增加比特数来检查哈希表中的条目。这意味着DBMS只需要在分割链的桶中移动数据;所有其他桶都保持原样。

- DBMS维护一个全局和局部深度位计数，它决定了在槽数组中查找bucket所需的位数。
  - 当查询时，需要降Key的后N位与全局槽位中的数进行匹配，然后访问对应的bucket。
- 当存储桶满时，DBMS将存储桶拆分并重新shuffle它的元素。
  - 如果拆分桶的局部深度小于全局深度，则新桶将被添加到现有的槽位数组中。否则，DBMS将插槽数组的大小翻倍以容纳新的存储桶，并增加全局深度计数器。
- 当删除元素时，可以触发Shrink，具体见2018 / 2019 Homework2

![extendible-hashing](/static/image/2022-02-19/extendible-hashing.png)

## Q：B+Tree的定义

B+树是一种自平衡的树数据结构，它保持数据排序，允许在`O(log(n))`内进行搜索、顺序访问、插入和删除。它是针对读写大块数据的面向磁盘的DBMS进行优化的数据结构。

现代的B+Tree实现结合了其他B-Tree变体的特性，比如Blink-Tree中使用的兄弟指针。另外，作为参照，这里给出每个优化的大致发表年份：1971 B-Tree、1973 B+Tree、1977 B*Tree、1981 Blink-Tree。

**定义**

B+树是一棵M路搜索树，且具有以下属性:

- 每个叶节点都在相同的深度，即完美平衡。
- 除根节点外，每个内部节点至少满一半`M/2−1 <= num of keys <= M−1`。
- 每个有k个键的内部节点有k+1个非空子节点。

一下是BusTub的叶节点定义，主要包括页信息、兄弟节点ID、父节点ID、`<key, RID>`对：

```
 * Store indexed key and record id(record id = page id combined with slot id,
 * see include/common/rid.h for detailed implementation) together within leaf
 * page. Only support unique key.
 *
 * Leaf page format (keys are stored in order):
 *  ----------------------------------------------------------------------
 * | HEADER | KEY(1) + RID(1) | KEY(2) + RID(2) | ... | KEY(n) + RID(n)
 *  ----------------------------------------------------------------------
 *
 *  Header format (size in byte, 28 bytes in total):
 *  ---------------------------------------------------------------------
 * | PageType (4) | LSN (4) | CurrentSize (4) | MaxSize (4) |
 *  ---------------------------------------------------------------------
 *  -----------------------------------------------
 * | ParentPageId (4) | PageId (4) | NextPageId (4)
 *  -----------------------------------------------
```

![b-plus-tree-leaf-node](/static/image/2022-02-19/b-plus-tree-leaf-node.png)

**查询**

这里想讨论一种非最左匹配的查询。比如索引包括了A、B两个列的属性，那么如何查询`<*, b>`的所有值？

从最后一层中间节点开始扫描，优化掉不需要访问的叶节点（指不包含`B==b`的叶节点），最后再依次访问叶节点即可。

## Q：B+Tree如何处理非唯一键？

与Hash表相似，两种方法：冗余键和拉链法。

## Q：Clustered Indexes / 聚簇索引

![clustered-indexes](/static/image/2022-02-19/clustered-indexes.png)

聚簇索引的优点：

- 减少额外存储空间，减少一次访存操作（虽然二级索引需要回表）
- 多版本GC + 删除时的tuple物理地址移动只会做一次
- 二级索引回表时，可以排序主键的访问顺序，做到顺序访问存储

## Q：B+Tree的设计选择

**节点大小**

- 取决于**存储介质**
  - HDD存储通常使用MB级别大小，以减少查找数据时访盘次数。
  - 内存数据库则使用最小为512B的页面大小，以便将整个页面放入CPU缓存，并减少数据碎片。
- 取决于**工作负载**
  - 点查询希望页面越小越好，以减少不必要的额外信息加载量
  - 大型顺序扫描可能希望页面越大，以减少所需的读取次数。

**合并阈值**：拖延删除插入时的合并操作

**可变长键**

- **指针**：只存储指向键的指针，而不是直接存储键(`<key-ptr, value>`)。
  - 效率很低。嵌入式设备会在生产中使用，其微小的寄存器和缓存可以从这种节省的空间中受益
- **可变长节点**：允许可变长度的节点
  - 不可行。由于处理可变长度节点的内存管理开销很大，所以基本上不使用
- **填充**：把短数据填充到最长数据的空间
  - 不可行。是对内存/存储的极大浪费。
- **Key Map**：额外存储一个`<key-ptr, kv-offset>`的映射
  - 几乎所有人都在用。
  - 甚至有足够的空间放置每个键的一个前缀`<prefix, <key-ptr, offset>>`，可能允许一些索引搜索和扫描

**中间节点访问方式**

到达节点后，仍然需要在节点内进行搜索(要么从内部节点查找下一个节点，要么在叶子节点中查找键值)

- **线性扫描**
- **二分查找**



## Q：B+Tree的优化

**Prefix Compression / 前缀压缩**

大多数情况下，叶节点中的大多数键的前缀会有重叠。我们可以简单地在节点的开头存储该前缀一次，然后只在每个槽中包含每个键的剩下一部分。

![prefix-compression](/static/image/2022-02-19/prefix-compression.png)

**Deduplication / 解冗余**

在允许非唯一键的索引的情况下，冗余键会生成多个相同的key`(key1, val1), (key1, val2)`。这里优化的方法是只写一次Key，然后在它后面跟着它的所有相关值：`(key, val1, val2, ...)`

**Bulk Insert / 大量插入 / 快速初始化**

当最初构建B+树时，可以直接构造一个有序的叶节点链表，然后从下向上构建索引，那么数据的初始插入将更加高效。

如果Bulk insert带上faster merging的话，就可以做到非初始化时的大量插入。下面是快速合并的一些方法：
1. 离线：阻止所有操作去合并
2. eager / 早访问：同时从两个index里做访问，如果查询结果有交集，那么用最新的
3. 后台合并：分布式下空闲机合并 / 空闲时合并
4. 懒合并：如果leaf没有变化，那么不合并



## Q：Hash Table如何做并发？

**Static Hash Table**

所有线程都沿着相同的方向移动，且线程一次也只访问一个页面，所以死锁是不可能的。因为没有两个线程会竞争由另一个线程持有的锁。所以直接上读写锁即可并发。

**Dynamic Hash Table**

其实是与静态hash table相同的做法，只不过有更多状态需要锁存。顺便CAS天然支持Insert操作，只需保证元素的CAS是原子性的即可。



## Q：B+Tree 如何做并发？

B+Tree做并发的主要问题在于如何解决一个线程遍历树，同时另一个线程拆分/合并节点。

**Latch Crabbing / Latch Coupling**

这是一个允许多个线程同时访问/修改B+Tree的协议：

1. 在访问的同时，从上到下给路径上的每个节点加锁。

2. 如果当前节点是安全的，那么释放所有父节点的锁。这里的安全是指，该节点不会拆分（插入时不是满的）或不会合并（删除时超过一半满的）。

**Basic Latch Crabbing Protocal**

**搜索**：从上到下，反复地获取子结点的读锁，然后释放结点的闩锁。

**插入 / 删除**：从上到下，根据需要获得写锁。一旦发现操作是安全的，那么释放他所有祖先的写锁。

注意：这里释放锁的顺序没有特别的讲究，不过从根开始释放会更好，因为根有更多的访问量。

**Impoved Latch Crabbing Protocal / 乐观的Latch Crabbing Protocal**

因为在插入删除时总需要根节点上获得独占锁，所以这限制了并行性。我们假定到目标叶节点的路径是大多数安全的，所以这里用读锁访问到叶节点检查安全性。

**搜索**：以前一样。

**插入 / 删除**：设置读锁访问叶节点，如果叶节点安全，那么设置叶子上的写锁；如果叶子不安全，使用之前的插入删除协议重新启动事务

# Operator Execution / 操作符执行

## Q：Sorting的原理

排序可能会在ORDER BY、GROUP BY、JOIN和DISTINCT操作符中使用。对于太大而无法装入内存的数据，标准的排序算法是外部归并排序：

- **Phase #1 – Sorting**：首先，该算法对装入主内存的小块数据进行排序，然后将排序后的页面写回磁盘

- **Phase #2 – Merge**：然后，该算法将排序后的子文件合并成一个更大的文件

**二路归并**

这个算法最基本的版本是二路归并排序。算法在排序阶段读取每个页面，对其进行排序，并将排序后的版本写入磁盘。然后，在合并阶段，它使用三个缓冲页进行（两个输入page，一个输出page）。

![2-way-merge-sort](/static/image/2022-02-19/2-way-merge-sort.png)

**I/O Cost**： $2N*(1 + ⌈log_2N⌉) $

其中，N是数据页个数，`1 + ⌈log2(N)⌉`是指sort和merge的总次数，`2N`是指每次对一个页的读写次数。

**K路归并**

该算法的一般化版本允许DBMS利用三个以上的缓冲页。设B是可用缓冲页的总数。在排序阶段，算法可以一次读取B个页面，并将`⌈N/B⌉`排序运行写回磁盘。合并阶段也可以在每个通道中合并B−1运行，再次使用一个缓冲页来合并数据，并在需要时写回磁盘。

**I/O Cost**： $2N*(1 + ⌈log_{B-1}⌈\frac{N}{B}⌉⌉) $

其中，B-1是每次可以进行合并的page个数。



## Q：Sorting优化

**双缓冲优化**：外部归并排序的一种优化方法是在后台预取下一次运行，并在系统处理当前运行时将其存储在第二个缓冲区中。通过持续使用磁盘，这减少了每一步I/O请求的等待时间。

**Clustered B+Tree**：如果索引是聚集索引，DBMS可以遍历B+树。由于索引是聚集的，数据将按照正确的顺序存储，因此I/O访问将是顺序的。



## Q：Aggregations的原理

聚合操作符将多个Tuple的值折叠为单个标量值。一般有两种实现聚合的方法：

**Sorting**

DBMS首先在GROUP BY键上对元组进行排序。它可以使用内存中的排序算法(例如，快速排序)，或者使用外部归并排序算法(如果数据的大小超过了内存)。然后DBMS对排序的数据执行顺序扫描以计算聚合。

**Hashing**

对于计算聚合而言，Hashing比排序运算成本更低。DBMS在扫描表时填充一个哈希表。对于每条记录，检查哈希表中是否已经有一个条目，并执行reduce。

- **Phase #1 – Partition**：使用哈希函数，根据目标hash键将Tuple映射成磁盘上的分区。这将把所有带有相同键的Tuple放入同一个分区（即某个key不可能在别的分区存储）。
- **Phase #2 – ReHash**：对于磁盘上的每个分区，将其页面读入内存。使用另一个哈希函数，构建一个**内存哈希表**`<GroupByKey, Tuple>`。然后遍历这个哈希表的每个bucket，将同一个Key的Tuple放在一起来计算聚合。

注意：partition在这里是为了降低rehash的内存空间，因为相同的GroupKey已经在同一个bucket里，这个GroupKey的结果可以在本bucket扫描结束后直接提交。

![aggregations-partition](/static/image/2022-02-19/aggregations-partition.png)

![aggregations-rehash](/static/image/2022-02-19/aggregations-rehash.png)

![aggregations-hashing-summary](/static/image/2022-02-19/aggregations-hashing-summary.png)



## Q：Join的原理

这里的链接专指等值链接，非等值链接大差不差。

**运算符的输出**

联接操作符生成的输出Tuple的内容是不同的。它取决于DBMS的查询处理模型、存储模型和查询本身：

- **early materialization / 早实体化**：这种方法将两个表中的属性值复制到结果中。这里可以省略部分属性来减少内存消耗。
  - 优点：Query Plan中的操作符不需要回表来获取数据
  - 缺点：需要更多的内存。
- **late materialization / 晚实体化**：DBMS只复制连接键和匹配元组的记录id
  - 列存储天然支持这种方法，因为DBMS不会复制查询不需要的数据。

**Nested Loop Join / 嵌套循环**

在高层次上，这种类型的连接算法由两个嵌套的循环组成，判断Tuple匹配连接并输出。外层for循环中的表称为外层表，而内部for循环中的表称为内部表。

下面的开销分析中，外表R中有M个页面，其Tuple个数为m；内表S中有N个页面，其Tuple个数为n。

- **Simple Nested Loop Join / 简单嵌套**：对于外部表中的每个元组，将其与内部表中的每个元组进行比较
  - **IO Cost**：$M+(m*N)$

![nested-loop-join](/static/image/2022-02-19/nested-loop-join.png)

- **Block Nested Loop Join / 块嵌套**：对于外部表中的每个块，从内部表中获取每个块，并比较这两个块中的所有元组。
  - **IO Cost**：$M+(M*N)$
  - 如果DBMS有B个缓冲区可用来计算连接，那么它可以使用B - 2个缓冲区来扫描外部表（一个缓冲区扫描内表，一个缓冲区存储输出）。**IO Cost**：$M+(⌈\frac{M}{B-2}⌉*N)$

![block-loop-join](/static/image/2022-02-19/block-loop-join.png)

- **Index Nested Loop Join / 索引嵌套**：如果数据库已经在连接键上为内表建立了索引，那么它可以使用该索引来加速比较。
  - **IO Cost**：$M+(m*C)$

![index-loop-join](/static/image/2022-02-19/index-loop-join.png)

**Sort-Merge Join / 归并连接**

![sort-merge-join](/static/image/2022-02-19/sort-merge-join.png)

当一个或两个表已经**按照连接属性排序**(比如聚集索引)，或者**输出需要按照连接键排序**，那么这个算法是有用的。

对于这个算法，最坏的情况是两个表中所有元组的join属性包含相同的值，这在真实的数据库中是不太可能发生的。此时，合并成本为M·N。

- **Sort Cost**：$2N*(1 + ⌈log_{B-1}⌈\frac{N}{B}⌉⌉) + 2M*(1 + ⌈log_{B-1}⌈\frac{M}{B}⌉⌉) $
- **Mege Cost**：$M+N$

**Hash Join / 哈希链接**

哈希连接的思想是使用哈希表根据Tuple的连接属性将其分割成更小的块。这减少了DBMS需要对每个元组执行比较来计算连接的次数。**散列连接只能用于等值连接。**

- **Basic Hash Join**
  - **Phase #1 – Build**：扫描外表，并使用JoinKey做hash填充哈希表
  - **Phase #2 – Probe**：扫描内表，根据JoinKey跳转到外表的哈希表对应值上，然后做链接并输出
  - 如果DBMS知道外部表的大小，则第一步可以使用静态哈希表
  - 使用Bloom Filter可以加速第二步。它可以使用更少内存来判断不存在性，减少了Hash表的读入。
  - 当表不适合放在主内存中时，DBMS不得不基本上随机地进进出出读hash表，这将导致较差的性能。

![basic-hash-join](/static/image/2022-02-19/basic-hash-join.png)

- **Grace Hash Join**：它也将内部表散列到写入磁盘的分区，但是不会出现hash表的频繁读入。
  - **Phase #1 – Build**：扫描内外表，并使用JoinKey做hash填充哈希表分区。
    - 如果需要插入到一个已满的bucket，这时可以使用不同的哈希函数h2，使用递归分区来进一步划分bucket。这可以避免多对多的Nest Loop，减少频繁读入。
  - **Phase #2 – Probe**：对于每个层的Bucket，查询内外表的相应页面，然后执行嵌套循环连接。这些页面可以装入内存，因此这个连接操作将会很快。

**IO Cost**：$2(M+N) + (M+N)$

![grace-hash-join](/static/image/2022-02-19/grace-hash-join.png)

![grace-hash-join-recursive](/static/image/2022-02-19/grace-hash-join-recursive.png)

**总结**

![join-summary](/static/image/2022-02-19/join-summary.png)

在等值链接时，系统默认使用HashJoin。当有两个条件满足时用SortMerge。后续的基于cost的优化器可以来做选择。



## Q：操作符的处理模型是什么样的？

DBMS的处理模型定义了系统如何执行查询计划。这些模型也可以实现为从上到下或从下到上调用操作符。虽然从上到下的方法更为常见，但从下到上的方法可以更严格地控制缓存/寄存器。

**Iterator Model / 迭代器模型**

迭代器模型，也称为Volcano或Pipeline模型，是最常见的处理模型，几乎每个行存储DBMS都使用它。支持的数据库：SQLite、MongoDB、DB2、SQL Server、PostgreSQL、Oracle、MySQL。

迭代器模型通过为数据库中的每个操作符实现Next函数来工作。查询计划中的每个节点调用子节点上的Next，直到到达叶节点，叶节点开始向其父节点发出元组以进行处理。

![iterator-model](/static/image/2022-02-19/iterator-model.png)

查询计划中为给定Tuple执行的一系列任务称为**pipeline**。其中有些操作符会阻塞，直到子操作符发出它们的所有元组。此类操作符的例子包括<u>连接、子查询和排序(ORDER BY)</u>，他们被称为**pipeline breaker**。

**Materialization Model / 实体化模型**

支持的数据库：VoltDB、monetDB

在迭代器模型中，每个操作符同时处理其所有的输入，然后同时发出所有的输出。每个查询计划操作符都实现了一个Output函数。这个函数的返回结果是操作符将发出的所有元组。

![materialization-model](/static/image/2022-02-19/materialization-model.png)

- 它更适合于OLTP工作负载，因为查询通常一次只访问少量的元组。因此，检索元组的函数调用更少。
- 它不适用于具有较大中间结果的OLAP查询，因为DBMS可能不得不在操作符之间将这些结果溢出到磁盘上。

**Vectorization Model / 向量模型**

支持的数据库：Oracle、DB2、SQL Server、RedShift、snowflake、presto。

每个操作符发出的是一批数据(即向量)，而不是单个元组。它是为处理批量数据而不是一次处理单个项目而优化。

![vectorization-model](/static/image/2022-02-19/vectorization-model.png)

它适合OLAP查询，因为可以减少对Next函数的调用。



## Q：访问操作符

访问方法是DBMS访问存储在表中的数据的方式。一般而言只有两种：

**Sequential Scan / 顺序扫描**

顺序表扫描几乎总是DBMS执行查询时效率最低的方法。有许多优化可以帮助使顺序扫描更快：**预取**、**绕过Buffer Pool**、**并发扫描**、**晚实体化**

**Index Scan / 索引扫描**

- 选取哪个索引来做扫描是很关键的，这个过程中涉及到很多因素：索引包含什么属性、查询什么属性、属性的值域
  - 比如，在第一个场景中，最好在扫描中使用dept索引，因为它只有两个元组要匹配。在第二种情况下，age索引将消除更多不必要的扫描。
  - 后续讲到使用Histogram来优化查询。

![choosing-index](/static/image/2022-02-19/choosing-index.png)

- **多索引扫描**：使用每个匹配的索引计算ID集合，再根据查询的谓词取交集/并集。
  - DBMS可以使用位图、哈希表或布隆过滤器通过集合交集来计算记录id



## Q：where语句 / 谓词如何被执行？

DBMS将WHERE子句表示为一个表达式树，其中节点表示不同的表达式类型。

DBMS将遍历树来计算它的操作符并产生一个结果。以这种方式计算谓词很慢，一个优化是直接对表达式求值，减少节点个数。

![expression-evaluation](/static/image/2022-02-19/expression-evaluation.png)

# Query Plan / 查询计划

## Q：什么是Query Plan？生成Query Plan的步骤？

因为SQL是声明式的，所以查询只告诉DBMS要计算什么，而没有告诉DBMS如何计算。因此，DBMS需要将SQL语句转换成可执行的查询计划。查询计划也就是可以执行的Operator组成的树。

![query-plan-overview](/static/image/2022-02-19/query-plan-overview.png)

1. SQL查询：客户端向DBMS系统发送一个SQL查询。
2. SQL重写：该查询可能被重写为不同的格式（不过很少有人做）。
3. 生成AST：SQL字符串被解析为组成语法树的标记。
4. 生成逻辑计划：绑定器通过查询系统Catalog将AST中的命名对象转换为内部标识符（如表、属性等）。
5. 优化逻辑计划：这里Tree Rewriter将应用一些静态规则进行大致优化。
6. 生成物理计划：将逻辑计划交给优化器，优化器通过cost model选择最有效的过程来执行计划。



## Q：什么是Query Optimizer？

在查询计划中执行每个操作符有不同的方法(例如，连接算法)，这些计划之间的性能也会有所不同。查询优化器的工作是为任何给定的查询选择一个最佳的计划。一般来说，优化器有两种实现方法：

- **static rules / heuristics / 启发式方法**：将查询的部分与已知的模式进行匹配，以重组一个查询计划。一般用于优化逻辑计划。
  - 这些规则是为了优化效率低下的查询。
  - 尽管这些规则可能需要查看Catalog以了解数据的分布，但它们从来不需要检查数据本身。
- **cost-based search / 基于成本的搜索**：读取数据并估计执行等价计划的成本，寻找接近最低成本的查询计划。一般用于优化物理计划。
  - 大多数新的数据库系统只使用启发式，而不是复杂的成本模型来选择访问方法。

关于ML的优化器，学术界有很多研究，但是工业界没有用任何ML方法。



## Q：逻辑计划与物理计划是什么？

- **逻辑计划**：指逻辑代数表达式层面的计划。大致相当于查询中的关系代数表达式。
  - 这里的理论依据在于，如果两个关系代数表达式生成相同的元组集，则它们是等价的。
- **物理计划**：指物理操作符的特定执行策略。这取决于所处理数据的物理格式(即排序、压缩)。



## Q：常见逻辑查询优化有哪些？

**selection optimization / 谓词优化**

- **谓词下推**：尽可能早地执行过滤器。
- **谓词重排**：首先应用最具选择性的谓词。
- **谓词拆分**：拆分一个复杂谓词并将其向下推。
- **谓词合并**：比如合并多个相交的range谓词。

**projection optimization / 投影优化**

- **投影下推**：尽可能早地执行投影以创建更小的元组并减少中间结果。
- **按需投影**：只投影出要求的属性。

**subquery optimization / 子查询优化**

- **解除关联 / 扁平化**：将子查询变为join操作。
- **提出子查询**：如果每个子查询都不依赖外部查询，那么可以提出一个公共查询出来。

下面是一个逻辑计划优化的例子

![query-optimization-example](/static/image/2022-02-19/query-optimization-example.jpeg)



## Q：成本估计的过程是怎么样的？

这里的成本估计是指，根据内部统计信息，来预测谓词能够选择出多少Tuple。这些内部统计信息可以在后台更新。

**selection cardinality / 基于选择基数**

在计算谓词的选择基数时，会使用一些假设：数据分布均匀（每个key都出现N次）、属性间互相独立（名字与性别无关、或年龄与院系无关）等。虽然真实的数据往往不能满足这些假设。这样我们可以根据Tuple总数估计某些谓词能够产出多少Tuple。

**Histogram / 基于直方图**

真实的数据往往是扭曲的，很难做出假设。既然如此，不妨将真实数据分布做一些压缩。

- **Histogram / 直方图**：一种减少内存使用量的方法是用直方图存储数据。比如`sel(age < 50)`可以直接从直方图中读取出来。
  - **累计直方图**：这里更好的方法是用累计直方图，就像Promethues那样，可以支持`O(1)`的范围查询和点查询。

- **Quantiles / 分位图**：另一种方法是使用等深度直方图，它改变桶的宽度，以便每个桶的总出现次数大致相同

**Sampling / 基于采样**

DBMS可以使用抽样将谓词应用到具有类似分布的表的较小副本上（可能是10%）。这样也算压缩了真实分布。



## Q：基于成本的优化过程是什么样？计划枚举是什么？

在执行基于规则的重写之后，DBMS将枚举查询的不同计划，并估计它们的成本。然后在耗尽所有计划或某个超时后为查询选择最佳计划。

**Single-Relation Query Plans**

对于单关系查询计划，最大的障碍是选择最佳的访问方法(例如，顺序扫描、二分搜索、索引扫描等)。

- 对于OLTP查询，这特别容易。因为它们是sargable，这意味着存在一个可以为查询选择的最佳索引。

- sargable是指总可以使用索引来访问数据。一个non-sargable的例子是，where中的列值做不可逆函数，那么是算不出这个列值在索引中的key

大多数新的数据库系统只使用启发式，而不是复杂的成本模型来选择访问方法。

**Multi-Relation Query Plans**

随着连接数量的增加，可选计划的数量也迅速增加。我们选择left-deep joining tree来做这件事，这是因为左深连接树更适合管道模型，因为DBMS不需要具体化连接操作符的输出。

![left-deep-join-tree](/static/image/2022-02-20/left-deep-join-tree.png)

下面三种方法，都是为了确定连接顺序、每个操作符的实现（如HashJoin / SortMergeJoin）、表的访问方式（如index#1、index#2、seq scan等）。

- **DP**：对每个状态做最低cost的状态转移。

![dp-for-query-optimization](/static/image/2022-02-20/dp-for-query-optimization.png)

- **随机优化方法**：PostgreSQL在12个及以上的表join时，用遗传算法来做优化。
  - 一种蒙特卡罗算法，具有一类随机优化方法的特性：采样越多越接近最优解

![genetic-optimization](/static/image/2022-02-20/genetic-optimization.png)

- **枚举**：为每个步骤进行枚举，这个过程可以带剪枝。

![enum-step-1](/static/image/2022-02-20/enum-step-1.png)

![enum-step-2](/static/image/2022-02-20/enum-step-2.png)

![enum-step-3](/static/image/2022-02-20/enum-step-3.png)



# Concurrency Control / 并发控制

并发控制覆盖了操作符执行和访问方法，它本质上是控制事务中操作的调度。

## Q：ACID是什么？

- **原子性**：原子性确保事务中的所有动作都发生，或者不发生。
  - 关注点在<u>事务有回退的能力</u>，而且回退过程需要考虑故障回复。
- **一致性**：在事务开始时数据库是一致状态的，那么在事务完成时数据库是一致状态的。
  - 这里的一致性主要是通过用户定义，由DBMS来维护的。如一个人年龄不能是负数（数据库一致性），转账前后总钱数不变等（事务一致性）。
- **隔离性**：隔离意味着当一个事务执行时，它应该有一个与其他事务隔离的错觉。
- **持久性**：如果一个事务提交，那么它对数据库的影响应该持久。
  - 关注点在<u>崩溃或重新启动</u>后，提交的事务的所有更改必须是持久的。这里需要考虑内存中的脏页写回磁盘的问题。
  - 其实原子性的实现方式恰好能满足持久性：Redo Log / Shadow Paging



## Q：ACID - 原子性如何实现？

- **Undo Log**：记录所有操作，以便撤消中止事务的操作。几乎所有的现代系统都使用日志记录。
- **Shadow Paging**：复制被事务修改的页面，让事务对这些副本进行更改。当事务提交时，与主页面做切换。
  - 它在运行时的开销大于恢复的开销，而真实场景下故障并不场景，因此在实践中很少使用这种方法。
  - 支持的数据库：CouchDB、LMDB



## Q：ACID - 隔离性的理论依据？

DBMS执行操作的顺序称为**调度（execution schedule）**。并发控制协议的目标是生成一个与串行执行等价的执行计划：

- **Serial Schedule / 串行调度**：不交叉不同事务的行动的计划。指事务AB，要么A先做完B再开始，要么相反。
- **Equivalent Schedules / 等价调度**：对于任何数据库状态，如果执行第一个调度的效果与执行第二个调度的效果相同，那么两个调度是等价的。
- **Serializable Schedule / 可串行化调度**：可串行化调度是一类等价于串行调度的调度。

**Conflict Serializability / 冲突可串行化**

- 如果两个调度的每对冲突操作都以相同的顺序进行，那么它们就是**冲突等价（conflict equivalent）**的。

- 如果调度S与某个串行调度冲突等效，那么它就是**冲突可串行化（conflict serializable）**的。

- 验证冲突可串行化的方法是使用依赖关系图。如果依赖图是无循环的，则调度是冲突可串行化的。

![dependency-graph](/static/image/2022-02-20/dependency-graph.png)

![universe-of-schedules](/static/image/2022-02-20/universe-of-schedules.png)



## Q：phenomena / 事务异像是什么？有哪些？

> - A Critique of ANSI SQL Isolation Levels
>
> - [transaction phenomena](http://xianmu.github.io/posts/2019-01-19-transaction-phenomena.html)
>
> - [The SQL92 Standard](http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt)

如果两个操作针对的是不同的事务，它们是在同一个对象上执行的，并且至少有一个操作是写操作，那么两个操作之间就会发生**冲突（conflict）**。当冲突发生时，可以说出现了**事务异像（phenomena）**。以下是SQL92定义的三种异常：

- **读写冲突 - Unrepeatable Reads / 不可重复读**：多次读取同一个对象时不能得到相同的值。
- **写读冲突 - Dirty Reads / 脏读**：可以看到在另一个事务之前的写。
- **Phantom / 幻读**：指读取两次记录的结果集合不同，原因是另一个事务在此期间insert / delete。

真实世界下还存在更多的异常，下面是`A Critique of ANSI SQL Isolation Levels`论文中提到的异常：

- **写写冲突 - Lost Updates / 更新丢失**：一个事务将覆盖另一个并发事务未提交的数据。
  - 更新丢失更多是指丢失的更新会造成一致性异常。如` R1[x], W2[x], C2, W1[x], C1`，这里事务1并不知道值改变了，如果事务2希望的是将存款清零，那么事实上事务1并未执行。
- **写写冲突 - Dirty Write / 脏写**：T2覆盖了未提交的T1的写，当T1回滚后，T2的更新丢失。
  - 区别于Lost Update，它是在某一个事务回滚后才出现问题。
- **Read Skew / 读偏移**：`R1(x)，W2(x), W2(y), R1(y)`，此时事务1读出来的x和y不满足一致性约束。
- **Write Skew / 写偏移**：两个并发事务都按照自己读到数据的一致性要求，去修改对方的数据。（会发生在快照隔离等级）



## Q：隔离等级有哪些？分别解决了什么异常？

> - http://www.bailis.org/blog/when-is-acid-acid-rarely/

下面是SQL92提出的一些隔离等级：

![isolation-levels](/static/image/2022-02-20/isolation-levels.png)

除此之外还有两个额外的隔离级别：

- **CURSOR STABILITY / 游标稳定性**：防止丢失更新（Lost Update）异常，是可重复读和读已提交之间的隔离性
  - 是IBM DB2中的默认隔离级别。
- **SNAPSHOT ISOLATION / 快照隔离**：保证在一个事务中进行的所有读取都能看到事务启动时存在的数据库的一致性快照。
  - 只存在写写冲突：事务只有在其写操作与该快照之后的任何并发更新不冲突时才会提交。
  - 容易导致Write Skew异常。

顺带一提，SQL92还提出了读写和只读的访问模式，只不过没有多少数据库实现了只读模式。

```
SET TRANSACTION [ READ WRITE | READ ONLY ];
BEGIN TRANSACTION [ READ WRITE | READ ONLY ];
```



## Q：如何实现隔离等级？哪些数据库支持什么等级？DBA常用哪个等级？

下面是一个提供SQL92各个隔离等级的一种方案：

![a-solution-to-isolation-levels](/static/image/2022-02-20/a-solution-to-isolation-levels.png)

一些DBMS支持的默认和最大隔离等级：

![isolation-levels-supporting](/static/image/2022-02-20/isolation-levels-supporting.png)

一个调查报告显示，DBA倾向于使用读已提交隔离等级。

![isolation-levels-survey](/static/image/2022-02-20/isolation-levels-survey.png)



## Q：幻读是如何解决的？

> - https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-gap-locks

幻读是一种特殊的异常，因为其他异常都是能从调整调度到与串行化调度相同来解决的。或者说insert和delete是一种针对表的特殊写。一些解决方案如下：

- **表锁**：在2PL的场景下，插入删除操作需要申请表写锁。
- **提交前重扫描**：如果没有出现幻读情况，那么提交；反之则重启。
- **索引锁 / 间隙锁**：
  - 如果有针对某个属性的索引，那么锁住对应的Page；如果索引中没有记录，那么锁住可能存在的位置
  - 如果没有这种索引，那么锁住所有page / 锁表。

对于MySQL而言，有Record Lock & Gap Lock来处理这件事。下面是我在读文档时想弄清楚的一些问题：
- 为什么record lock要锁前后区间防止inserting and deleting？那么Gap Lock的意义在哪里？
- 为什么在快照隔离等级里引入 NextKey Lock 来预防幻读？快照隔离是否天然可防止幻读？
- 为什么record lock要在非索引下创建索引，然后锁住索引record？不会导致索引变多么？如果是多个谓词条件查询情况下呢？



## Q：悲观 / 乐观并发控制协议是什么？

并发控制协议是DBMS如何在运行时从多个事务中决定操作的适当交错。并发控制协议有两类:

- **悲观并发控制**：假定事务之间经常发生冲突，所以它从事务开始就使用严格的方法，不让问题出现。
- **乐观并发控制**：假定事务之间的冲突很少发生，因此它选择在事务提交时发送冲突再处理问题。



## Q：2PL和S2PL是什么？执行过程如何？

两阶段锁定是一种悲观并发控制协议，它使用锁来确定是否允许事务动态地访问数据库中的对象。协议不需要提前知道事务将执行的所有查询，所以它提供了可交互的能力：

- **Phase #1– Growing**：每个事务向锁管理器请求它需要的锁。
- **Phase #2– Shrinking**：事务在释放第一个锁后立即进入收缩阶段。在收缩阶段，事务只允许释放锁。

![2pl-locking](/static/image/2022-02-20/2pl-locking.png)

注意：

- 2PL本身就足以保证冲突可串行化。它生成的调度优先图是非循环的。
- **死锁**：两个事务互相获取对方持有的锁。

- **级联回滚（cascading aborts）**：当一个事务中止时，现在必须回滚另一个事务，这会导致浪费。
  - 当T1进入释放阶段后执行某些操作时，T2获得锁，并在T1的修改上进行读写。当T1最终abort，T2的读写也失效了，于是也需要abort。
  - 其实就是由于脏读的产生导致级联回滚，下面的S2PL会解决这个问题。
  - 事实上，DBMS很难从用户得知什么时候应该进入Shrink阶段，所以大多数系统使用S2PL？

**Strict Two-Phase Locking / 严格两段锁**：S2PL是2PL的一种变体，事务只在提交时释放锁。

![s2pl-locking](/static/image/2022-02-20/s2pl-locking.png)



## Q：2PL下死锁如何解决？

**Deadlock Detection / 死锁检测**

系统在后台线程中周期性地检查事务等待图。当DBMS检测到死锁时，它将中止其中一个事务以打破这个循环。

- **终止因素**：选择哪一个事务来终止呢？常见的考虑因素有：年龄、锁个数、等待它的事务数等。许多系统使用这些因素的组合。
- **回滚范围**：在选择一个受影响的事务中止之后，DBMS还可以决定回滚该事务的更改的范围。它可以回滚整个事务，也可以回滚到足以打破死锁的某个操作。

![deadlock-detection](/static/image/2022-02-20/deadlock-detection.png)

**Deadlock Prevention / 死锁预防**

死锁预防是指在申请锁时如果已有事务占用，那么依据事务优先级来抢占或正常等待锁，即在发生死锁之前阻止事务。这里的优先级需要保证它总是偏序的，一般而言，将根据时间戳分配优先级（旧的事务具有更高的优先级）。

- **Wait-Die (“Old waitfor Young”)**：如果请求事务的优先级更高，则等待。否则，终止请求事务并抢占锁。 
- **Wound-Wait (“Young for Old”)**：如果请求事务的优先级更高，终止持有锁的事务并抢占。否则，请求事务将等待。

（不少系统使用了后者，比如Spanner）

![deadlock-prevention](/static/image/2022-02-20/deadlock-prevention.png)



## Q：锁的多粒度如何实现？

多数DBMS实现了表锁和行锁，并提出了意向锁。意向锁的意义在于提供一种优化：当申请表锁时可以不用扫描检查每一个行锁是否冲突。如果节点处于意图模式，则显式锁定将在树的较低级别执行。

- **Intention-Shared (IS) / 意向共享锁**：当事务给行加共享锁前，必须先取得该表的IS锁。表示使用共享锁在较低级别上显式锁定。
- **Intent-Exclusive (IX) / 意向独占锁**：当事务给行加独占锁前，必须先取得该表的IX锁。表示使用排他锁或共享锁在较低级别上显式锁定。
- **Shared+Intention-Exclusive (SIX) / 共享+意向独占**：根节点的子树在共享模式下是显式锁定的，显式锁定是在较低级别上用排他模式锁定完成的。
  - 本质上是原子性的申请了S和IX锁，常用于Update扫描表，一边扫描一边修改。

![intent-locking-compatibility-matrix](/static/image/2022-02-20/intent-locking-compatibility-matrix.png)

![explicitly-locking](/static/image/2022-02-20/explicitly-locking.png)



## Q：乐观并发控制协议有提到哪些？

**Basic Timestamp Ordering (BASIC T/O) / 基本时间戳排序**

每个数据库对象X都存在一个最后更新的事务时间戳，如读操作（记`R-TS(X)`）或写操作（记`W-TS(X)`）。

如果一个事务试图以一种违反时间戳顺序的方式访问一个对象，该事务将被中止并重新启动。潜在的假设是，违规行为将是罕见的，因此这些重启也将是罕见的。

- **读操作**
  - 当`TS(Ti) < W-TS(X)`，则违反时间戳顺序，所以事务将被中止，并使用一个新的时间戳重新启动。
  - 否则，Ti被允许读取X。然后更新`R-TS(X) = max(R-TS(X), TS(Ti))`。同时在事务过程中保存X的副本，以确保可重复读。
- **写操作**
  - 如果`TS(Ti) < R-TS(X) || TS(Ti) < W-TS(X)`，则重启Ti。
  - 否则，DBMS允许Ti写X并更新`W-TS(X)`。同时生成X的副本，以确保Ti的可重复读。

注意：

- **复制开销**：将数据复制到事务工作区和更新时间戳带来的高开销。
- **长事务饥饿**：长时间运行的事务可能会饿死。
- **时间戳瓶颈**：在高并发系统上受时间戳分配瓶颈。
- 所以基本没人用它。



**Optimistic Concurrency Control (OCC) / 乐观并发控制**

这里的OCC只是一种协议而已，跟乐观并发控制协议这个分类无关。

每个事务将保存一个**私有工作空间**。任何读写的对象都被复制到工作区中，并在那里修改。当事务提交时，DBMS会比较事务的工作区写操作，以查看它是否与其他事务冲突。如果没有冲突，则将数据写入全局数据库中。这个过程会有三步：

1. **Read Phase**：跟踪事务的读写，并将它们的写存储在一个私有工作区中。
2. **Validation Phase**：当一个事务提交时，DBMS检查它是否与其他事务冲突。
   - 在这个过程中，当前事务会与它开始之前或者提交之后的事务的时间戳和读写集做比较。
   - 如：T1在T2开始之前提交、T1和T2在第一阶段之前提交并且二者没有写集交集等。
3. **Write Phase**：如果验证成功，DBMS将私有工作区更改应用到数据库。否则，它将中止并重新启动事务

注意：

- **复制开销**：将数据复制到工作区带来的高开销。
- **时间戳瓶颈**：在高并发系统上受时间戳分配瓶颈。
- 似乎也没人用它。

![occ-example](/static/image/2022-02-20/occ-example.png)



## Q：MVCC是什么？设计MVCC需要考虑什么？

多版本并发控制（Multi-Version Concurrency Control）涉及DBMS设计和实现的各个方面。MVCC是dbms中应用最广泛的方案，几乎10年内所有新的DBMS都使用它。

MVCC使得数据库中单个逻辑对象会对应多个物理版本，读写操作都会根据一定的规则来寻找或创建该对象的物理版本，所以只会存在写写阻塞。每一种MVCC的设计都需要考虑四个部分，并选择对应的可选方案：**并发控制协议**、**版本存储**、**GC**、**索引管理**。

![mvcc-impl](/static/image/2022-02-20/mvcc-impl.png)



**Concurrency Control Protocol / 并发控制协议**

这里的并发控制是指在两个事务在同一个对象上发生了写写冲突时的解决方案，因为版本链是不能有分叉的。之前的悲观乐观控制协议都可以作为解决方案，比如MySQL-InnoDB使用了MV-2PL协议。



**Version Storage / 版本存储**

每个Tuple会带有一个上一个版本指针，它们形成了一个**版本链（version chain）**。索引总是指向链的Header，线程将遍历链，直到找到正确的版本。不同的存储方案决定了每个版本的存储位置和内容：

- **Approach #1: Append-Only Storage**：Tuple的所有物理版本都存储在同一个Page空间中。
  - 每次更新只是将元组的一个新版本添加到Page中，并更新版本链。
  - 这个链可以是最老到最新的排序(O2N)，这需要在查找时遍历链；也可以是最新到最老的排序(N2O)，但这需要为新版本更新所有索引指针

![append-only-storage](/static/image/2022-02-20/append-only-storage.png)

- **Approach #2: Time-Travel Storage**：维护一个单独的时间旅行表，用来存储较旧版本的元组。
  - 每次更新时，DBMS将主表中旧版本Tuple复制到时间旅行表中，并用新数据覆盖主表。同时主表中的元组指针指向时间旅行表中的过去版本。

![time-travel-storage](/static/image/2022-02-20/time-travel-storage.png)

- **Approach #3: Delta Storage**：在时间旅行表中，只存储Tuple之间的增量或变化。
  - 事务可以通过遍历增量来重新创建旧版本。这导致了比时间旅行存储更快的写操作，但更慢的读操作

![delta-storage](/static/image/2022-02-20/delta-storage.png)



**Garbage Collection / 垃圾回收**

随着时间的推移，DBMS需要从数据库中删除**可回收（reclaimable）**的物理版本。如果没有活动事务能看到该版本，或者该版本是由已中止的事务创建的，则该版本可回收。

- **Approach #1: Tuple-level GC**：直接检查元组来查找旧版本
  - **Background Vacuuming / 后台清理**：后台线程定期扫描表并寻找可回收的版本。一个简单的优化是维护一个脏页BitMap，跟踪自上次扫描以来哪些页面被修改过。
  - **Cooperative Cleaning / 合作清理**：运行事务的线程在遍历O2N版本链时，顺带做可回收检查。
- **Approach #2: Transaction-level GC**
  - 每个事务维护自己的写对象的旧版本。当提交时，可以使用它来确定要回收哪些元组。

![tx-level-gc](/static/image/2022-02-20/tx-level-gc.png)



**Index Management / 索引管理**

所有索引中的Tuple数据总是指向版本链头，所以DBMS需要在创建新版本后维护所有索引。注意，二级索引因为需要回表所以不必做更新，同时Delta和TimeTravel存储方法因为本身不用改变地址所以也不需要更新。

- **逻辑指针**：做一个物理指针映射中间层，索引总是指向中间层，而中间层做指针改变。这需要两次访盘。
- **物理指针**：每个索引存物理位置，所以新版本到来时都要更新所有索引。

注意，MVCC中的插入和删除会引起索引中的**冗余键**问题：

- T1在读A对象，此时T2想删除A，同时有T3想插入新的A。
- 那么旧A不能删除（也不能打墓碑位），而新A需要添加在index，导致了冗余键。那么如何处理？

需要注意的是，我们只能当逻辑上没有Tx访问该tuple时物理上删除它。所以这里必须引入<u>逻辑上删除</u>的概念。当逻辑删除后需要插入时，必须锁住插入的Tx：
1. Delete Flag：可以放在tupler header或者一个新column
2. Tombstone Tuple：创建新的版本，指明该tuple需要被删除

![mvcc-dup-key](/static/image/2022-02-20/mvcc-dup-key.png)
