# [CMU15-445] 知识点总结

> - https://15445.courses.cs.cmu.edu/fall2021/schedule.html

这里将从lecture的顺序来做总结。下面是在并发控制中展示的图，它说明了整个数据库系统的大致组成部分：

![dbms-structure](/static/image/2022-02-19/dbms-structure.png)

# Storage / 存储

## Q：常见介质读写速度

![access-speed](/static/image/2022-02-19/access-speed.png)



## Q：数据库中讨论的Page是指什么？

![database-pages](/static/image/2022-02-19/database-pages.png)



## Q：DBMS如何存储各个Page？

一般而言有两种存储方式：

**Heap File**

堆文件是一个无序的页面集合，其中Tuple按随机顺序存储。而Heap File则通过使用页面链表或页面目录实现，用于给定页面id的时定位磁盘上的页面：

- Linked List：维护一个Header Page，里面存储free page和data page的位置；同时每个page带有双向链表的指针。
- Page Directory：维护一个目录页，存储每个page的位置。

![linked-list](/static/image/2022-02-19/linked-list.png)

![page-directory](/static/image/2022-02-19/page-directory.png)

**存储于索引**

B+Tree：Cluster Index聚簇索引，在叶节点上直接包含对应的数据页。

HashTable：哈希表也可以存储`<key, location>`，也可以存储`<key, tuple>`。相当于减少一次访存。



## Q：在数据页的布局是什么样的？

**Slotted Pages**

这时当今dbms中最常用的方法。

- Page中的布局依次是头、空闲空间和Tuples数组。
- 其中Header记录了使用的槽数，最后一个使用的槽的起始位置，以及记录每个元组起始位置的槽数组。
- 对于Tuples数组部分，Tuples将从末尾到开始增长，响应的槽数组将从开始到结束增长。当槽数组和Tuple数据满足时，该页被认为是满的。

![slotted-pages](/static/image/2022-02-19/slotted-pages.png)

```
 table_page.h
 *  Slotted page format:
 *  ---------------------------------------------------------
 *  | HEADER | ... FREE SPACE ... | ... INSERTED TUPLES ... |
 *  ---------------------------------------------------------
 *                                ^
 *                                free space pointer
 *
 *  Header format (size in bytes):
 *  ----------------------------------------------------------------------------
 *  | PageId (4)| LSN (4)| PrevPageId (4)| NextPageId (4)| FreeSpacePointer(4) |
 *  ----------------------------------------------------------------------------
 *  ----------------------------------------------------------------------------
 *  | TupleCount (4) | Tuple_1 offset (4) | Tuple_1 size (4) | ...             |
 *  ----------------------------------------------------------------------------
```



**Log Structured**

一般DBMS只使用这种方法在存储日志记录。

- 为了读取记录，DBMS会扫描日志文件来重建日志。
- 适用于仅追加存储，因为DBMS不能返回和更新数据。所以写得快，读得慢。
- 为了避免长时间的读取，DBMS可以有索引，允许它跳转到日志中的特定位置。
- 可以周期性地压缩日志。但压缩的问题是DBMS最终会产生**写放大**。(Write Amplification，重复写相同的数据。)

![log-structured-file](/static/image/2022-02-19/log-structured-file.png)

![log-structured-snapshot](/static/image/2022-02-19/log-structured-snapshot.png)

## Q：什么是写放大？

> - [存储系统中的各种“写放大”](http://blog.jcix.top/2018-06-05/write_amplification/)



## Q：Tuple的内部结构是什么样的？

Tuple会存储两部分数据：

- Header：记录Tuple的大小、每个值是否为Null值的BitMap、并发控制的可见性信息等
- Payload：就是数据本身
  - 大部分数据库不支持Payload超过一个页
  - 可以将数据存储在一个特殊的“溢出”页面上，并让元组包含对该页面的引用的对象。这些溢出页可以包含指向其他溢出页的指针，直到可以存储所有数据为止。
  - 或者可以将数据存放在外部存储中，但这样就不能享受到DBMS提供的持久化和事务保证。

![overflow-page](/static/image/2022-02-19/overflow-page.png)

![external-file](/static/image/2022-02-19/external-file.png)

注意:

- 每个Tuple都有一个全局可访问的ID，一般而言是`page_id + offset`
- 如果两个表是相关的，那么**预连接**可能会有效：这两个表的数据最终会出现在同一个Tuple上。这使得读取速度更快，但更新成本更高



## Q：OLTP和OLAP工作负载区别？

OLTP：负载特征是快速且短暂的操作，典型的OLTP是写比读多的。

OLAP：负载特征是长时间且复杂的查询，定期会将数据从OLTP做ETL（提取转换加载）。

HTAP：二者混合。可直接在HTAP上做数据分析，也可以将数据转移在OLAP上。

![workloads](/static/image/2022-02-19/workloads.png)

## Q：数据页中Tuple的存储模型

这里的存储模型与数据页分布没有冲突，如Slotted Pages可以采用列式存储。不过列式存储的典型做法这里并没有介绍到，可以参考DDIA。

**N-Ary Storage Model (NSM） / 行存储**

DBMS将单个元组的所有属性连续存储在单个页面中。

这种方法对于OLTP工作负载非常理想：请求需要大量插入，且事务往往只操作单个实体。因为它只需要一次就能够获得单个Tuple的所有属性。

- **优势**：
  - 快速插入、更新、删除
  - 对查询Tuple所有属性的操作友好

- **缺点**：不适合做全表扫描、不适合做单独某些属性的查询（因为会查询到不需要的数据）

![nsm](/static/image/2022-02-19/nsm.png)

**Decomposition Storage Model (DSM) / 列存储**

DBMS将所有Tuple的列连续地存储在一个数据页中。

这个模型非常适合OLAP工作负载：大多数是只读查询，且常常做全表扫描 & 查询属性子集

- **优势**：
  - 减少了查询执行过程中浪费的工作量
  - 支持更好的压缩，因为相同属性的所有值都是连续存储的
- **缺点**：点查询、插入、更新和删除速度慢（因为需要多次随机查询，拼接出完整的Tuple）

![dsm](/static/image/2022-02-19/dsm.png)

拼接完整Tuple的方法有两种：

- **定长偏移量**：这是最常见的方法
  - 属性都是固定长度的，DBMS可以为每个元组计算属性的偏移量
  - 当拼接Tuple时，知道如何从offest跳转到文件中的该位置
  - 对于变长字段：维护`<offset, location>`的字典以便跳转；或者填充字段
- **内嵌ID**
  - 对于列中的每个属性，DBMS存储一个元组id。然后系统还会存储一个映射，告诉它如何跳转到每个具有该id的属性。
  - 这个方法有很大的存储开销，因为它需要为每个属性条目存储一个tuple id。

![dsm-history](/static/image/2022-02-19/dsm-history.png)

# Buffer Pool / 缓存

## Q：Buffer Pool是什么？为什么需要它？为什么不用OS的缓存？

Buffer Pool是从磁盘读取页面的内存缓存。它本质上是在数据库内部分配的一个大内存区域，用于存储从磁盘获取的页面。Buffer Pool的中的数据页被成为frame。

Buffer Pool维护的也不仅仅是Tuple和Index，更多的还有：sorting & joining缓存、查询缓存、日志缓存等。

**意义**

- DBMS面临的一个障碍是如何最大限度地减少移动数据的耗时。理想情况下，数据理应全部在内存中。
- DBMS比OS更加了解磁盘操作执行顺序和时机。比如：数据页淘汰策略、预取、脏页写回、WAL和checkpoint等。
- DBMS更清楚数据的时空局部性：在磁盘上经常使用的页面在物理上尽可能靠近、尽量减少从磁盘读取数据的档位数量。

大多数DBMS不使用OS缓存（O_DIRECT可绕过缓存）。不过，Postgres是一个使用操作系统页面缓存的数据库系统的例子。



## Q：锁与闩的区别？

![lock-vs-latch](/static/image/2022-02-19/lock-vs-latch.png)

## Q：闩的实现

**OS Mutex**

Linux提供了futex(快速用户空间互斥锁)，它由**用户空间中的自旋锁存器**和**操作系统级的互斥锁存器**组成。尽管它包含两个内部锁存器，但它看起来就像DBMS的一个锁存器。一些编程语言中包装了它，如C++`std::mutex`。

如果DBMS可以获得用户空间锁存器，那么就设置锁存器。如果DBMS没有获得用户空间锁存器，那么它就会进入内核，试图获得更重的互斥锁。如果DBMS没有获得第二个互斥锁，那么线程通知操作系统它被阻塞在这个互斥锁上，然后它被重新调度。

- 优势：简单易用；常用于处理等待进程多的场景，释放进程资源占用

- 缺点：开销太大，且不可扩展

**Spin Latch**

一般是指原子性的CAS。

- 优势：上锁/解锁很快
- 缺点：不可扩展，只能用在等待进程少的场景，否则占用进程资源；缓存不友好，因为它会出现导致缓存一致性问题，因为线程在轮询其他CPU上的缓存。

**RW Latch**

读写锁跟踪有多少线程持有它并等待获得锁。它在本质上使用前面两种锁存器实现中的一种作为原语，同时额外维护读写者队列，并记录读写者个数。

- 优势：读读可并发
- 缺点：可能导致饥饿问题（如果持续有reader占用锁，那么writer将饿死）。一个解决方法是当writer到来时，停止接受reader。

![rw-latch](/static/image/2022-02-19/rw-latch.png)

## Q：Buffer Pool的运作方式

当DBMS请求一个页面时，一个精确的副本被放置到缓冲池的一个帧中。然后，当请求页面时，数据库系统可以首先搜索缓冲池。如果没有找到该页，则系统从磁盘中获取该页的副本。

![buffer-pool](/static/image/2022-02-19/buffer-pool.png)

**metadata / 元数据**

- **页表**：内存中的哈希表，用于将页面id映射到缓冲池中的帧位置。
  - 页表还需要维护每页的额外元数据：**脏标记**和 **pin / reference counter**。
- **脏标志**：是由线程在修改页面时设置的。这指示存储管理器后续必须将该页写回磁盘。
- **pin / reference counter**：跟踪当前访问该页面的线程数。
  - 线程在访问该页之前必须增加计数器。如果一个页的计数大于零，那么存储管理器就不允许从内存中删除该页。



## Q：Buffer Pool的优化

**Multiple Buffer Pool**

支持的数据库：MySQL、Oracle、SQL Server、DB2

为不同的目的维护多个Buffer Pool。每个Buffer Pool可以采用针对存储在其中的数据定制的本地策略。该方法有助于减少锁存争用并改善局部性。

**预取**

根据查询计划预取页面。这是在连续访问多个页面时常用的方法。

**Scan Sharing / 共享游标**

支持的数据库：Oracle、SQL Server、PostgreSQL、DB2

查询游标可以重用扫描中检索到的数据：如果存在一个查询开始扫全表，那么DBMS就可以连接这个scan到第二个查询上。

**Buffer Pool 绕过**

支持的数据库：Oracle、SQL Server、PostgreSQL、Informix

顺序扫描操作符不会将获取的页面存储在缓冲池中，以避免开销。

因为某些数据大概率只会读取一次，比如读取连续大量页面时、临时数据查询时(排序，连接)。

后续会讨论到sequential flooding的情况，也可以用这种方法解决。



## Q：Buffer Pool的换页策略

**Least Recently Used (LRU) / 至少最近使用 / 最久未使用**

维护page队列。

- 当使用某个页时，将它放置在队头。
- 当驱逐某个页时，排出队尾元素。

**CLOCK**

维护环形链。每个元素都有一个计数位。

- 当使用一个页时，计数位设置为1。
- 当驱逐某个页时，如果页面的位设置为1，设置为零；如果不是，则驱逐它。

**Sequential Flooding / 顺序泛洪**

LRU和CLOCK容易受到顺序泛洪的影响：缓冲池的内容会因为顺序扫描，而不断被驱逐。

因为顺序扫描读取的每个页面，实际上是最不需要的页面，因为未来的一系列访问都不会再访问扫描过的页。

解决方法如下：

- 更大的工作集。
- 更好的换页策略：如LRU-K，它将最后K个引用的历史作为时间戳跟踪，用于预测页面下次被访问的时间。
- 查询的本地化：DBMS在每个事务/查询的基础上选择退出哪些页面。
- 优先级提示：允许事务根据查询执行期间每个页面的上下文告诉缓冲池页面是否重要。

**关于脏页**

这里的脏页会在后续的WAL中的checkpoint处理，如果使用简单checkpoint会直接写入磁盘，但是fuzzy checkpoint将在后台空闲执行.

# Access Methods / 访问方法

## Q：Hash Table的设计应该注意什么？

**Hash Function**：如何将一个较大的键空间映射到一个较小的域

- 需要考虑**执行速度**和**冲突率（均匀分布）**之间的权衡。
- DBMS不需要使用加密安全的哈希函数，不需要担心保护键的内容。
- 目前最先进的哈希函数是Facebook XXHash3。

![hash-function-benchmark](/static/image/2022-02-19/hash-function-benchmark.png)

**Hash Scheme**：如何处理哈希后的键冲突

- 需要考虑在分配一个大哈希表以减少冲突，还是在冲突发生时必须执行额外指令之间的权衡。



## Q：什么是 Static Hash Scheme / 静态哈希？

Static Hash Scheme，即哈希表的大小是固定的。如果哈希表中的存储空间用光了，那么必须重建更大的哈希表（通常两倍），这是非常昂贵的。

**Linear Probe Hashing / 线性探查**

是最基本的哈希方案，通常也是**最快的**。

数据结构上，它使用循环数组：

- 当冲突发生时，线性搜索相邻的插槽，直到找到一个开放的插槽，然后插入
- 对于查找，我们可以检查键散列所指向的槽，并线性搜索，直到找到所需的条目(或者一个空槽，在这种情况下键不在表中)
- 删除操作比较困难。为了不打破查询规则，一般有两种解决方案：
  - 墓碑位：为删除的数据打上墓碑位。查询时可以跳过，插入时可以直接插入。
  - 移动数据：直接将最末尾的数据移动到空位上。

关于**非唯一键**，有两种解决方案：

- 拉链法：每个槽将存储一个链表，相同hash的key存储在一起。
- 冗余键：直接存储即可，这是最常见的方案。

**Cuckoo Hashing / 布谷鸟哈希**

维护多个具有不同哈希函数的表。这里的哈希函数是相同的算法，但使用不同的种子。

- 当插入时，需要检查每个表，并选择一个有空闲槽的表
  - 如果没有表有空闲槽，我们随机选择一个表，并驱逐旧的条目。然后将旧条目重新散列到另一个表中。
  - 在极少数情况下，我们可能会陷入一个循环。这时需要重建所有哈希表，或者使用更大的表(更常见)重建哈希表。
- 这种Hashing保证了`O(1)`的查找和删除，但插入成本更高。

![cuckoo-hashing](/static/image/2022-02-19/cuckoo-hashing.png)

## Q：什么是 Dynamic Hash Scheme / 动态哈希？

动态哈希方案能够根据需要调整哈希表的大小，而不需要重建整个哈希表。

**Chained Hashing / 链式哈希**

这是最常见的动态哈希方案。DBMS为哈希表中的每个槽维护一个桶的链表，散列到相同槽位的键被简单地插入到该槽位的链表中。

注意：
1. 这里的链表是block（或者说page，它可以内涵多个元素）的链表，而非元素链表。
2. buckets扩容仍然需要rehash

![cuckoo-hashing](/static/image/2022-02-19/cuckoo-hashing.png)

**Extendible Hashing / 可扩展哈希**

GFS和ZFS等大多数文件系统使用这种方式来做Hash索引。

这种方法允许哈希表中的多个槽位置指向同一个bucket。其核心思想是在拆分时移动桶项，并增加比特数来检查哈希表中的条目。这意味着DBMS只需要在分割链的桶中移动数据;所有其他桶都保持原样。

- DBMS维护一个全局和局部深度位计数，它决定了在槽数组中查找bucket所需的位数。
  - 当查询时，需要降Key的后N位与全局槽位中的数进行匹配，然后访问对应的bucket。
- 当存储桶满时，DBMS将存储桶拆分并重新shuffle它的元素。
  - 如果拆分桶的局部深度小于全局深度，则新桶将被添加到现有的槽位数组中。否则，DBMS将插槽数组的大小翻倍以容纳新的存储桶，并增加全局深度计数器。
- 当删除元素时，可以触发Shrink，具体见2018 / 2019 Homework2

![extendible-hashing](/static/image/2022-02-19/extendible-hashing.png)

## Q：B+Tree的定义

B+树是一种自平衡的树数据结构，它保持数据排序，允许在`O(log(n))`内进行搜索、顺序访问、插入和删除。它是针对读写大块数据的面向磁盘的DBMS进行优化的数据结构。

现代的B+Tree实现结合了其他B-Tree变体的特性，比如Blink-Tree中使用的兄弟指针。另外，作为参照，这里给出每个优化的大致发表年份：1971 B-Tree、1973 B+Tree、1977 B*Tree、1981 Blink-Tree。

**定义**

B+树是一棵M路搜索树，且具有以下属性:

- 每个叶节点都在相同的深度，即完美平衡。
- 除根节点外，每个内部节点至少满一半`M/2−1 <= num of keys <= M−1`。
- 每个有k个键的内部节点有k+1个非空子节点。

一下是BusTub的叶节点定义，主要包括页信息、兄弟节点ID、父节点ID、`<key, RID>`对：

```
 * Store indexed key and record id(record id = page id combined with slot id,
 * see include/common/rid.h for detailed implementation) together within leaf
 * page. Only support unique key.
 *
 * Leaf page format (keys are stored in order):
 *  ----------------------------------------------------------------------
 * | HEADER | KEY(1) + RID(1) | KEY(2) + RID(2) | ... | KEY(n) + RID(n)
 *  ----------------------------------------------------------------------
 *
 *  Header format (size in byte, 28 bytes in total):
 *  ---------------------------------------------------------------------
 * | PageType (4) | LSN (4) | CurrentSize (4) | MaxSize (4) |
 *  ---------------------------------------------------------------------
 *  -----------------------------------------------
 * | ParentPageId (4) | PageId (4) | NextPageId (4)
 *  -----------------------------------------------
```

![b-plus-tree-leaf-node](/static/image/2022-02-19/b-plus-tree-leaf-node.png)

**查询**

这里想讨论一种非最左匹配的查询。比如索引包括了A、B两个列的属性，那么如何查询`<*, b>`的所有值？

从最后一层中间节点开始扫描，优化掉不需要访问的叶节点（指不包含`B==b`的叶节点），最后再依次访问叶节点即可。

## Q：B+Tree如何处理非唯一键？

与Hash表相似，两种方法：冗余键和拉链法。

## Q：Clustered Indexes / 聚簇索引

![clustered-indexes](/static/image/2022-02-19/clustered-indexes.png)

聚簇索引的优点：

- 减少额外存储空间，减少一次访存操作（虽然二级索引需要回表）
- 多版本GC + 删除时的tuple物理地址移动只会做一次
- 二级索引回表时，可以排序主键的访问顺序，做到顺序访问存储

## Q：B+Tree的设计选择

**节点大小**

- 取决于**存储介质**
  - HDD存储通常使用MB级别大小，以减少查找数据时访盘次数。
  - 内存数据库则使用最小为512B的页面大小，以便将整个页面放入CPU缓存，并减少数据碎片。
- 取决于**工作负载**
  - 点查询希望页面越小越好，以减少不必要的额外信息加载量
  - 大型顺序扫描可能希望页面越大，以减少所需的读取次数。

**合并阈值**：拖延删除插入时的合并操作

**可变长键**

- **指针**：只存储指向键的指针，而不是直接存储键(`<key-ptr, value>`)。
  - 效率很低。嵌入式设备会在生产中使用，其微小的寄存器和缓存可以从这种节省的空间中受益
- **可变长节点**：允许可变长度的节点
  - 不可行。由于处理可变长度节点的内存管理开销很大，所以基本上不使用
- **填充**：把短数据填充到最长数据的空间
  - 不可行。是对内存/存储的极大浪费。
- **Key Map**：额外存储一个`<key-ptr, kv-offset>`的映射
  - 几乎所有人都在用。
  - 甚至有足够的空间放置每个键的一个前缀`<prefix, <key-ptr, offset>>`，可能允许一些索引搜索和扫描

**中间节点访问方式**

到达节点后，仍然需要在节点内进行搜索(要么从内部节点查找下一个节点，要么在叶子节点中查找键值)

- **线性扫描**
- **二分查找**



## Q：B+Tree的优化

**Prefix Compression / 前缀压缩**

大多数情况下，叶节点中的大多数键的前缀会有重叠。我们可以简单地在节点的开头存储该前缀一次，然后只在每个槽中包含每个键的剩下一部分。

![prefix-compression](/static/image/2022-02-19/prefix-compression.png)

**Deduplication / 解冗余**

在允许非唯一键的索引的情况下，冗余键会生成多个相同的key`(key1, val1), (key1, val2)`。这里优化的方法是只写一次Key，然后在它后面跟着它的所有相关值：`(key, val1, val2, ...)`

**Bulk Insert / 大量插入 / 快速初始化**

当最初构建B+树时，可以直接构造一个有序的叶节点链表，然后从下向上构建索引，那么数据的初始插入将更加高效。

如果Bulk insert带上faster merging的话，就可以做到非初始化时的大量插入。下面是快速合并的一些方法：
1. 离线：阻止所有操作去合并
2. eager / 早访问：同时从两个index里做访问，如果查询结果有交集，那么用最新的
3. 后台合并：分布式下空闲机合并 / 空闲时合并
4. 懒合并：如果leaf没有变化，那么不合并



## Q：Hash Table如何做并发？

**Static Hash Table**

所有线程都沿着相同的方向移动，且线程一次也只访问一个页面，所以死锁是不可能的。因为没有两个线程会竞争由另一个线程持有的锁。所以直接上读写锁即可并发。

**Dynamic Hash Table**

其实是与静态hash table相同的做法，只不过有更多状态需要锁存。顺便CAS天然支持Insert操作，只需保证元素的CAS是原子性的即可。



## Q：B+Tree 如何做并发？

B+Tree做并发的主要问题在于如何解决一个线程遍历树，同时另一个线程拆分/合并节点。

**Latch Crabbing / Latch Coupling**

这是一个允许多个线程同时访问/修改B+Tree的协议：

1. 在访问的同时，从上到下给路径上的每个节点加锁。

2. 如果当前节点是安全的，那么释放所有父节点的锁。这里的安全是指，该节点不会拆分（插入时不是满的）或不会合并（删除时超过一半满的）。

**Basic Latch Crabbing Protocal**

**搜索**：从上到下，反复地获取子结点的读锁，然后释放结点的闩锁。

**插入 / 删除**：从上到下，根据需要获得写锁。一旦发现操作是安全的，那么释放他所有祖先的写锁。

注意：这里释放锁的顺序没有特别的讲究，不过从根开始释放会更好，因为根有更多的访问量。

**Impoved Latch Crabbing Protocal / 乐观的Latch Crabbing Protocal**

因为在插入删除时总需要根节点上获得独占锁，所以这限制了并行性。我们假定到目标叶节点的路径是大多数安全的，所以这里用读锁访问到叶节点检查安全性。

**搜索**：以前一样。

**插入 / 删除**：设置读锁访问叶节点，如果叶节点安全，那么设置叶子上的写锁；如果叶子不安全，使用之前的插入删除协议重新启动事务
