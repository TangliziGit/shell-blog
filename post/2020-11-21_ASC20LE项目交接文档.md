
<!-- vim-markdown-toc Marked -->

* [ASC - LE 项目交接文档](#asc---le-项目交接文档)
    * [背景](#背景)
        * [一些参考文档](#一些参考文档)
    * [已有的工作](#已有的工作)
    * [项目结构](#项目结构)
    * [安装运行](#安装运行)
        * [安装](#安装)
        * [训练模型](#训练模型)
        * [评估模型](#评估模型)
        * [分析](#分析)
            * [分析微调日志](#分析微调日志)
            * [分析评估日志](#分析评估日志)
                * [统计数据](#统计数据)
                * [错误类型的图像](#错误类型的图像)
        * [建立新的数据集](#建立新的数据集)
    * [优化思路](#优化思路)
        * [对评估过程的优化](#对评估过程的优化)
        * [对微调的优化](#对微调的优化)
        * [对数据集的优化](#对数据集的优化)
    * [一些你需要注意的地方](#一些你需要注意的地方)
    * [其他的一些想法](#其他的一些想法)

<!-- vim-markdown-toc -->

# ASC - LE 项目交接文档


##  背景

本项目是2020年1月份开始进行的，本人在当年6月份进行了最后一次的训练和测试。原团队里有张椿旭和张栩浩，本人负责数据爬取、数据预处理和模型预测优化全流程的调研、设计和代码实现，张栩浩负责模型选取和分布式训练的调研、设计和实现。此项目仍有一些优化空间，本人和张栩浩是由于课程和升学的事情而暂停了ASC的工作。目前我们的最高正确率在88.22%。

项目选取了`RoBERTa`模型，于2019年由`facebook`实现，基于`PyTorch`框架。在模型选取上，我们最终选择它的原因是在一些数据集上的正确率表现比较好。模型选取的细节在后文中会体现。

本项目现在存于`202.117.249.6`节点的`/public/home/asc03/ele`目录中。除了数据和日志等敏感数据，代码部分也可访问<https://gitee.com/TangliziGit/ASC20-ELE>。

在接手项目前，希望能阅读一些`RoBERTa`的文档，否则会难以理解接下来的说明。



### 一些参考文档

事实上不限于这些，遇到问题时任何渠道都可以提供参考。

- PyTorch和BERT模型的使用：可参考大多数博客
- 官方repo：<https://github.com/pytorch/fairseq/>，是一个NLP工具箱，我们只使用了其中的`roberta`。
- 需要重点阅读：<https://github.com/pytorch/fairseq/tree/master/examples/roberta>，其中数据集构建和微调等，本项目是没有变化的。
- 优化思路的原始记录：<https://tanglizi.one/post.sh?name=2020-02-05_ASC-Supplementary_4.md>
- 关于运行等的记录：<https://tanglizi.one/post.sh?name=2020-03-05_ASC-Supplementary_6.md>



## 已有的工作

1. 模型比较和选取
2. 数据爬取、清洗和结构化的工作
3. 各种数据集选取与测试
4. 各种优化思路、结果和分析：<https://tanglizi.one/post.sh?name=2020-02-05_ASC-Supplementary_4.md>
5. 微调脚本、评估代码和结果分析脚本的实现
6. 项目迁移的工作：<https://tanglizi.one/post.sh?name=2020-02-21_ASC-Supplementary_5.md>



## 项目结构

由于直接基于`RoBERTa`进行开发，所以有很多文框架提供的，实际上这里只要关注一些重要的文件即可。

下面是一个简化的目录结构，标星号的是需要经常使用的：

```
/public/home/asc03/ele
├── analysis/						# *存储分析结果用的ipynb文件
│   ├── log.ipynb
│   └── loss.ipynb
├── checkpoints/					# *用于存储训练结果的
│   ├── mask-exp10
│   ├── mask-exp11
│   ├── mask-exp12
│   ├── mask-exp13
│   ├── mask-exp13-2
│   ├── mask-exp13-3
│   ├── mask-exp13-4
|   ...
├── data/							# 存储数据集的，一些原始数据可以暂时存储在这里
├── data-bin/						# 用于训练的数据
│   ├── ele
│   ├── ele-clean-mtc
│   ├── ele-clean-tc
│   ├── ele-mofangge
│   ├── ele-mofangge-test
|   ...
├── draw.py							# *读取指定的训练产生的日志，进行绘图，包括loss和错误类型的统计图
├── evaluate_candidates.py			# *评估训练完成的模型
├── fig/							# *存储draw.py绘图的图像
│   ├── error.png
│   └── loss.png
├── find_prop.py					# 用于计算阈值的程序，注意它只能给出一个大概的范围，关于阈值的选取需要经验来敲定
├── finetune/						# 旧有的微调脚本，请直接忽略
├── log/							# *日志
│   ├── 0131_03:51.log
│   ├── 0131_13:40.log
│   ├── 0131_14:49.log
│   ├── 0131_15:17.log
|   ...
├── mask-finetune/					# *现有的微调脚本，包含了exp开头的文件
│   ├── base.sh
│   ├── exp10.sh
│   ├── exp11.sh
│   ├── exp12.sh
│   ├── exp13-2.sh
│   ...
├── models/							# 存储roberta基础的模型
│   ├── roberta.base
│   ├── roberta.large
│   ├── roberta.large.mnli
│   └── roberta.large.wsc
├── monitor.py						# 原本用于管理训练测试等模型生命周期的简单脚本，现被更轻量的函数取代，已弃用
├── pkl/							# *是评估程序的结构化的输出，可用于各种分析。
│   ├── mask_base-log.pkl			# 注意，本人在最后的几次测试中，忘了把一些pkl文件从项目根目录移动到这里了
│   ├── mask_base-slog.pkl
│   ├── mask-exp1-log.pkl
│   ├── mask-exp1-slog.pkl
│   ├── mask-exp2-log.pkl
│   ...
├── process.sh						# 用于构建数据集的脚本
├── raw/							# 是处理好的原始数据
├── send_email.py					# 发邮件的，结合log的shell函数使用，不需要直接运行
├── stat.py							# 对评估的日志，做一些简单的统计
└── test_near.py					# 基于评估脚本，在错误类型中做得一些尝试，可忽略
```



## 安装运行

> 请参考 <https://tanglizi.one/post.sh?name=2020-03-05_ASC-Supplementary_6.md>



### 安装

项目基于`fairseq`工具集，它的安装是极大依赖网络的，如果遇到此类问题参考：[内网环境下的依赖处理](https://tanglizi.one/post.sh?name=2020-01-16_%E5%86%85%E7%BD%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E4%BE%9D%E8%B5%96%E5%A4%84%E7%90%86.md)

最简单的解决方式是问老师要可以访问网络的节点。

建议直接使用原来的目录。



### 训练模型

需要明确的一点是，任何一个基于`BERT`的模型都需要大量时间进行训练。而为了提高复用性和训练效率，我们都是在官方提供的已训练好的模型上，进行微调。

微调只需要运行一个CLI命令，但是为了方便管理，所以我们通常写一个shell脚本：

```shell
# 以 mask-finetune/exp4.sh 为例

TOTAL_UPDATES=2400    # Total number of training steps
# WARMUP_UPDATES=100    # Warmup the learning rate over this many updates
PEAK_LR=0.000004          # Peak learning rate, adjust as needed
TOKENS_PER_SAMPLE=512   # Max sequence length
MAX_POSITIONS=512       # Num. positional embeddings (usually same as above)
# MAX_SENTENCES=16        # Number of sequences per batch (batch size)
# UPDATE_FREQ=16          # Increase the batch size 16x
MAX_SENTENCES=2        # Number of sequences per batch (batch size)
UPDATE_FREQ=64          # Increase the batch size 16x

SAVE_DIR=checkpoints/mask-exp4     # !!! 这里不要忘了改
ROBERTA_PATH=models/roberta.large/model.pt

DATA_DIR=data-bin/ele

# CUDA_VISIBLE_DEVICES=0 fairseq-train --fp16 $DATA_DIR \		# 这是开启半精度，仅0号GPU运行
fairseq-train $DATA_DIR \
    --task masked_lm --criterion masked_lm \
    --arch roberta_large --sample-break-mode complete --tokens-per-sample $TOKENS_PER_SAMPLE \
    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \
    --lr-scheduler fixed --lr $PEAK_LR \
    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \
    --max-sentences $MAX_SENTENCES --update-freq $UPDATE_FREQ \
    --max-update $TOTAL_UPDATES --log-format simple --log-interval 25 \
    --ddp-backend=no_c10d \
    --restore-file $ROBERTA_PATH \
    --save-dir $SAVE_DIR \
    --skip-invalid-size-inputs-valid-test
```

然后运行`bash mask-finetune/exp4.sh`。

或者你如果想输出一个日志，并在结束时给自己发一封邮件，使用在`.bashrc`中实现的`log`命令:

```bash
log bash mask-finetune/exp4.sh
```

它会输出一个`log/0303_23:19.log`日志。

`log`函数是大概这样的，`send_mail.py`文件中请自己配置客户端密码。

```bash
function log(){
    dir=`pwd`
    filename=$dir/log/`date +%m%d_%H:%M.log`

    echo "$@" >> $filename
    $@ 2>&1 | tee -a $filename

    echo "" >> $filename
    date +%m%d_%H:%M >> $filename
    python $dir/send_email.py $filename
}
```





### 评估模型

```bash
python evaluate_candidates.py --questions data/ELE/valid.jsonl --model checkpoints/mask-exp4 --log mask-exp4
```

用于解答 `data/ELE/valid.jsonl`里的问题，使用 `checkpoints/mask-exp4/model.pt`模型，并且记录一些日志到`mask-exp4-log.pkl`。



### 分析



#### 分析微调日志

更新在`draw.py`文件中的`log_files`

```python
log_files = {
    "large": "0208_13:11.log",
    "exp1":  "0210_21:12.log",
    "exp2":  "0211_11:51.log",
    "exp3":  "0212_21:20.log",
    "exp4":  "0214_00:21.log",
    "exp6":  "0228_08:58.log",
    "exp7":  "0228_20:23.log",
}
```

然后运行`python draw.py`, 你可以得到 `fig/loss.png`。



#### 分析评估日志

##### 统计数据

评估之后，运行 `python stat.py pkl/mask-exp4` 可以得到一个简单的统计结果：

```bash
multi-words      0.0
unk            220.0
near           468.0
far            268.0
dtype: float64

max acc 1.0
min acc 0.25
var acc 0.01125261111111111
Accuracy: 0.8774044626827392
```



##### 错误类型的图像

如`分析微调日志`一样，修改`pkl_log_files`在`draw.py`中：

```python
pkl_log_files = {
    "#18": "mask-large-without_ul",
    "#19": "mask-large-without_ul-long_art",
    "#20": "mask-large-without_ul-long_art-unk",
    "#21": "mask-exp3-without_ul-long_art-unk",
    "#22": "mask-exp3-t4",
    "#23": "mask-exp4-t4",
    "#24": "mask-exp4-t3",
}
```

运行`python draw.py`得到`fig/error.png`。



### 建立新的数据集

请主要参照`RoBERTa`文档，以及[ASC-Supplementary 6](https://tanglizi.one/post.sh?name=2020-03-05_ASC-Supplementary_6.md)。



## 优化思路

> 原文在[ASC-Supplementary 4](https://tanglizi.one/post.sh?name=2020-02-05_ASC-Supplementary_4.md)

经过各种优化方案的测试，目前我们的最高正确率在88.22%：

- 评估过程的优化实现为`evaluate_candidates.py`文件；
- 微调的优化是`mask-finetune/exp15-clean-tc.sh`；
- 数据集的优化是使用了`ele-clean-tc`的数据集，它基于`ele-raw`添加了清洗过的`cloth`数据集。



### 对评估过程的优化

我们提出了很多优化的想法，但有一部分想法是难以实现或者没有效果的。这里按照重要程度讲一下最终采取的四种优化方案。

1. **Candidates**

   实际上是压缩了候选词的选择空间，从全局词表中抽出候选项的几个词，作为选项的选择权重。注意评估文件中的`self.roberta.fill_mask_with_candidates`方法，它是本人在原框架的基础上添加的一个新的方法。它作为此次优化的实现。

2. **迭代回填**

   思路是当预测的某个词的概率大于某个阈值时，可有一定概率认为这是正确选项。并将这个`认为正确的词`填回文章中，直觉上、理论上和测试结果都反映了它能提高平均正确率，这个操作我们叫做回填。

   迭代回填的意思是，当头一次预测时，某个题目中的预测词的概率小于某个阈值，未被选为可回填的词。同时，在接下来的某个题目中存在某词被回填。那么，相当于文章多了一个信息，则之前未被回填的题目就有可能会存在可回填的词。反复预测, 直到本轮没有新的`认为正确的选项`。

   那么这个阈值该如何确定？首先本人通过概率计算了一个粗略的值，见`find_prop.py`；其次，在各种测试中选定了一些可能更好的阈值，见`evaluate_candidates.py`。

3. **多段词优化**

   经日志分析, 发现像`look at`或`seek for`这样的多个词组成的答案（这里我们称为多段词）, 在词表中是不存在的。并且这个现象非常常见(见Error Type分析).
   我们基于贝叶斯序列对此进行优化，计算出多段词的选取概率。原理简单，但效果拔群。 如`look at`: 

   $$P(look \space at)=P(look)∗P(at∣look)$$

4. **长文章优化**

   此项优化针对由于文章长度超过模型预设的大小，一次性评估不可行的问题。
   于是通过对长文章进行裁剪，解决此问题。本此优化的简略步骤:

   1. 将某个将预测的选项所处的句子号码找出, 作为输入文章的句子列表
   2. 对上下文临近的句子添加进来, 同时进行长度测试



### 对微调的优化

通过调整各种微调参数进行模型本身的优化，本人的各种尝试，见`mask-finetune/expX.sh`中。

通常为batch，数据集，lr，优化算法等的修改尝试。



### 对数据集的优化

数据集也是一个非常重要的部分，比如我们使用的`cloth`数据集，经过数据清洗，它与原有`ele-raw`结合提升了将近一个百分点的正确率。

关于数据集的各种尝试，见`data-bin/`或`raw/`。



## 一些你需要注意的地方

1. 项目由git管理，所以当有一个可以回退的状态出现时，最好提交一次。比如，新的评估脚本经过测试能够提高正确率。
2. 同样，项目由git管理。你可以在本地使用IDE进行开发，当本地开发完成后，提交至`gitee`。在节点上再拉取下来，进行测试。这样就不必来回复制文件。
3. 注意`log`函数的使用，它能够很大的减轻你的负担，你可不必手动上节点查看是否运行结束。
4. 尤其注意各种日志的存储和优化过程的记录，当你的方案和结果越来越多时，它能够指导你如何选取已有的方案。
5. 注意日志的分析过程，它能够给你下一步的idea提供思路。



## 其他的一些想法

1. 原有的模型选定后，已经过了将近一年的时间，新的模型和数据集尤其值得注意。也可重新选择模型，在它的基础上，复现之前的各种idea。
2. 在任何竞赛上，都要善于与老师队员进行沟通、负责任地克服难点和了解学习各种知识。提高自身的价值并带动其他人，我认为这才是竞赛本身的最终目的。
