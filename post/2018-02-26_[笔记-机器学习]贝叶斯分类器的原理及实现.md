最近阅读了《Python与机器学习实战》的贝叶斯分类器这部分
对比了一下我写的分类器，发现还有很多地方可以优化，不知道有没有时间去做优化了
但是这个笔记还是要写的，我们先做一个简单的目录
**注意本文只是一个夹杂了个人理解的笔记，初次学习，有误是肯定的**
- 贝叶斯决策论
- 参数估计
    1. 极大似然估计
    2. 极大后验概率估计
- 朴素贝叶斯
    1. 离散型朴素贝叶斯
    2. 连续型朴素贝叶斯
    3. 混合型朴素贝叶斯
- 半朴素贝叶斯和贝叶斯网

### 贝叶斯决策论
这里首先写一下其中的一些概念
- 样本空间 $ X $ ：指一个包含数据样本的向量$ \tilde{X} $的空间，即有 $ \tilde{X} \in X $
- 样本  $ \tilde{X} $：由各个数据样本构成的高维向量，即 $ \tilde{X}=(x_1, ..., x_n)^T $
- 行动空间 $ A $：指处理问题的所有行动的空间（我的理解就是处理问题的各种方法的空间）
- 参数空间 $ \Theta $：指所有分类的各个参数的集合，在这里我们这样规定 $ A=\Theta $
- 决策 $ \delta(\tilde{X}) $ ：一个样本空间到行动空间的映射，可以通过一组样本 $ \tilde{X} $ 取得一个处理问题的行动（ $ \delta(\tilde{X}) \in A $ ）
- 损失 $ L(\theta, \delta(\tilde{X})) $ ：用以描述在参数$\theta, (\theta \in \Theta)$和行动 $ \delta(\tilde{X}) $ 时所引起的损失
- 决策风险 $ R(\theta, \delta) $ ：它是损失函数的期望：$ R(\theta,\delta)=EL(\theta,\delta(\tilde X)) $
- 平均风险 $ \rho(\delta) $ ：它是决策风险在先验分布 $ \theta{X} $ 下的期望： $ \rho(\delta)=E_\xi R(\theta,\delta) $ 
- 贝叶斯决策 $ \delta^* $ ，它满足：$ \rho(\delta^*)=\inf_\delta\rho(\delta) $ 
即最小后验期望损失，贝叶斯决策也就是这样的
$$ \delta^*=\arg \min_\delta \sum_{\theta_{k} \in \Theta} L(\theta_{k}, \delta)P(\theta_{k}|\tilde{X}) $$
（这里不理解）
（数学这块还是不太行啊，看来要预习一下）

### 参数估计
1. **极大似然估计**
自然希望得到一个参数，能当输入为X时，输出正确分类的概率最大。
我们希望找到这样一个 $\hat{\theta}$:
$$ \hat{\theta}= \arg \max_\theta \prod_{i=1}^{N}P(x_{i}|\theta)  $$
2. **极大后验概率估计（MAP估计）**
MAP估计的一个优势就是它引入了一个先验概率，即
$$ \hat{\theta}= \arg \max_\theta P(\theta)\prod_{i=1}^{N}P(x_{i}|\theta)  $$

### 朴素贝叶斯
首先给出由贝叶斯公式推出的概率：
$$ P(\theta|\tilde{X})=\frac{P(\tilde{X}|\theta)P(\theta)}{P(\tilde{X})} $$
朴素贝叶斯的一个假设是各个随机变量之间是相互独立的，即：
$$ P(X)=P(x_{1}, x_{2}, ..., x_{n}|\theta)=\prod P(x_{i}|\theta) $$
- **朴素贝叶斯参数空间**
朴素贝叶斯模型参数空间即为类别的选择空间（假设一共有K类：$ c_{1}, .., c_{K} $），即：
$$ \Theta={y=c_{1}, y=c_{2}, ..., y=c_{K},} $$
通过观察贝叶斯公式，可以知道$ P(\tilde{X}) $是一个不需要的信息，
所以朴素贝叶斯参数空间中包括先验概率$ p(\theta_{k})=p(y=c_{k}) $，条件概率$ p(X|y=c_{k}) $， 样本空间概率$ p(X) $
- **决策**
决策就是后验概率最大化（需证明），于是具体的决策函数就是这样：
$$ f(x)=\arg \max_{c_{k}} \prod _{j=1}^{n}\hat{p}(x|y=c_{k}) $$
- **损失**
在离散朴素贝叶斯中，损失函数是这样：
$$ L(\theta, \delta(\tilde{X}))=\sum_{i=1}^{N}I(y_{i}\neq f(x_{i})) $$

暂时更新到这里，还有其他事：（

> 2018-02-28 16:35 Update: 更新至朴素贝叶斯的损失